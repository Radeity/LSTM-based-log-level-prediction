<logcall>org.apache.kafka.connect.data.Logger.debug</logcall> <parameter>java.lang.String(name)Unable to parse the value as a map; reverting to string-org.apache.kafka.connect.errors.DataException(name)e</parameter><constant>Unable to parse the value as a map; reverting to string</constant><level>debug</level><callsite>org.apache.kafka.connect.data.Values.parse</callsite><line>817</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to deserialize value for header '{}' on topic '{}', so using byte array-java.lang.String(name)headerKey-java.lang.String(name)topic-java.lang.Throwable(name)t</parameter><constant>Failed to deserialize value for header '{}' on topic '{}', so using byte array</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.SimpleHeaderConverter.toConnectHeader</callsite><line>68</line><superclass>null</superclass><logcall>org.apache.kafka.connect.rest.basic.auth.extension.Logger.error</logcall> <parameter>java.lang.String(name)Error loading credentials file -java.io.IOException(name)e</parameter><constant>Error loading credentials file </constant><level>error</level><callsite>org.apache.kafka.connect.rest.basic.auth.extension.PropertyFileLoginModule.initialize</callsite><line>73</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Hostname for node {} changed from {} to {}.-java.lang.String(name)id-java.lang.String(name)connectionState.host()-java.lang.String(name)host</parameter><constant>Hostname for node {} changed from {} to {}.</constant><level>info</level><callsite>org.apache.kafka.clients.ClusterConnectionStates.connecting</callsite><line>136</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Manually disconnected from {}. Removed requests: {}.-java.lang.String(name)nodeId-java.lang.String(name)Utils.join(requestTypes,", ")</parameter><constant>Manually disconnected from {}. Removed requests: {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.disconnect</callsite><line>326</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)No version information found when sending {} with correlation id {} to node {}. Assuming version {}.-org.apache.kafka.common.protocol.ApiKeys(name)clientRequest.apiKey()-int(name)clientRequest.correlationId()-java.lang.String(name)nodeId-short(name)version</parameter><constant>No version information found when sending {} with correlation id {} to node {}. Assuming version {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.doSend</callsite><line>466</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Version mismatch when attempting to send {} with correlation id {} to {}-org.apache.kafka.common.requests.Builder<>(name)builder-int(name)clientRequest.correlationId()-java.lang.String(name)clientRequest.destination()-org.apache.kafka.common.errors.UnsupportedVersionException(name)unsupportedVersionException</parameter><constant>Version mismatch when attempting to send {} with correlation id {} to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.doSend</callsite><line>478</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Sending {} {} with correlation id {} to node {}-org.apache.kafka.common.protocol.ApiKeys(name)clientRequest.apiKey()-org.apache.kafka.common.requests.AbstractRequest(name)request-int(name)clientRequest.correlationId()-java.lang.String(name)destination</parameter><constant>Sending {} {} with correlation id {} to node {}</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.doSend</callsite><line>496</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Using older server API v{} to send {} {} with correlation id {} to node {}-short(name)header.apiVersion()-org.apache.kafka.common.protocol.ApiKeys(name)clientRequest.apiKey()-org.apache.kafka.common.requests.AbstractRequest(name)request-int(name)clientRequest.correlationId()-java.lang.String(name)destination</parameter><constant>Using older server API v{} to send {} {} with correlation id {} to node {}</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.doSend</callsite><line>499</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during I/O-java.io.IOException(name)e</parameter><constant>Unexpected error during I/O</constant><level>error</level><callsite>org.apache.kafka.clients.NetworkClient.poll</callsite><line>541</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught error in request completion:-java.lang.Exception(name)e</parameter><constant>Uncaught error in request completion:</constant><level>error</level><callsite>org.apache.kafka.clients.NetworkClient.completeResponses</callsite><line>563</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Attempting to close NetworkClient that has already been closed.</parameter><constant>Attempting to close NetworkClient that has already been closed.</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.close</callsite><line>634</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Found least loaded node {} connected with no in-flight requests-org.apache.kafka.common.Node(name)node</parameter><constant>Found least loaded node {} connected with no in-flight requests</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>666</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Removing node {} from least loaded node selection since it is neither ready for sending or connecting-org.apache.kafka.common.Node(name)node</parameter><constant>Removing node {} from least loaded node selection since it is neither ready for sending or connecting</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>678</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Found least loaded node {} with {} inflight requests-org.apache.kafka.common.Node(name)foundReady-int(name)inflight</parameter><constant>Found least loaded node {} with {} inflight requests</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>686</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Found least loaded connecting node {}-org.apache.kafka.common.Node(name)foundConnecting</parameter><constant>Found least loaded connecting node {}</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>689</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Found least loaded node {} with no active connection-org.apache.kafka.common.Node(name)foundCanConnect</parameter><constant>Found least loaded node {} with no active connection</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>692</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Least loaded node selection failed to find an available node</parameter><constant>Least loaded node selection failed to find an available node</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.leastLoadedNode</callsite><line>695</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.error</logcall> <parameter>java.lang.String(name)Connection to node {} ({}) failed authentication due to: {}-java.lang.String(name)nodeId-java.lang.String(name)disconnectState.remoteAddress()-java.lang.String(name)exception.getMessage()</parameter><constant>Connection to node {} ({}) failed authentication due to: {}</constant><level>error</level><callsite>org.apache.kafka.clients.NetworkClient.processDisconnection</callsite><line>737</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Connection to node {} ({}) terminated during authentication. This may happen due to any of the following reasons: (1) Authentication failed due to invalid credentials with brokers older than 1.0.0, (2) Firewall blocking Kafka TLS traffic (eg it may only allow HTTPS traffic), (3) Transient network issue.-java.lang.String(name)nodeId-java.lang.String(name)disconnectState.remoteAddress()</parameter><constant>Connection to node {} ({}) terminated during authentication. This may happen due to any of the following reasons: (1) Authentication failed due to invalid credentials with brokers older than 1.0.0, (2) Firewall blocking Kafka TLS traffic (eg it may only allow HTTPS traffic), (3) Transient network issue.</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.processDisconnection</callsite><line>741</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Connection to node {} ({}) could not be established. Broker may not be available.-java.lang.String(name)nodeId-java.lang.String(name)disconnectState.remoteAddress()</parameter><constant>Connection to node {} ({}) could not be established. Broker may not be available.</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.processDisconnection</callsite><line>748</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Cancelled request {} {} with correlation id {} due to node {} being disconnected-org.apache.kafka.common.protocol.ApiKeys(name)request.header.apiKey()-org.apache.kafka.common.requests.AbstractRequest(name)request.request-int(name)request.header.correlationId()-java.lang.String(name)nodeId</parameter><constant>Cancelled request {} {} with correlation id {} due to node {} being disconnected</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.processDisconnection</callsite><line>754</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Disconnecting from node {} due to request timeout.-java.lang.String(name)nodeId</parameter><constant>Disconnecting from node {} due to request timeout.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleTimedOutRequests</callsite><line>775</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Connection to node {} is throttled for {} ms until timestamp {}-java.lang.String(name)nodeId-int(name)throttleTimeMs-long(name)now + throttleTimeMs</parameter><constant>Connection to node {} is throttled for {} ms until timestamp {}</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.maybeThrottle</callsite><line>819</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Completed receive from node {} for {} with correlation id {}, received {}-java.lang.String(name)req.destination-org.apache.kafka.common.protocol.ApiKeys(name)req.header.apiKey()-int(name)req.header.correlationId()-org.apache.kafka.common.protocol.types.Struct(name)responseStruct</parameter><constant>Completed receive from node {} for {} with correlation id {}, received {}</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.handleCompletedReceives</callsite><line>837</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Received error {} from node {} when making an ApiVersionsRequest with correlation id {}. Disconnecting.-org.apache.kafka.common.protocol.Errors(name)apiVersionsResponse.error()-java.lang.String(name)node-int(name)req.header.correlationId()</parameter><constant>Received error {} from node {} when making an ApiVersionsRequest with correlation id {}. Disconnecting.</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse</callsite><line>858</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Recorded API versions for node {}: {}-java.lang.String(name)node-org.apache.kafka.clients.NodeApiVersions(name)nodeVersionInfo</parameter><constant>Recorded API versions for node {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleApiVersionsResponse</callsite><line>870</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Node {} disconnected.-java.lang.String(name)node</parameter><constant>Node {} disconnected.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleDisconnections</callsite><line>882</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Completed connection to node {}. Fetching API versions.-java.lang.String(name)node</parameter><constant>Completed connection to node {}. Fetching API versions.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleConnections</callsite><line>902</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Completed connection to node {}. Ready.-java.lang.String(name)node</parameter><constant>Completed connection to node {}. Ready.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleConnections</callsite><line>905</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Initiating API versions fetch from node {}.-java.lang.String(name)node</parameter><constant>Initiating API versions fetch from node {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.handleInitiateApiVersionRequests</callsite><line>916</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Initiating connection to node {} using address {}-org.apache.kafka.common.Node(name)node-java.net.InetAddress(name)address</parameter><constant>Initiating connection to node {} using address {}</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.initiateConnect</callsite><line>944</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Error connecting to node {}-org.apache.kafka.common.Node(name)node-java.io.IOException(name)e</parameter><constant>Error connecting to node {}</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.initiateConnect</callsite><line>950</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Give up sending metadata request since no node is available</parameter><constant>Give up sending metadata request since no node is available</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.maybeUpdate</callsite><line>1001</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Bootstrap broker {} disconnected-org.apache.kafka.common.Node(name)node</parameter><constant>Bootstrap broker {} disconnected</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.handleDisconnection</callsite><line>1019</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name){} partitions have leader brokers without a matching listener, including {}-int(name)count-java.util.List<TopicPartition>(name)missingListenerPartitions.subList(0,Math.min(10,count))</parameter><constant>{} partitions have leader brokers without a matching listener, including {}</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.handleCompletedMetadataResponse</callsite><line>1044</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Error while fetching metadata with correlation id {} : {}-int(name)requestHeader.correlationId()-java.util.Map<String,Errors>(name)errors</parameter><constant>Error while fetching metadata with correlation id {} : {}</constant><level>warn</level><callsite>org.apache.kafka.clients.NetworkClient.handleCompletedMetadataResponse</callsite><line>1051</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Ignoring empty metadata response with correlation id {}.-int(name)requestHeader.correlationId()</parameter><constant>Ignoring empty metadata response with correlation id {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.NetworkClient.handleCompletedMetadataResponse</callsite><line>1056</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Sending metadata request {} to node {}-org.apache.kafka.common.requests.Builder(name)metadataRequest-org.apache.kafka.common.Node(name)node</parameter><constant>Sending metadata request {} to node {}</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.maybeUpdate</callsite><line>1097</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Initialize connection to node {} for sending metadata request-org.apache.kafka.common.Node(name)node</parameter><constant>Initialize connection to node {} for sending metadata request</constant><level>debug</level><callsite>org.apache.kafka.clients.NetworkClient.maybeUpdate</callsite><line>1113</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Disabling exponential reconnect backoff because {} is set, but {} is not.-java.lang.String(name)reconnect.backoff.ms-java.lang.String(name)reconnect.backoff.max.ms</parameter><constant>Disabling exponential reconnect backoff because {} is set, but {} is not.reconnect.backoff.msreconnect.backoff.max.ms</constant><level>debug</level><callsite>org.apache.kafka.clients.CommonClientConfigs.postProcessReconnectBackoffConfigs</callsite><line>155</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Couldn't resolve server {} from {} as DNS resolution of the canonical hostname [} failed for {}-java.lang.String(name)url-java.lang.String(name)bootstrap.servers-java.lang.String(name)resolvedCanonicalName-java.lang.String(name)host</parameter><constant>Couldn't resolve server {} from {} as DNS resolution of the canonical hostname [} failed for {}bootstrap.servers</constant><level>warn</level><callsite>org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses</callsite><line>66</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.warn</logcall> <parameter>java.lang.String(name)Couldn't resolve server {} from {} as DNS resolution failed for {}-java.lang.String(name)url-java.lang.String(name)bootstrap.servers-java.lang.String(name)host</parameter><constant>Couldn't resolve server {} from {} as DNS resolution failed for {}bootstrap.servers</constant><level>warn</level><callsite>org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses</callsite><line>74</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)An error occurred in broker-to-broker communication.-org.apache.kafka.common.KafkaException(name)exception</parameter><constant>An error occurred in broker-to-broker communication.</constant><level>debug</level><callsite>org.apache.kafka.clients.ManualMetadataUpdater.handleFatalException</callsite><line>80</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Built full fetch {} for node {} with {}.-org.apache.kafka.common.requests.FetchMetadata(name)nextMetadata-int(name)node-java.lang.String(name)partitionsToLogString(next.keySet())</parameter><constant>Built full fetch {} for node {} with {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.build</callsite><line>200</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Built incremental fetch {} for node {}. Added {}, altered {}, removed {} out of {}-org.apache.kafka.common.requests.FetchMetadata(name)nextMetadata-int(name)node-java.lang.String(name)partitionsToLogString(added)-java.lang.String(name)partitionsToLogString(altered)-java.lang.String(name)partitionsToLogString(removed)-java.lang.String(name)partitionsToLogString(sessionPartitions.keySet())</parameter><constant>Built incremental fetch {} for node {}. Added {}, altered {}, removed {} out of {}</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.build</callsite><line>253</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Node {} was unable to process the fetch request with {}: {}.-int(name)node-org.apache.kafka.common.requests.FetchMetadata(name)nextMetadata-org.apache.kafka.common.protocol.Errors(name)response.error()</parameter><constant>Node {} was unable to process the fetch request with {}: {}.</constant><level>info</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>385</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Node {} sent an invalid full fetch response with {}-int(name)node-java.lang.String(name)problem</parameter><constant>Node {} sent an invalid full fetch response with {}</constant><level>info</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>396</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Node {} sent a full fetch response{}-int(name)node-java.lang.String(name)responseDataToLogString(response)</parameter><constant>Node {} sent a full fetch response{}</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>400</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Node {} sent a full fetch response that created a new incremental fetch session {}{}-int(name)node-int(name)response.sessionId()-java.lang.String(name)responseDataToLogString(response)</parameter><constant>Node {} sent a full fetch response that created a new incremental fetch session {}{}</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>406</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Node {} sent an invalid incremental fetch response with {}-int(name)node-java.lang.String(name)problem</parameter><constant>Node {} sent an invalid incremental fetch response with {}</constant><level>info</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>414</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Node {} sent an incremental fetch response closing session {}{}-int(name)node-int(name)nextMetadata.sessionId()-java.lang.String(name)responseDataToLogString(response)</parameter><constant>Node {} sent an incremental fetch response closing session {}{}</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>419</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Node {} sent an incremental fetch response for session {}{}-int(name)node-int(name)response.sessionId()-java.lang.String(name)responseDataToLogString(response)</parameter><constant>Node {} sent an incremental fetch response for session {}{}</constant><level>debug</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleResponse</callsite><line>425</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Error sending fetch request {} to node {}: {}.-org.apache.kafka.common.requests.FetchMetadata(name)nextMetadata-int(name)node-java.lang.String(name)t.toString()</parameter><constant>Error sending fetch request {} to node {}: {}.</constant><level>info</level><callsite>org.apache.kafka.clients.FetchSessionHandler.handleError</callsite><line>442</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.trace</logcall> <parameter>java.lang.String(name)Determining if we should replace existing epoch {} with new epoch {}-java.lang.Integer(name)oldEpoch-int(name)epoch</parameter><constant>Determining if we should replace existing epoch {} with new epoch {}</constant><level>trace</level><callsite>org.apache.kafka.clients.Metadata.updateLastSeenEpoch</callsite><line>171</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Updating last seen epoch from {} to {} for partition {}-java.lang.Integer(name)oldEpoch-int(name)epoch-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Updating last seen epoch from {} to {} for partition {}</constant><level>debug</level><callsite>org.apache.kafka.clients.Metadata.updateLastSeenEpoch</callsite><line>173</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Not replacing existing epoch {} with new epoch {} for partition {}-java.lang.Integer(name)oldEpoch-int(name)epoch-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Not replacing existing epoch {} with new epoch {} for partition {}</constant><level>debug</level><callsite>org.apache.kafka.clients.Metadata.updateLastSeenEpoch</callsite><line>180</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.info</logcall> <parameter>java.lang.String(name)Cluster ID: {}-java.lang.String(name)newClusterId</parameter><constant>Cluster ID: {}</constant><level>info</level><callsite>org.apache.kafka.clients.Metadata.update</callsite><line>266</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Updated cluster metadata updateVersion {} to {}-int(name)this.updateVersion-org.apache.kafka.clients.MetadataCache(name)this.cache</parameter><constant>Updated cluster metadata updateVersion {} to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.Metadata.update</callsite><line>270</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.error</logcall> <parameter>java.lang.String(name)Metadata response reported invalid topics {}-java.util.Set<String>(name)cluster.invalidTopics()</parameter><constant>Metadata response reported invalid topics {}</constant><level>error</level><callsite>org.apache.kafka.clients.Metadata.checkInvalidTopics</callsite><line>282</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.error</logcall> <parameter>java.lang.String(name)Topic authorization failed for topics {}-java.util.Set<String>(name)cluster.unauthorizedTopics()</parameter><constant>Topic authorization failed for topics {}</constant><level>error</level><callsite>org.apache.kafka.clients.Metadata.checkUnauthorizedTopics</callsite><line>290</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting metadata update for partition {} due to error {}-org.apache.kafka.common.TopicPartition(name)new TopicPartition(metadata.topic(),partitionMetadata.partition())-org.apache.kafka.common.protocol.Errors(name)partitionMetadata.error()</parameter><constant>Requesting metadata update for partition {} due to error {}</constant><level>debug</level><callsite>org.apache.kafka.clients.Metadata.handleMetadataResponse</callsite><line>319</line><superclass>null</superclass><logcall>org.apache.kafka.clients.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting metadata update for topic {} due to error {}-java.lang.String(name)metadata.topic()-org.apache.kafka.common.protocol.Errors(name)metadata.error()</parameter><constant>Requesting metadata update for topic {} due to error {}</constant><level>debug</level><callsite>org.apache.kafka.clients.Metadata.handleMetadataResponse</callsite><line>325</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka admin client initialized</parameter><constant>Kafka admin client initialized</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.KafkaAdminClient</callsite><line>458</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Initiating close operation.</parameter><constant>Initiating close operation.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>478</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Moving hard shutdown time forward.</parameter><constant>Moving hard shutdown time forward.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>480</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Hard shutdown time is already earlier than requested.</parameter><constant>Hard shutdown time is already earlier than requested.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>487</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Waiting for the I/O thread to exit. Hard shutdown in {} ms.-long(name)deltaMs</parameter><constant>Waiting for the I/O thread to exit. Hard shutdown in {} ms.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>494</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka admin client closed.</parameter><constant>Kafka admin client closed.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>502</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Interrupted while joining I/O thread-java.lang.InterruptedException(name)e</parameter><constant>Interrupted while joining I/O thread</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.close</callsite><line>504</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} aborted at {} after {} attempt(s)-org.apache.kafka.clients.admin.Call(name)this-long(name)now-int(name)tries-java.lang.Exception(name)new Exception(prettyPrintException(throwable))</parameter><constant>{} aborted at {} after {} attempt(s)</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>618</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} attempting protocol downgrade and then retry.-org.apache.kafka.clients.admin.Call(name)this</parameter><constant>{} attempting protocol downgrade and then retry.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>629</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} timed out at {} after {} attempt(s)-org.apache.kafka.clients.admin.Call(name)this-long(name)now-int(name)tries-java.lang.Exception(name)new Exception(prettyPrintException(throwable))</parameter><constant>{} timed out at {} after {} attempt(s)</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>639</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} failed with non-retriable exception after {} attempt(s)-org.apache.kafka.clients.admin.Call(name)this-int(name)tries-java.lang.Exception(name)new Exception(prettyPrintException(throwable))</parameter><constant>{} failed with non-retriable exception after {} attempt(s)</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>648</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} failed after {} attempt(s)-org.apache.kafka.clients.admin.Call(name)this-int(name)tries-java.lang.Exception(name)new Exception(prettyPrintException(throwable))</parameter><constant>{} failed after {} attempt(s)</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>657</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name){} failed: {}. Beginning retry #{}-org.apache.kafka.clients.admin.Call(name)this-java.lang.String(name)prettyPrintException(throwable)-int(name)tries</parameter><constant>{} failed: {}. Beginning retry #{}</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.fail</callsite><line>664</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Timed out {} pending calls.-int(name)numTimedOut</parameter><constant>Timed out {} pending calls.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.timeoutPendingCalls</callsite><line>828</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Timed out {} call(s) with assigned nodes.-int(name)numTimedOut</parameter><constant>Timed out {} call(s) with assigned nodes.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.timeoutCallsToSend</callsite><line>843</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Trying to choose nodes for {} at {}-java.util.ArrayList<Call>(name)pendingCalls-long(name)now</parameter><constant>Trying to choose nodes for {} at {}</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.maybeDrainPendingCalls</callsite><line>869</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Assigned {} to node {}-org.apache.kafka.clients.admin.Call(name)call-org.apache.kafka.common.Node(name)node</parameter><constant>Assigned {} to node {}</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.maybeDrainPendingCall</callsite><line>894</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Unable to assign {} to a node.-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>Unable to assign {} to a node.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.maybeDrainPendingCall</callsite><line>899</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Unable to choose node for {}-org.apache.kafka.clients.admin.Call(name)call-java.lang.Throwable(name)t</parameter><constant>Unable to choose node for {}</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.maybeDrainPendingCall</callsite><line>904</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Client is not ready to send to {}. Must delay {} ms-org.apache.kafka.common.Node(name)node-long(name)nodeTimeout</parameter><constant>Client is not ready to send to {}. Must delay {} ms</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.sendEligibleCalls</callsite><line>929</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Sending {} to {}. correlationId={}-org.apache.kafka.common.requests.Builder<>(name)requestBuilder-org.apache.kafka.common.Node(name)node-int(name)clientRequest.correlationId()</parameter><constant>Sending {} to {}. correlationId={}</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.sendEligibleCalls</callsite><line>943</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.warn</logcall> <parameter>java.lang.String(name)Aborted call {} is still in callsInFlight.-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>Aborted call {} is still in callsInFlight.</constant><level>warn</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.timeoutCallsInFlight</callsite><line>972</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Closing connection to {} to time out {}-java.lang.String(name)nodeId-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>Closing connection to {} to time out {}</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.timeoutCallsInFlight</callsite><line>974</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Timed out {} call(s) in flight.-int(name)numTimedOut</parameter><constant>Timed out {} call(s) in flight.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.timeoutCallsInFlight</callsite><line>985</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.error</logcall> <parameter>java.lang.String(name)Internal server error on {}: server returned information about unknown correlation ID {}, requestHeader = {}-java.lang.String(name)response.destination()-int(name)correlationId-org.apache.kafka.common.requests.RequestHeader(name)response.requestHeader()</parameter><constant>Internal server error on {}: server returned information about unknown correlation ID {}, requestHeader = {}</constant><level>error</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.handleResponses</callsite><line>1002</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.error</logcall> <parameter>java.lang.String(name)Internal server error on {}: ignoring call {} in correlationIdToCall that did not exist in callsInFlight-java.lang.String(name)response.destination()-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>Internal server error on {}: ignoring call {} in correlationIdToCall that did not exist in callsInFlight</constant><level>error</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.handleResponses</callsite><line>1013</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name){} got response {}-org.apache.kafka.clients.admin.Call(name)call-java.lang.String(name)response.responseBody().toString(response.requestHeader().apiVersion())</parameter><constant>{} got response {}</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.handleResponses</callsite><line>1035</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name){} handleResponse failed with {}-org.apache.kafka.clients.admin.Call(name)call-java.lang.String(name)prettyPrintException(t)</parameter><constant>{} handleResponse failed with {}</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.handleResponses</callsite><line>1039</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)All work has been completed, and the I/O thread is now exiting.</parameter><constant>All work has been completed, and the I/O thread is now exiting.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.threadShouldExit</callsite><line>1094</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.info</logcall> <parameter>java.lang.String(name)Forcing a hard I/O thread shutdown. Requests in progress will be aborted.</parameter><constant>Forcing a hard I/O thread shutdown. Requests in progress will be aborted.</constant><level>info</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.threadShouldExit</callsite><line>1098</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Hard shutdown in {} ms.-long(name)curHardShutdownTimeMs - now</parameter><constant>Hard shutdown in {} ms.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.threadShouldExit</callsite><line>1101</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Thread starting</parameter><constant>Thread starting</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.run</callsite><line>1108</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)Entering KafkaClient#poll(timeout={})-long(name)pollTimeout</parameter><constant>Entering KafkaClient#poll(timeout={})</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.run</callsite><line>1152</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.trace</logcall> <parameter>java.lang.String(name)KafkaClient#poll retrieved {} response(s)-int(name)responses.size()</parameter><constant>KafkaClient#poll retrieved {} response(s)</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.run</callsite><line>1154</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Timed out {} remaining operation(s).-int(name)numTimedOut</parameter><constant>Timed out {} remaining operation(s).</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.run</callsite><line>1174</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Exiting AdminClientRunnable thread.</parameter><constant>Exiting AdminClientRunnable thread.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.run</callsite><line>1178</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)Queueing {} with a timeout {} ms from now.-org.apache.kafka.clients.admin.Call(name)call-long(name)call.deadlineMs - now</parameter><constant>Queueing {} with a timeout {} ms from now.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.enqueue</callsite><line>1193</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)The AdminClient thread has exited. Timing out {}.-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>The AdminClient thread has exited. Timing out {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.enqueue</callsite><line>1205</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.debug</logcall> <parameter>java.lang.String(name)The AdminClient is not accepting new calls. Timing out {}.-org.apache.kafka.clients.admin.Call(name)call</parameter><constant>The AdminClient is not accepting new calls. Timing out {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.call</callsite><line>1220</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.info</logcall> <parameter>java.lang.String(name)Node {} is no longer the Coordinator. Retrying with new coordinator.-org.apache.kafka.common.Node(name)context.getNode().orElse(null)</parameter><constant>Node {} is no longer the Coordinator. Retrying with new coordinator.</constant><level>info</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.rescheduleTask</callsite><line>2582</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping return offset for {} due to error {}.-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Skipping return offset for {} due to error {}.</constant><level>warn</level><callsite>org.apache.kafka.clients.admin.KafkaAdminClient.getListConsumerGroupOffsetsCall</callsite><line>2954</line><superclass>org.apache.kafka.clients.admin.AdminClient</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Metadata is not usable: failed to get metadata.-org.apache.kafka.common.errors.AuthenticationException(name)authException</parameter><constant>Metadata is not usable: failed to get metadata.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.isReady</callsite><line>149</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Metadata is not ready: bootstrap nodes have not been initialized yet.</parameter><constant>Metadata is not ready: bootstrap nodes have not been initialized yet.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.isReady</callsite><line>153</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.</parameter><constant>Metadata is not ready: we have not fetched metadata from the bootstrap nodes yet.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.isReady</callsite><line>158</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Metadata is ready to use.</parameter><constant>Metadata is ready to use.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.isReady</callsite><line>162</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting metadata update.</parameter><constant>Requesting metadata update.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.requestUpdate</callsite><line>177</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Clearing cached controller node {}.-org.apache.kafka.common.Node(name)cluster.controller()</parameter><constant>Clearing cached controller node {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.clearController</callsite><line>183</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Metadata update failed due to authentication error-java.lang.Throwable(name)exception</parameter><constant>Metadata update failed due to authentication error</constant><level>warn</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.updateFailed</callsite><line>235</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.info</logcall> <parameter>java.lang.String(name)Metadata update failed-java.lang.Throwable(name)exception</parameter><constant>Metadata update failed</constant><level>info</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.updateFailed</callsite><line>238</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Setting bootstrap cluster metadata {}.-org.apache.kafka.common.Cluster(name)cluster</parameter><constant>Setting bootstrap cluster metadata {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.update</callsite><line>248</line><superclass>null</superclass><logcall>org.apache.kafka.clients.admin.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Updating cluster metadata to {}-org.apache.kafka.common.Cluster(name)cluster</parameter><constant>Updating cluster metadata to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.admin.internals.AdminMetadataManager.update</callsite><line>250</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.warn</logcall> <parameter>java.lang.String(name)Partition '{}' is assigned to multiple consumers following sticky assignment generation {}.-org.apache.kafka.common.TopicPartition(name)partition-java.util.Optional<Integer>(name)consumerUserData.generation</parameter><constant>Partition '{}' is assigned to multiple consumers following sticky assignment generation {}.</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.prepopulateCurrentAssignments</callsite><line>335</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name){} is assigned to more than one consumer.-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>{} is assigned to more than one consumer.</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.isBalanced</callsite><line>415</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name){} can be moved from consumer {} to consumer {} for a more balanced assignment.-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.String(name)otherConsumer-java.lang.String(name)consumer</parameter><constant>{} can be moved from consumer {} to consumer {} for a more balanced assignment.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.isBalanced</callsite><line>437</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)The consumer {} is assigned more partitions than the maximum possible.-java.lang.String(name)consumer</parameter><constant>The consumer {} is assigned more partitions than the maximum possible.</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.canParticipateInReassignment</callsite><line>597</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)Expected more than one potential consumer for partition '{}'-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Expected more than one potential consumer for partition '{}'</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.performReassignments</callsite><line>698</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)Expected partition '{}' to be assigned to a consumer-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Expected partition '{}' to be assigned to a consumer</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.performReassignments</callsite><line>703</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)A cycle of length {} was found: {}-int(name)path.size() - 1-java.lang.String(name)path.toString()</parameter><constant>A cycle of length {} was found: {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.hasCycles</callsite><line>1011</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)Stickiness is violated for topic {} Partition movements for this topic occurred among the following consumer pairs: {}-java.lang.String(name)topicMovements.getKey()-java.lang.String(name)topicMovements.getValue().toString()</parameter><constant>Stickiness is violated for topic {} Partition movements for this topic occurred among the following consumer pairs: {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.StickyAssignor.isSticky</callsite><line>1028</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor</superclass><logcall>org.apache.kafka.clients.consumer.Logger.warn</logcall> <parameter>java.lang.String(name)Support for using the empty group id by consumers is deprecated and will be removed in the next major release.</parameter><constant>Support for using the empty group id by consumers is deprecated and will be removed in the next major release.</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.KafkaConsumer</callsite><line>694</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Initializing the Kafka consumer</parameter><constant>Initializing the Kafka consumer</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.KafkaConsumer</callsite><line>696</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka consumer initialized</parameter><constant>Kafka consumer initialized</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.KafkaConsumer</callsite><line>811</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Subscribed to topic(s): {}-java.lang.String(name)Utils.join(topics,", ")</parameter><constant>Subscribed to topic(s): {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.subscribe</callsite><line>953</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Subscribed to pattern: '{}'-java.util.regex.Pattern(name)pattern</parameter><constant>Subscribed to pattern: '{}'</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.subscribe</callsite><line>1016</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Unsubscribed all topics or patterns and assigned partitions</parameter><constant>Unsubscribed all topics or patterns and assigned partitions</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.unsubscribe</callsite><line>1057</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Subscribed to partition(s): {}-java.lang.String(name)Utils.join(partitions,", ")</parameter><constant>Subscribed to partition(s): {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.assign</callsite><line>1103</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.warn</logcall> <parameter>java.lang.String(name)Still waiting for metadata</parameter><constant>Still waiting for metadata</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.poll</callsite><line>1210</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Committing offsets: {}-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets</parameter><constant>Committing offsets: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.commitAsync</callsite><line>1511</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Seeking to offset {} for partition {}-long(name)offset-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Seeking to offset {} for partition {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.seek</callsite><line>1534</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Seeking to offset {} for partition {} with epoch {}-long(name)offset-org.apache.kafka.common.TopicPartition(name)partition-java.lang.Integer(name)offsetAndMetadata.leaderEpoch().get()</parameter><constant>Seeking to offset {} for partition {} with epoch {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.seek</callsite><line>1564</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.info</logcall> <parameter>java.lang.String(name)Seeking to offset {} for partition {}-long(name)offset-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Seeking to offset {} for partition {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.seek</callsite><line>1567</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Pausing partitions {}-java.util.Collection<TopicPartition>(name)partitions</parameter><constant>Pausing partitions {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.pause</callsite><line>1896</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Resuming partitions {}-java.util.Collection<TopicPartition>(name)partitions</parameter><constant>Resuming partitions {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.resume</callsite><line>1916</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.trace</logcall> <parameter>java.lang.String(name)Closing the Kafka consumer</parameter><constant>Closing the Kafka consumer</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.close</callsite><line>2194</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close coordinator-java.lang.Throwable(name)t</parameter><constant>Failed to close coordinator</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.close</callsite><line>2201</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka consumer has been closed</parameter><constant>Kafka consumer has been closed</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.KafkaConsumer.close</callsite><line>2210</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Missing partition {} from response, ignoring-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Missing partition {} from response, ignoring</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>71</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Handling OffsetsForLeaderEpoch response for {}. Got offset {} for epoch {}-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)epochEndOffset.endOffset()-int(name)epochEndOffset.leaderEpoch()</parameter><constant>Handling OffsetsForLeaderEpoch response for {}. Got offset {} for epoch {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>77</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Attempt to fetch offsets for partition {} failed due to {}, retrying.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>85</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Attempt to fetch offsets for partition {} failed due to {}, retrying.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>90</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Received unknown topic or partition error in ListOffset request for partition {}-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Received unknown topic or partition error in ListOffset request for partition {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>94</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to: {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.String(name)error.message()</parameter><constant>Attempt to fetch offsets for partition {} failed due to: {}, retrying.</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient.handleResponse</callsite><line>99</line><superclass>org.apache.kafka.clients.consumer.internals.AsyncClient</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onConsume callback-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onConsume callback</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerInterceptors.onConsume</callsite><line>64</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onCommit callback-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onCommit callback</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerInterceptors.onCommit</callsite><line>85</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close consumer interceptor -java.lang.Exception(name)e</parameter><constant>Failed to close consumer interceptor </constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerInterceptors.close</callsite><line>99</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Assigned partition {} for non-subscribed topic regex pattern; subscription pattern is {}-org.apache.kafka.common.TopicPartition(name)topicPartition-java.util.regex.Pattern(name)this.subscribedPattern</parameter><constant>Assigned partition {} for non-subscribed topic regex pattern; subscription pattern is {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.assignFromSubscribed</callsite><line>250</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Assigned partition {} for non-subscribed topic; subscription is {}-org.apache.kafka.common.TopicPartition(name)topicPartition-java.util.Set<String>(name)this.subscription</parameter><constant>Assigned partition {} for non-subscribed topic; subscription is {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.assignFromSubscribed</callsite><line>258</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping reset of partition {} since it is no longer assigned-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Skipping reset of partition {} since it is no longer assigned</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeSeekUnvalidated</callsite><line>368</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping reset of partition {} since reset is no longer needed-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Skipping reset of partition {} since reset is no longer needed</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeSeekUnvalidated</callsite><line>370</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping reset of partition {} since an alternative reset has been requested-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Skipping reset of partition {} since an alternative reset has been requested</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeSeekUnvalidated</callsite><line>372</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Resetting offset for partition {} to offset {}.-org.apache.kafka.common.TopicPartition(name)tp-long(name)offset</parameter><constant>Resetting offset for partition {} to offset {}.</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeSeekUnvalidated</callsite><line>374</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping completed validation for partition {} which is not currently assigned.-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Skipping completed validation for partition {} which is not currently assigned.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeCompleteValidation</callsite><line>422</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping completed validation for partition {} which is no longer expecting validation.-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Skipping completed validation for partition {} which is no longer expecting validation.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeCompleteValidation</callsite><line>424</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping completed validation for partition {} since the current position {} no longer matches the position {} when the request was sent-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.clients.consumer.internals.FetchPosition(name)currentPosition-org.apache.kafka.clients.consumer.internals.FetchPosition(name)requestPosition</parameter><constant>Skipping completed validation for partition {} since the current position {} no longer matches the position {} when the request was sent</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeCompleteValidation</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Truncation detected for partition {} at offset {}, resetting offset to the first offset known to diverge {}-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.clients.consumer.internals.FetchPosition(name)currentPosition-org.apache.kafka.clients.consumer.internals.FetchPosition(name)newPosition</parameter><constant>Truncation detected for partition {} at offset {}, resetting offset to the first offset known to diverge {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeCompleteValidation</callsite><line>436</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Truncation detected for partition {} at offset {} (the end offset from the broker is {}), but no reset policy is set-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.clients.consumer.internals.FetchPosition(name)currentPosition-org.apache.kafka.common.requests.EpochEndOffset(name)epochEndOffset</parameter><constant>Truncation detected for partition {} at offset {} (the end offset from the broker is {}), but no reset policy is set</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.SubscriptionState.maybeCompleteValidation</callsite><line>440</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping assignment for topic {} since no metadata is available-java.lang.String(name)topic</parameter><constant>Skipping assignment for topic {} since no metadata is available</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor.assign</callsite><line>66</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received user wakeup</parameter><constant>Received user wakeup</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.wakeup</callsite><line>186</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Raising WakeupException in response to user wakeup</parameter><constant>Raising WakeupException in response to user wakeup</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup</callsite><line>488</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Cancelled request with header {} due to node {} being disconnected-org.apache.kafka.common.requests.RequestHeader(name)response.requestHeader()-java.lang.String(name)response.destination()</parameter><constant>Cancelled request with header {} due to node {} being disconnected</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.fireCompletion</callsite><line>572</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Joining group with current subscription: {}-java.util.Set<String>(name)subscriptions.subscription()</parameter><constant>Joining group with current subscription: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.metadata</callsite><line>200</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)We received an assignment {} that doesn't match our current subscription {}; it is likely that the subscription has changed since we joined the group. Will try re-join the group with current subscription-java.util.List<TopicPartition>(name)assignment.partitions()-java.lang.String(name)subscriptions.prettyString()</parameter><constant>We received an assignment {} that doesn't match our current subscription {}; it is likely that the subscription has changed since we joined the group. Will try re-join the group with current subscription</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete</callsite><line>272</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Coordinator has owned partitions {} that are not revoked with {} protocol, it is likely client is woken up before a previous pending rebalance completes its callback-java.util.Set<TopicPartition>(name)ownedPartitions-org.apache.kafka.clients.consumer.internals.RebalanceProtocol(name)protocol</parameter><constant>Coordinator has owned partitions {} that are not revoked with {} protocol, it is likely client is woken up before a previous pending rebalance completes its callback</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete</callsite><line>300</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Setting newly assigned partitions: {}-java.lang.String(name)Utils.join(assignedPartitions,", ")</parameter><constant>Setting newly assigned partitions: {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete</callsite><line>304</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)User provided listener {} failed on partition assignment-java.lang.String(name)listener.getClass().getName()-java.lang.Exception(name)e</parameter><constant>User provided listener {} failed on partition assignment</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinComplete</callsite><line>310</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Updating with newly assigned partitions: {}, compare with already owned partitions: {}, newly added partitions: {}, revoking partitions: {}-java.lang.String(name)Utils.join(assignedPartitions,", ")-java.lang.String(name)Utils.join(ownedPartitions,", ")-java.lang.String(name)Utils.join(addedPartitions,", ")-java.lang.String(name)Utils.join(revokedPartitions,", ")</parameter><constant>Updating with newly assigned partitions: {}, compare with already owned partitions: {}, newly added partitions: {}, revoking partitions: {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.assignAndRevoke</callsite><line>334</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)User provided listener {} failed on partition assignment-java.lang.String(name)listener.getClass().getName()-java.lang.Exception(name)e</parameter><constant>User provided listener {} failed on partition assignment</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.assignAndRevoke</callsite><line>346</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)User provided listener {} failed on partition revocation-java.lang.String(name)listener.getClass().getName()-java.lang.Exception(name)e</parameter><constant>User provided listener {} failed on partition revocation</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.assignAndRevoke</callsite><line>354</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Performing assignment using strategy {} with subscriptions {}-java.lang.String(name)assignor.name()-java.util.Map<String,Subscription>(name)subscriptions</parameter><constant>Performing assignment using strategy {} with subscriptions {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment</callsite><line>495</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)The following subscribed topics are not assigned to any members: {} -java.util.Set<String>(name)notAssignedTopics</parameter><constant>The following subscribed topics are not assigned to any members: {} </constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment</callsite><line>524</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: {}-java.util.Set<String>(name)newlyAddedTopics</parameter><constant>The following not-subscribed topics are assigned, and their metadata will be fetched from the brokers: {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment</callsite><line>530</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Finished assignment for group: {}-java.util.Map<String,Assignment>(name)assignments</parameter><constant>Finished assignment for group: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.performAssignment</callsite><line>539</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Revoking previously assigned partitions {}-java.util.Set<TopicPartition>(name)revokedPartitions</parameter><constant>Revoking previously assigned partitions {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare</callsite><line>595</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)User provided listener {} failed on partition revocation-java.lang.String(name)listener.getClass().getName()-java.lang.Exception(name)e</parameter><constant>User provided listener {} failed on partition revocation</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onJoinPrepare</callsite><line>601</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Setting offset for partition {} to the committed offset {}-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position</parameter><constant>Setting offset for partition {} to the committed offset {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded</callsite><line>653</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending asynchronous auto-commit of offsets {}-java.util.Map<TopicPartition,OffsetAndMetadata>(name)allConsumedOffsets</parameter><constant>Sending asynchronous auto-commit of offsets {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.doAutoCommitOffsetsAsync</callsite><line>857</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending synchronous auto-commit of offsets {}-java.util.Map<TopicPartition,OffsetAndMetadata>(name)allConsumedOffsets</parameter><constant>Sending synchronous auto-commit of offsets {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsSync</callsite><line>878</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Auto-commit of offsets {} timed out before completion-java.util.Map<TopicPartition,OffsetAndMetadata>(name)allConsumedOffsets</parameter><constant>Auto-commit of offsets {} timed out before completion</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsSync</callsite><line>880</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Auto-commit of offsets {} was interrupted before completion-java.util.Map<TopicPartition,OffsetAndMetadata>(name)allConsumedOffsets</parameter><constant>Auto-commit of offsets {} was interrupted before completion</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsSync</callsite><line>882</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Synchronous auto-commit of offsets {} failed: {}-java.util.Map<TopicPartition,OffsetAndMetadata>(name)allConsumedOffsets-java.lang.String(name)e.getMessage()</parameter><constant>Synchronous auto-commit of offsets {} failed: {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsSync</callsite><line>887</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Offset commit with offsets {} failed-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets-java.lang.Exception(name)exception</parameter><constant>Offset commit with offsets {} failed</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.onComplete</callsite><line>896</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failing OffsetCommit request since the consumer is not part of an active group</parameter><constant>Failing OffsetCommit request since the consumer is not part of an active group</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest</callsite><line>946</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Sending OffsetCommit request with {} to coordinator {}-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets-org.apache.kafka.common.Node(name)coordinator</parameter><constant>Sending OffsetCommit request with {} to coordinator {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest</callsite><line>961</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Committed offset {} for partition {}-long(name)offset-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Committed offset {} for partition {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>989</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Offset commit failed on partition {} at offset {}: {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)offset-java.lang.String(name)error.message()</parameter><constant>Offset commit failed on partition {} at offset {}: {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>992</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Offset commit failed on partition {} at offset {}: {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)offset-java.lang.String(name)error.message()</parameter><constant>Offset commit failed on partition {} at offset {}: {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>994</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Received fatal exception: group.instance.id gets fenced</parameter><constant>Received fatal exception: group.instance.id gets fenced</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>1019</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Not authorized to commit to topics {}-java.util.Set<String>(name)unauthorizedTopics</parameter><constant>Not authorized to commit to topics {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>1048</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Fetching committed offsets for partitions: {}-java.util.Set<TopicPartition>(name)partitions</parameter><constant>Fetching committed offsets for partitions: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetFetchRequest</callsite><line>1068</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Offset fetch failed: {}-java.lang.String(name)error.message()</parameter><constant>Offset fetch failed: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>1083</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Failed to fetch offset for partition {}: {}-org.apache.kafka.common.TopicPartition(name)tp-java.lang.String(name)error.message()</parameter><constant>Failed to fetch offset for partition {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>1107</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Found no committed offset for partition {}-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Found no committed offset for partition {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.handle</callsite><line>1126</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending {} {} to broker {}-org.apache.kafka.common.requests.IsolationLevel(name)isolationLevel-java.lang.String(name)data.toString()-org.apache.kafka.common.Node(name)fetchTarget</parameter><constant>Sending {} {} to broker {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches</callsite><line>248</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unable to find FetchSessionHandler for node {}. Ignoring fetch response.-int(name)fetchTarget.id()</parameter><constant>Unable to find FetchSessionHandler for node {}. Ignoring fetch response.</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches</callsite><line>260</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Fetch {} at offset {} for partition {} returned fetch data {}-org.apache.kafka.common.requests.IsolationLevel(name)isolationLevel-long(name)fetchOffset-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.common.requests.PartitionData<Records>(name)fetchData</parameter><constant>Fetch {} at offset {} for partition {} returned fetch data {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.sendFetches</callsite><line>292</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Topic metadata fetch included errors: {}-java.util.Map<String,Errors>(name)errors</parameter><constant>Topic metadata fetch included errors: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.getTopicMetadata</callsite><line>368</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Not returning fetched records for partition {} since it is no longer assigned-org.apache.kafka.common.TopicPartition(name)partitionRecords.partition</parameter><constant>Not returning fetched records for partition {} since it is no longer assigned</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords</callsite><line>633</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Not returning fetched records for assigned partition {} since it is no longer fetchable-org.apache.kafka.common.TopicPartition(name)partitionRecords.partition</parameter><constant>Not returning fetched records for assigned partition {} since it is no longer fetchable</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords</callsite><line>638</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Returning fetched records at offset {} for assigned partition {} and update position to {}-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position-org.apache.kafka.common.TopicPartition(name)partitionRecords.partition-org.apache.kafka.clients.consumer.internals.FetchPosition(name)nextPosition</parameter><constant>Returning fetched records at offset {} for assigned partition {} and update position to {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords</callsite><line>650</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Ignoring fetched records for {} at offset {} since the current position is {}-org.apache.kafka.common.TopicPartition(name)partitionRecords.partition-long(name)partitionRecords.nextFetchOffset-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position</parameter><constant>Ignoring fetched records for {} at offset {} since the current position is {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.fetchRecords</callsite><line>668</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Discarding error in ListOffsetResponse because another error is pending-java.lang.RuntimeException(name)e</parameter><constant>Discarding error in ListOffsetResponse because another error is pending</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.resetOffsetsAsync</callsite><line>715</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Leader for partition {} is unknown for fetching offset {}-org.apache.kafka.common.TopicPartition(name)tp-java.lang.Long(name)offset</parameter><constant>Leader for partition {} is unknown for fetching offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.groupListOffsetRequests</callsite><line>869</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Leader for partition {} is unavailable for fetching offset {}-org.apache.kafka.common.TopicPartition(name)tp-java.lang.Long(name)offset</parameter><constant>Leader for partition {} is unavailable for fetching offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.groupListOffsetRequests</callsite><line>873</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires-org.apache.kafka.common.Node(name)currentInfo.get().partitionInfo().leader()-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.groupListOffsetRequests</callsite><line>882</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending ListOffsetRequest {} to broker {}-org.apache.kafka.common.requests.Builder(name)builder-org.apache.kafka.common.Node(name)node</parameter><constant>Sending ListOffsetRequest {} to broker {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.sendListOffsetRequest</callsite><line>908</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Received ListOffsetResponse {} from broker {}-org.apache.kafka.common.requests.ListOffsetResponse(name)lor-org.apache.kafka.common.Node(name)node</parameter><constant>Received ListOffsetResponse {} from broker {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.sendListOffsetRequest</callsite><line>914</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Handling v0 ListOffsetResponse response for {}. Fetched offset {}-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)offset</parameter><constant>Handling v0 ListOffsetResponse response for {}. Fetched offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>956</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Handling ListOffsetResponse response for {}. Fetched offset {}, timestamp {}-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.Long(name)partitionData.offset-java.lang.Long(name)partitionData.timestamp</parameter><constant>Handling ListOffsetResponse response for {}. Fetched offset {}, timestamp {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>964</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Cannot search by timestamp for partition {} because the message format version is before 0.10.0-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Cannot search by timestamp for partition {} because the message format version is before 0.10.0</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>976</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Attempt to fetch offsets for partition {} failed due to {}, retrying.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>983</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Attempt to fetch offsets for partition {} failed due to {}, retrying.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>988</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Received unknown topic or partition error in ListOffset request for partition {}-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Received unknown topic or partition error in ListOffset request for partition {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>992</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Attempt to fetch offsets for partition {} failed due to: {}, retrying.-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.String(name)error.message()</parameter><constant>Attempt to fetch offsets for partition {} failed due to: {}, retrying.</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.handleListOffsetResponse</callsite><line>997</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Not fetching from {} for partition {} since it is marked offline or is missing from our metadata, using the leader instead.-java.util.Optional<Integer>(name)nodeId-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Not fetching from {} for partition {} since it is marked offline or is missing from our metadata, using the leader instead.</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.selectReadReplica</callsite><line>1044</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Skipping fetch for partition {} because node {} is awaiting reconnect backoff-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.common.Node(name)node</parameter><constant>Skipping fetch for partition {} because node {} is awaiting reconnect backoff</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests</callsite><line>1079</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Skipping fetch for partition {} because previous request to {} has not been processed-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.common.Node(name)node</parameter><constant>Skipping fetch for partition {} because previous request to {} has not been processed</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests</callsite><line>1082</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Added {} fetch request for partition {} at position {} to node {}-org.apache.kafka.common.requests.IsolationLevel(name)isolationLevel-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position-org.apache.kafka.common.Node(name)node</parameter><constant>Added {} fetch request for partition {} at position {} to node {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.prepareFetchRequests</callsite><line>1100</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Ignoring fetched records for partition {} since it is no longer fetchable-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Ignoring fetched records for partition {} since it is no longer fetchable</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1141</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Discarding stale fetch response for partition {} since its offset {} does not match the expected offset {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)fetchOffset-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position</parameter><constant>Discarding stale fetch response for partition {} since its offset {} does not match the expected offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1147</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Preparing to read {} bytes of data for partition {} with offset {}-int(name)partition.records.sizeInBytes()-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.clients.consumer.internals.FetchPosition(name)position</parameter><constant>Preparing to read {} bytes of data for partition {} with offset {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1152</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating high watermark for partition {} to {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)partition.highWatermark</parameter><constant>Updating high watermark for partition {} to {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1176</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating log start offset for partition {} to {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)partition.logStartOffset</parameter><constant>Updating log start offset for partition {} to {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1181</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating last stable offset for partition {} to {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)partition.lastStableOffset</parameter><constant>Updating last stable offset for partition {} to {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1186</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Error in fetch for partition {}: {}-org.apache.kafka.common.TopicPartition(name)tp-java.lang.String(name)error.exceptionName()</parameter><constant>Error in fetch for partition {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1204</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Received unknown topic or partition error in fetch for partition {}-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Received unknown topic or partition error in fetch for partition {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1207</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Discarding stale fetch response for partition {} since the fetched offset {} does not match the current offset {}-org.apache.kafka.common.TopicPartition(name)tp-long(name)fetchOffset-org.apache.kafka.clients.consumer.internals.FetchPosition(name)subscriptions.position(tp)</parameter><constant>Discarding stale fetch response for partition {} since the fetched offset {} does not match the current offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1214</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Fetch offset {} is out of range for partition {}, resetting offset-long(name)fetchOffset-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Fetch offset {} is out of range for partition {}, resetting offset</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1217</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Unset the preferred read replica {} for partition {} since we got {} when fetching {}-java.lang.Integer(name)clearedReplicaId.get()-org.apache.kafka.common.TopicPartition(name)tp-org.apache.kafka.common.protocol.Errors(name)error-long(name)fetchOffset</parameter><constant>Unset the preferred read replica {} for partition {} since we got {} when fetching {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1223</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Not authorized to read from partition {}.-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Not authorized to read from partition {}.</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1228</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received unknown leader epoch error in fetch for partition {}-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Received unknown leader epoch error in fetch for partition {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1231</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Unknown error fetching data for topic-partition {}-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Unknown error fetching data for topic-partition {}</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.parseCompletedFetch</callsite><line>1233</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping aborted record batch from partition {} with producerId {} and offsets {} to {}-org.apache.kafka.common.TopicPartition(name)partition-long(name)producerId-long(name)currentBatch.baseOffset()-long(name)currentBatch.lastOffset()</parameter><constant>Skipping aborted record batch from partition {} with producerId {} and offsets {} to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.Fetcher.nextFetchedRecord</callsite><line>1441</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Coordinator discovery failed, refreshing metadata</parameter><constant>Coordinator discovery failed, refreshing metadata</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady</callsite><line>226</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)No broker available to send FindCoordinator request</parameter><constant>No broker available to send FindCoordinator request</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.lookupCoordinator</callsite><line>246</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)still waiting to ensure active group</parameter><constant>still waiting to ensure active group</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureActiveGroup</callsite><line>308</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Interrupted while waiting for consumer heartbeat thread to close</parameter><constant>Interrupted while waiting for consumer heartbeat thread to close</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.closeHeartbeatThread</callsite><line>353</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Successfully joined group with generation {}-int(name)generation.generationId</parameter><constant>Successfully joined group with generation {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.initiateJoinGroup</callsite><line>437</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)(Re-)joining group</parameter><constant>(Re-)joining group</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest</callsite><line>473</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending JoinGroup ({}) to coordinator {}-org.apache.kafka.common.requests.Builder(name)requestBuilder-org.apache.kafka.common.Node(name)this.coordinator</parameter><constant>Sending JoinGroup ({}) to coordinator {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendJoinGroupRequest</callsite><line>485</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received successful JoinGroup response: {}-org.apache.kafka.common.requests.JoinGroupResponse(name)joinResponse</parameter><constant>Received successful JoinGroup response: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>500</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to join group rejected since coordinator {} is loading the group.-org.apache.kafka.common.Node(name)coordinator()</parameter><constant>Attempt to join group rejected since coordinator {} is loading the group.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>519</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to join group failed due to unknown member id.</parameter><constant>Attempt to join group failed due to unknown member id.</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>525</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Attempt to join group failed due to obsolete coordinator information: {}-java.lang.String(name)error.message()</parameter><constant>Attempt to join group failed due to obsolete coordinator information: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>531</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Received fatal exception: group.instance.id gets fenced</parameter><constant>Received fatal exception: group.instance.id gets fenced</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>534</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Attempt to join group failed due to fatal error: {}-java.lang.String(name)error.message()</parameter><constant>Attempt to join group failed due to fatal error: {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>542</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Attempt to join group failed due to unsupported version error. Please unset field group.instance.id and retryto see if the problem resolves</parameter><constant>Attempt to join group failed due to unsupported version error. Please unset field group.instance.id and retryto see if the problem resolves</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>551</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Attempt to join group failed due to unexpected error: {}-java.lang.String(name)error.message()</parameter><constant>Attempt to join group failed due to unexpected error: {}</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>566</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending follower SyncGroup to coordinator {}: {}-org.apache.kafka.common.Node(name)this.coordinator-org.apache.kafka.common.requests.Builder(name)requestBuilder</parameter><constant>Sending follower SyncGroup to coordinator {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.onJoinFollower</callsite><line>583</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending leader SyncGroup to coordinator {}: {}-org.apache.kafka.common.Node(name)this.coordinator-org.apache.kafka.common.requests.Builder(name)requestBuilder</parameter><constant>Sending leader SyncGroup to coordinator {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.onJoinLeader</callsite><line>610</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)SyncGroup failed because the group began another rebalance</parameter><constant>SyncGroup failed because the group began another rebalance</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>638</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Received fatal exception: group.instance.id gets fenced</parameter><constant>Received fatal exception: group.instance.id gets fenced</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>641</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)SyncGroup failed: {}-java.lang.String(name)error.message()</parameter><constant>SyncGroup failed: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>645</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)SyncGroup failed: {}-java.lang.String(name)error.message()</parameter><constant>SyncGroup failed: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>650</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending FindCoordinator request to broker {}-org.apache.kafka.common.Node(name)node</parameter><constant>Sending FindCoordinator request to broker {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendFindCoordinatorRequest</callsite><line>667</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received FindCoordinator response {}-org.apache.kafka.clients.ClientResponse(name)resp</parameter><constant>Received FindCoordinator response {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.onSuccess</callsite><line>681</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Discovered group coordinator {}-org.apache.kafka.common.Node(name)coordinator</parameter><constant>Discovered group coordinator {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.onSuccess</callsite><line>696</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Group coordinator {} is unavailable or invalid, will attempt rediscovery-org.apache.kafka.common.Node(name)this.coordinator</parameter><constant>Group coordinator {} is unavailable or invalid, will attempt rediscovery</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.markCoordinatorUnknown</callsite><line>748</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Close timed out with {} pending requests to coordinator, terminating client connections-int(name)client.pendingRequestCount(coordinator)</parameter><constant>Close timed out with {} pending requests to coordinator, terminating client connections</constant><level>warn</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.close</callsite><line>835</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Member {} sending LeaveGroup request to coordinator {} due to {}-java.lang.String(name)generation.memberId-org.apache.kafka.common.Node(name)coordinator-java.lang.String(name)leaveReason</parameter><constant>Member {} sending LeaveGroup request to coordinator {} due to {}</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.maybeLeaveGroup</callsite><line>853</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)LeaveGroup request returned successfully</parameter><constant>LeaveGroup request returned successfully</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>874</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)LeaveGroup request failed with error: {}-java.lang.String(name)error.message()</parameter><constant>LeaveGroup request failed with error: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>877</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending Heartbeat request to coordinator {}-org.apache.kafka.common.Node(name)coordinator</parameter><constant>Sending Heartbeat request to coordinator {}</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.sendHeartbeatRequest</callsite><line>885</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received successful Heartbeat response</parameter><constant>Received successful Heartbeat response</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>902</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Attempt to heartbeat failed since coordinator {} is either not started or not valid.-org.apache.kafka.common.Node(name)coordinator()</parameter><constant>Attempt to heartbeat failed since coordinator {} is either not started or not valid.</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>906</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Attempt to heartbeat failed since group is rebalancing</parameter><constant>Attempt to heartbeat failed since group is rebalancing</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>911</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Attempt to heartbeat failed since generation {} is not current-int(name)generation.generationId</parameter><constant>Attempt to heartbeat failed since generation {} is not current</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>915</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Received fatal exception: group.instance.id gets fenced</parameter><constant>Received fatal exception: group.instance.id gets fenced</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>919</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Attempt to heartbeat failed for since member id {} is not valid.-java.lang.String(name)generation.memberId</parameter><constant>Attempt to heartbeat failed for since member id {} is not valid.</constant><level>info</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.handle</callsite><line>922</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Enabling heartbeat thread</parameter><constant>Enabling heartbeat thread</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.enable</callsite><line>1029</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Disabling heartbeat thread</parameter><constant>Disabling heartbeat thread</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.disable</callsite><line>1038</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Heartbeat thread started</parameter><constant>Heartbeat thread started</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1061</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Caught fenced group.instance.id {} error in heartbeat thread-java.util.Optional<String>(name)rebalanceConfig.groupInstanceId</parameter><constant>Caught fenced group.instance.id {} error in heartbeat thread</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1125</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)An authentication error occurred in the heartbeat thread-org.apache.kafka.common.errors.AuthenticationException(name)e</parameter><constant>An authentication error occurred in the heartbeat thread</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1140</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)A group authorization error occurred in the heartbeat thread-org.apache.kafka.common.errors.GroupAuthorizationException(name)e</parameter><constant>A group authorization error occurred in the heartbeat thread</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1143</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected interrupt received in heartbeat thread-java.lang.Exception(name)e</parameter><constant>Unexpected interrupt received in heartbeat thread</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1147</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Heartbeat thread failed due to unexpected error-java.lang.Throwable(name)e</parameter><constant>Heartbeat thread failed due to unexpected error</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1150</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Heartbeat thread has closed</parameter><constant>Heartbeat thread has closed</constant><level>debug</level><callsite>org.apache.kafka.clients.consumer.internals.AbstractCoordinator.run</callsite><line>1156</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Could not cast response body-java.lang.ClassCastException(name)cce</parameter><constant>Could not cast response body</constant><level>error</level><callsite>org.apache.kafka.clients.consumer.internals.AsyncClient.sendAsyncRequest</callsite><line>47</line><superclass>null</superclass><logcall>org.apache.kafka.clients.consumer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Received {} {} from broker {}-java.lang.String(name)resp.getClass().getSimpleName()-Resp(name)resp-org.apache.kafka.common.Node(name)node</parameter><constant>Received {} {} from broker {}</constant><level>trace</level><callsite>org.apache.kafka.clients.consumer.internals.AsyncClient.sendAsyncRequest</callsite><line>51</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Starting the Kafka producer</parameter><constant>Starting the Kafka producer</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.KafkaProducer</callsite><line>345</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka producer started</parameter><constant>Kafka producer started</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.KafkaProducer</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.warn</logcall> <parameter>java.lang.String(name){} should be equal to or larger than {} + {}. Setting it to {}.-java.lang.String(name)delivery.timeout.ms-java.lang.String(name)linger.ms-java.lang.String(name)request.timeout.ms-int(name)deliveryTimeoutMs</parameter><constant>{} should be equal to or larger than {} + {}. Setting it to {}.delivery.timeout.mslinger.msrequest.timeout.ms</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.configureDeliveryTimeout</callsite><line>498</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Instantiated a transactional producer.</parameter><constant>Instantiated a transactional producer.</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.configureTransactionState</callsite><line>532</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Instantiated an idempotent producer.</parameter><constant>Instantiated an idempotent producer.</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.configureTransactionState</callsite><line>534</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Overriding the default retries config to the recommended value of {} since the idempotent producer is enabled.-int(name)2147483647</parameter><constant>Overriding the default retries config to the recommended value of {} since the idempotent producer is enabled.2147483647</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.configureRetries</callsite><line>548</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Overriding the default {} to all since idempotence is enabled.-java.lang.String(name)acks</parameter><constant>Overriding the default {} to all since idempotence is enabled.acks</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.configureAcks</callsite><line>574</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Sending record {} with callback {} to topic {} partition {}-org.apache.kafka.clients.producer.ProducerRecord<K,V>(name)record-org.apache.kafka.clients.producer.Callback(name)callback-java.lang.String(name)record.topic()-int(name)partition</parameter><constant>Sending record {} with callback {} to topic {} partition {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.doSend</callsite><line>910</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Waking up the sender since topic {} partition {} is either full or getting a new batch-java.lang.String(name)record.topic()-int(name)partition</parameter><constant>Waking up the sender since topic {} partition {} is either full or getting a new batch</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.doSend</callsite><line>920</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.debug</logcall> <parameter>java.lang.String(name)Exception occurred during message send:-org.apache.kafka.common.errors.ApiException(name)e</parameter><constant>Exception occurred during message send:</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.doSend</callsite><line>928</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Requesting metadata update for partition {} of topic {}.-java.lang.Integer(name)partition-java.lang.String(name)topic</parameter><constant>Requesting metadata update for partition {} of topic {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata</callsite><line>991</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Requesting metadata update for topic {}.-java.lang.String(name)topic</parameter><constant>Requesting metadata update for topic {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.waitOnMetadata</callsite><line>993</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.trace</logcall> <parameter>java.lang.String(name)Flushing accumulated records in producer.</parameter><constant>Flushing accumulated records in producer.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.flush</callsite><line>1075</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Closing the Kafka producer with timeoutMillis = {} ms.-long(name)timeoutMs</parameter><constant>Closing the Kafka producer with timeoutMillis = {} ms.</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.close</callsite><line>1153</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.warn</logcall> <parameter>java.lang.String(name)Overriding close timeout {} ms to 0 ms in order to prevent useless blocking due to self-join. This means you have incorrectly invoked close with a non-zero timeout from the producer call-back.-long(name)timeoutMs</parameter><constant>Overriding close timeout {} ms to 0 ms in order to prevent useless blocking due to self-join. This means you have incorrectly invoked close with a non-zero timeout from the producer call-back.</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.close</callsite><line>1160</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.error</logcall> <parameter>java.lang.String(name)Interrupted while joining ioThread-java.lang.InterruptedException(name)t</parameter><constant>Interrupted while joining ioThread</constant><level>error</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.close</callsite><line>1172</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.info</logcall> <parameter>java.lang.String(name)Proceeding to force close the producer since pending requests could not be completed within timeout {} ms.-long(name)timeoutMs</parameter><constant>Proceeding to force close the producer since pending requests could not be completed within timeout {} ms.</constant><level>info</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.close</callsite><line>1179</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka producer has been closed</parameter><constant>Kafka producer has been closed</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.KafkaProducer.close</callsite><line>1205</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Removing unused topic {} from the metadata list, expiryMs {} now {}-java.lang.String(name)topic-java.lang.Long(name)expireMs-long(name)nowMs</parameter><constant>Removing unused topic {} from the metadata list, expiryMs {} now {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.ProducerMetadata.retainTopic</callsite><line>83</line><superclass>org.apache.kafka.clients.Metadata</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Begin adding offsets {} for consumer group {} to transaction-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets-java.lang.String(name)consumerGroupId</parameter><constant>Begin adding offsets {} for consumer group {} to transaction</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.sendOffsetsToTransaction</callsite><line>332</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Begin adding new partition {} to transaction-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Begin adding new partition {} to transaction</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.maybeAddPartitionToTransaction</callsite><line>346</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping transition to abortable error state since the transaction is already being aborted. Underlying exception: -java.lang.RuntimeException(name)exception</parameter><constant>Skipping transition to abortable error state since the transaction is already being aborted. Underlying exception: </constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.transitionToAbortableError</callsite><line>406</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.info</logcall> <parameter>java.lang.String(name)ProducerId set to {} with epoch {}-long(name)producerIdAndEpoch.producerId-short(name)producerIdAndEpoch.epoch</parameter><constant>ProducerId set to {} with epoch {}</constant><level>info</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.setProducerIdAndEpoch</callsite><line>450</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Partition {} keeps lastOffset at {}-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-long(name)lastOffset</parameter><constant>Partition {} keeps lastOffset at {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.updateLastAckedOffset</callsite><line>565</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Ignoring completed batch {} with producer id {}, epoch {}, and sequence number {} since the producerId has been reset internally-org.apache.kafka.clients.producer.internals.ProducerBatch(name)batch-long(name)batch.producerId()-short(name)batch.producerEpoch()-int(name)batch.baseSequence()</parameter><constant>Ignoring completed batch {} with producer id {}, epoch {}, and sequence number {} since the producerId has been reset internally</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleCompletedBatch</callsite><line>571</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)ProducerId: {}; Set last ack'd sequence number for topic-partition {} to {}-long(name)batch.producerId()-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-int(name)lastAckedSequence(batch.topicPartition).orElse(-1)</parameter><constant>ProducerId: {}; Set last ack'd sequence number for topic-partition {} to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleCompletedBatch</callsite><line>578</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Ignoring failed batch {} with producer id {}, epoch {}, and sequence number {} since the producerId has been reset internally-org.apache.kafka.clients.producer.internals.ProducerBatch(name)batch-long(name)batch.producerId()-short(name)batch.producerEpoch()-int(name)batch.baseSequence()-java.lang.RuntimeException(name)exception</parameter><constant>Ignoring failed batch {} with producer id {}, epoch {}, and sequence number {} since the producerId has been reset internally</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleFailedBatch</callsite><line>602</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)The broker returned {} for topic-partition {} with producerId {}, epoch {}, and sequence number {}-java.lang.RuntimeException(name)exception-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-long(name)batch.producerId()-short(name)batch.producerEpoch()-int(name)batch.baseSequence()</parameter><constant>The broker returned {} for topic-partition {} with producerId {}, epoch {}, and sequence number {}</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleFailedBatch</callsite><line>609</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)producerId: {}, send to partition {} failed fatally. Reducing future sequence numbers by {}-long(name)batch.producerId()-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-int(name)batch.recordCount</parameter><constant>producerId: {}, send to partition {} failed fatally. Reducing future sequence numbers by {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.adjustSequencesDueToFailedBatch</callsite><line>633</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Marking partition {} unresolved-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Marking partition {} unresolved</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.markSequenceUnresolved</callsite><line>684</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.info</logcall> <parameter>java.lang.String(name)No inflight batches remaining for {}, last ack'd sequence for partition is {}, next sequence is {}. Going to reset producer state.-org.apache.kafka.common.TopicPartition(name)topicPartition-int(name)lastAckedSequence(topicPartition).orElse(NO_LAST_ACKED_SEQUENCE_NUMBER)-java.lang.Integer(name)sequenceNumber(topicPartition)</parameter><constant>No inflight batches remaining for {}, last ack'd sequence for partition is {}, next sequence is {}. Going to reset producer state.</constant><level>info</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.shouldResetProducerStateAfterResolvingSequences</callsite><line>705</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Not sending transactional request {} because we are in an error state-org.apache.kafka.common.requests.Builder<>(name)nextRequestHandler.requestBuilder()</parameter><constant>Not sending transactional request {} because we are in an error state</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.nextRequestHandler</callsite><line>737</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Not sending EndTxn for completed transaction since no partitions or offsets were successfully added</parameter><constant>Not sending EndTxn for completed transaction since no partitions or offsets were successfully added</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.nextRequestHandler</callsite><line>745</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Request {} dequeued for sending-org.apache.kafka.common.requests.Builder<>(name)nextRequestHandler.requestBuilder()</parameter><constant>Request {} dequeued for sending</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.nextRequestHandler</callsite><line>753</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Transition from state {} to error state {}-org.apache.kafka.clients.producer.internals.State(name)currentState-org.apache.kafka.clients.producer.internals.State(name)target-java.lang.RuntimeException(name)lastError</parameter><constant>Transition from state {} to error state {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.transitionTo</callsite><line>904</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Transition from state {} to {}-org.apache.kafka.clients.producer.internals.State(name)currentState-org.apache.kafka.clients.producer.internals.State(name)target</parameter><constant>Transition from state {} to {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.transitionTo</callsite><line>906</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Enqueuing transactional request {}-org.apache.kafka.common.requests.Builder<>(name)requestHandler.requestBuilder()</parameter><constant>Enqueuing transactional request {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.enqueueRequest</callsite><line>942</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Disconnected from {}. Will retry.-java.lang.String(name)response.destination()</parameter><constant>Disconnected from {}. Will retry.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.onComplete</callsite><line>1059</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Received transactional response {} for request {}-org.apache.kafka.common.requests.AbstractResponse(name)response.responseBody()-org.apache.kafka.common.requests.Builder<>(name)requestBuilder()</parameter><constant>Received transactional response {} for request {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.onComplete</callsite><line>1066</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Did not attempt to add partition {} to transaction because other partitions in the batch had errors.-org.apache.kafka.common.TopicPartition(name)topicPartition</parameter><constant>Did not attempt to add partition {} to transaction because other partitions in the batch had errors.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleResponse</callsite><line>1209</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Could not add partition {} due to unexpected error {}-org.apache.kafka.common.TopicPartition(name)topicPartition-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Could not add partition {} due to unexpected error {}</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleResponse</callsite><line>1213</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Successfully added partitions {} to transaction-java.util.Set<TopicPartition>(name)partitions</parameter><constant>Successfully added partitions {} to transaction</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleResponse</callsite><line>1232</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Successfully added partition for consumer group {} to transaction-java.lang.String(name)builder.consumerGroupId()</parameter><constant>Successfully added partition for consumer group {} to transaction</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleResponse</callsite><line>1389</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received TxnOffsetCommit response for consumer group {}: {}-java.lang.String(name)builder.consumerGroupId()-java.util.Map<TopicPartition,Errors>(name)errors</parameter><constant>Received TxnOffsetCommit response for consumer group {}: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.TransactionManager.handleResponse</callsite><line>1446</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onSend callback for topic: {}, partition: {}-java.lang.String(name)record.topic()-java.lang.Integer(name)record.partition()-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onSend callback for topic: {}, partition: {}</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.ProducerInterceptors.onSend</callsite><line>66</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onSend callback-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onSend callback</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.ProducerInterceptors.onSend</callsite><line>68</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onAcknowledgement callback-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onAcknowledgement callback</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.ProducerInterceptors.onAcknowledgement</callsite><line>91</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error executing interceptor onAcknowledgement callback-java.lang.Exception(name)e</parameter><constant>Error executing interceptor onAcknowledgement callback</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.ProducerInterceptors.onSendError</callsite><line>121</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close producer interceptor -java.lang.Exception(name)e</parameter><constant>Failed to close producer interceptor </constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.ProducerInterceptors.close</callsite><line>135</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Allocating a new {} byte message buffer for topic {} partition {}-int(name)size-java.lang.String(name)tp.topic()-int(name)tp.partition()</parameter><constant>Allocating a new {} byte message buffer for topic {} partition {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.RecordAccumulator.append</callsite><line>209</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping next batch expiry time update due to addition overflow: batch.createMs={}, deliveryTimeoutMs={}-long(name)batch.createdMs-int(name)deliveryTimeoutMs</parameter><constant>Skipping next batch expiry time update due to addition overflow: batch.createMs={}, deliveryTimeoutMs={}</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.RecordAccumulator.maybeUpdateNextBatchExpiryTime</callsite><line>286</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Reordered incoming batch with sequence {} for partition {}. It was placed in the queue at position {}-int(name)batch.baseSequence()-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-int(name)orderedBatches.size()</parameter><constant>Reordered incoming batch with sequence {} for partition {}. It was placed in the queue at position {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.RecordAccumulator.insertInSequenceOrder</callsite><line>399</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Assigned producerId {} and producerEpoch {} to batch with base sequence {} being sent to partition {}-long(name)producerIdAndEpoch.producerId-short(name)producerIdAndEpoch.epoch-int(name)batch.baseSequence()-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Assigned producerId {} and producerEpoch {} to batch with base sequence {} being sent to partition {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.RecordAccumulator.drainBatchesForOneNode</callsite><line>576</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Starting Kafka producer I/O thread.</parameter><constant>Starting Kafka producer I/O thread.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>233</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught error in kafka producer I/O thread: -java.lang.Exception(name)e</parameter><constant>Uncaught error in kafka producer I/O thread: </constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>240</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Beginning shutdown of Kafka producer I/O thread, sending remaining records.</parameter><constant>Beginning shutdown of Kafka producer I/O thread, sending remaining records.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>244</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught error in kafka producer I/O thread: -java.lang.Exception(name)e</parameter><constant>Uncaught error in kafka producer I/O thread: </constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>253</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.info</logcall> <parameter>java.lang.String(name)Aborting incomplete transaction due to shutdown</parameter><constant>Aborting incomplete transaction due to shutdown</constant><level>info</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>260</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught error in kafka producer I/O thread: -java.lang.Exception(name)e</parameter><constant>Uncaught error in kafka producer I/O thread: </constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>266</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Aborting incomplete transactional requests due to forced shutdown</parameter><constant>Aborting incomplete transactional requests due to forced shutdown</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>274</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Aborting incomplete batches due to forced shutdown</parameter><constant>Aborting incomplete batches due to forced shutdown</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close network client-java.lang.Exception(name)e</parameter><constant>Failed to close network client</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>283</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Shutdown of Kafka producer I/O thread has completed.</parameter><constant>Shutdown of Kafka producer I/O thread has completed.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.run</callsite><line>286</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Authentication exception while processing transactional request: {}-org.apache.kafka.common.errors.AuthenticationException(name)e</parameter><constant>Authentication exception while processing transactional request: {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.runOnce</callsite><line>324</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting metadata update due to unknown leader topics from the batched records: {}-java.util.Set<String>(name)result.unknownLeaderTopics</parameter><constant>Requesting metadata update due to unknown leader topics from the batched records: {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.sendProducerData</callsite><line>347</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Expired {} batches in accumulator-int(name)expiredBatches.size()</parameter><constant>Expired {} batches in accumulator</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.sendProducerData</callsite><line>383</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Nodes with data ready to send: {}-java.util.Set<Node>(name)result.readyNodes</parameter><constant>Nodes with data ready to send: {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.sendProducerData</callsite><line>404</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending transactional request {} to node {}-org.apache.kafka.common.requests.Builder<>(name)requestBuilder-org.apache.kafka.common.Node(name)targetNode</parameter><constant>Sending transactional request {} to node {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeSendTransactionalRequest</callsite><line>455</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Disconnect from {} while trying to send request {}. Going to back off and retry.-org.apache.kafka.common.Node(name)targetNode-org.apache.kafka.common.requests.Builder<>(name)requestBuilder-java.io.IOException(name)e</parameter><constant>Disconnect from {} while trying to send request {}. Going to back off and retry.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeSendTransactionalRequest</callsite><line>461</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Aborting producer batches due to fatal error-java.lang.RuntimeException(name)exception</parameter><constant>Aborting producer batches due to fatal error</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeAbortBatches</callsite><line>478</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Retriable error from InitProducerId response-java.lang.String(name)error.message()</parameter><constant>Retriable error from InitProducerId response</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeWaitForProducerId</callsite><line>539</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Could not find an available broker to send InitProducerIdRequest to. Will back off and retry.</parameter><constant>Could not find an available broker to send InitProducerIdRequest to. Will back off and retry.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeWaitForProducerId</callsite><line>545</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Broker {} disconnected while awaiting InitProducerId response-org.apache.kafka.common.Node(name)node-java.io.IOException(name)e</parameter><constant>Broker {} disconnected while awaiting InitProducerId response</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeWaitForProducerId</callsite><line>551</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Retry InitProducerIdRequest in {}ms.-long(name)retryBackoffMs</parameter><constant>Retry InitProducerIdRequest in {}ms.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.maybeWaitForProducerId</callsite><line>553</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Cancelled request with header {} due to node {} being disconnected-org.apache.kafka.common.requests.RequestHeader(name)requestHeader-java.lang.String(name)response.destination()</parameter><constant>Cancelled request with header {} due to node {} being disconnected</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse</callsite><line>567</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Cancelled request {} due to a version mismatch with node {}-org.apache.kafka.clients.ClientResponse(name)response-java.lang.String(name)response.destination()-org.apache.kafka.common.errors.UnsupportedVersionException(name)response.versionMismatch()</parameter><constant>Cancelled request {} due to a version mismatch with node {}</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse</callsite><line>572</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Received produce response from node {} with correlation id {}-java.lang.String(name)response.destination()-int(name)correlationId</parameter><constant>Received produce response from node {} with correlation id {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse</callsite><line>577</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Got error produce response in correlation id {} on topic-partition {}, splitting and retrying ({} attempts left). Error: {}-long(name)correlationId-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-int(name)this.retries - batch.attempts()-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Got error produce response in correlation id {} on topic-partition {}, splitting and retrying ({} attempts left). Error: {}</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.Sender.completeBatch</callsite><line>613</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}-long(name)correlationId-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-int(name)this.retries - batch.attempts() - 1-org.apache.kafka.common.protocol.Errors(name)error</parameter><constant>Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.Sender.completeBatch</callsite><line>626</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Retrying batch to topic-partition {}. ProducerId: {}; Sequence number : {}-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-long(name)batch.producerId()-int(name)batch.baseSequence()</parameter><constant>Retrying batch to topic-partition {}. ProducerId: {}; Sequence number : {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.Sender.completeBatch</callsite><line>637</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Received unknown topic or partition error in produce request on partition {}. The topic-partition may not exist or the user may not have Describe access to it-org.apache.kafka.common.TopicPartition(name)batch.topicPartition</parameter><constant>Received unknown topic or partition error in produce request on partition {}. The topic-partition may not exist or the user may not have Describe access to it</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.Sender.completeBatch</callsite><line>667</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Received invalid metadata error in produce request on partition {} due to {}. Going to request metadata update now-org.apache.kafka.common.TopicPartition(name)batch.topicPartition-java.lang.String(name)error.exception().toString()</parameter><constant>Received invalid metadata error in produce request on partition {} due to {}. Going to request metadata update now</constant><level>warn</level><callsite>org.apache.kafka.clients.producer.internals.Sender.completeBatch</callsite><line>671</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Sent produce request to {}: {}-java.lang.String(name)nodeId-org.apache.kafka.common.requests.Builder(name)requestBuilder</parameter><constant>Sent produce request to {}: {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.Sender.sendProduceRequest</callsite><line>797</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Aborting batch for partition {}-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.RuntimeException(name)exception</parameter><constant>Aborting batch for partition {}</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.abort</callsite><line>157</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Successfully produced messages to {} with base offset {}.-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)baseOffset</parameter><constant>Successfully produced messages to {} with base offset {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.done</callsite><line>190</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Failed to produce messages to {} with base offset {}.-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)baseOffset-java.lang.RuntimeException(name)exception</parameter><constant>Failed to produce messages to {} with base offset {}.</constant><level>trace</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.done</callsite><line>192</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)ProduceResponse returned {} for {} after batch with base offset {} had already been {}.-org.apache.kafka.clients.producer.internals.FinalState(name)tryFinalState-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)baseOffset-org.apache.kafka.clients.producer.internals.FinalState(name)this.finalState.get()</parameter><constant>ProduceResponse returned {} for {} after batch with base offset {} had already been {}.</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.done</callsite><line>203</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Ignored state transition {} -> {} for {} batch with base offset {}-org.apache.kafka.clients.producer.internals.FinalState(name)this.finalState.get()-org.apache.kafka.clients.producer.internals.FinalState(name)tryFinalState-org.apache.kafka.common.TopicPartition(name)topicPartition-long(name)baseOffset</parameter><constant>Ignored state transition {} -> {} for {} batch with base offset {}</constant><level>debug</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.done</callsite><line>207</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Error executing user-provided callback on message for topic-partition '{}'-org.apache.kafka.common.TopicPartition(name)topicPartition-java.lang.Exception(name)e</parameter><constant>Error executing user-provided callback on message for topic-partition '{}'</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks</callsite><line>233</line><superclass>null</superclass><logcall>org.apache.kafka.clients.producer.internals.Logger.error</logcall> <parameter>java.lang.String(name)Error when sending message to topic {} with key: {}, value: {} with error:-java.lang.String(name)topic-java.lang.String(name)keyString-java.lang.String(name)valueString-java.lang.Exception(name)e</parameter><constant>Error when sending message to topic {} with key: {}, value: {} with error:</constant><level>error</level><callsite>org.apache.kafka.clients.producer.internals.ErrorLoggingCallback.onCompletion</callsite><line>52</line><superclass>null</superclass><logcall>org.apache.kafka.common.config.Logger.info</logcall> <parameter>java.lang.String(name)b.toString()</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.config.AbstractConfig.logAll</callsite><line>347</line><superclass>null</superclass><logcall>org.apache.kafka.common.config.Logger.warn</logcall> <parameter>java.lang.String(name)The configuration '{}' was supplied but isn't a known config.-java.lang.String(name)key</parameter><constant>The configuration '{}' was supplied but isn't a known config.</constant><level>warn</level><callsite>org.apache.kafka.common.config.AbstractConfig.logUnused</callsite><line>355</line><superclass>null</superclass><logcall>org.apache.kafka.common.config.Logger.error</logcall> <parameter>java.lang.String(name)"ClassNotFoundException exception occurred: " + entry.getValue()</parameter><constant>ClassNotFoundException exception occurred: </constant><level>error</level><callsite>org.apache.kafka.common.config.AbstractConfig.instantiateConfigProviders</callsite><line>534</line><superclass>null</superclass><logcall>org.apache.kafka.common.memory.Logger.trace</logcall> <parameter>java.lang.String(name)refused to allocate buffer of size {}-int(name)sizeBytes</parameter><constant>refused to allocate buffer of size {}</constant><level>trace</level><callsite>org.apache.kafka.common.memory.SimpleMemoryPool.tryAllocate</callsite><line>78</line><superclass>null</superclass><logcall>org.apache.kafka.common.memory.Logger.trace</logcall> <parameter>java.lang.String(name)allocated buffer of size {} -int(name)justAllocated.capacity()</parameter><constant>allocated buffer of size {} </constant><level>trace</level><callsite>org.apache.kafka.common.memory.SimpleMemoryPool.bufferToBeReturned</callsite><line>114</line><superclass>null</superclass><logcall>org.apache.kafka.common.memory.Logger.trace</logcall> <parameter>java.lang.String(name)released buffer of size {}-int(name)justReleased.capacity()</parameter><constant>released buffer of size {}</constant><level>trace</level><callsite>org.apache.kafka.common.memory.SimpleMemoryPool.bufferToBeReleased</callsite><line>119</line><superclass>null</superclass><logcall>org.apache.kafka.common.memory.Logger.trace</logcall> <parameter>java.lang.String(name)allocated buffer of size {} and identity {}-long(name)sizeBytes-int(name)ref.hashCode</parameter><constant>allocated buffer of size {} and identity {}</constant><level>trace</level><callsite>org.apache.kafka.common.memory.GarbageCollectedMemoryPool.bufferToBeReturned</callsite><line>61</line><superclass>org.apache.kafka.common.memory.SimpleMemoryPool</superclass><logcall>org.apache.kafka.common.memory.Logger.trace</logcall> <parameter>java.lang.String(name)released buffer of size {} and identity {}-int(name)metadata.sizeBytes-int(name)ref.hashCode</parameter><constant>released buffer of size {} and identity {}</constant><level>trace</level><callsite>org.apache.kafka.common.memory.GarbageCollectedMemoryPool.bufferToBeReleased</callsite><line>76</line><superclass>org.apache.kafka.common.memory.SimpleMemoryPool</superclass><logcall>org.apache.kafka.common.memory.Logger.error</logcall> <parameter>java.lang.String(name)Reclaimed buffer of size {} and identity {} that was not properly release()ed. This is a bug.-int(name)metadata.sizeBytes-int(name)ref.hashCode</parameter><constant>Reclaimed buffer of size {} and identity {} that was not properly release()ed. This is a bug.</constant><level>error</level><callsite>org.apache.kafka.common.memory.GarbageCollectedMemoryPool.run</callsite><line>106</line><superclass>org.apache.kafka.common.memory.SimpleMemoryPool</superclass><logcall>org.apache.kafka.common.memory.Logger.debug</logcall> <parameter>java.lang.String(name)interrupted-java.lang.InterruptedException(name)e</parameter><constant>interrupted</constant><level>debug</level><callsite>org.apache.kafka.common.memory.GarbageCollectedMemoryPool.run</callsite><line>108</line><superclass>org.apache.kafka.common.memory.SimpleMemoryPool</superclass><logcall>org.apache.kafka.common.memory.Logger.info</logcall> <parameter>java.lang.String(name)GC listener shutting down</parameter><constant>GC listener shutting down</constant><level>info</level><callsite>org.apache.kafka.common.memory.GarbageCollectedMemoryPool.run</callsite><line>112</line><superclass>org.apache.kafka.common.memory.SimpleMemoryPool</superclass><logcall>org.apache.kafka.common.metrics.Logger.debug</logcall> <parameter>java.lang.String(name)Added sensor with name {}-java.lang.String(name)name</parameter><constant>Added sensor with name {}</constant><level>debug</level><callsite>org.apache.kafka.common.metrics.Metrics.sensor</callsite><line>416</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.debug</logcall> <parameter>java.lang.String(name)Removed sensor with name {}-java.lang.String(name)name</parameter><constant>Removed sensor with name {}</constant><level>debug</level><callsite>org.apache.kafka.common.metrics.Metrics.removeSensor</callsite><line>449</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.error</logcall> <parameter>java.lang.String(name)"Error when removing metric from " + reporter.getClass().getName()-java.lang.Exception(name)e</parameter><constant>Error when removing metric from </constant><level>error</level><callsite>org.apache.kafka.common.metrics.Metrics.removeMetric</callsite><line>536</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.trace</logcall> <parameter>java.lang.String(name)Removed metric named {}-org.apache.kafka.common.MetricName(name)metricName</parameter><constant>Removed metric named {}</constant><level>trace</level><callsite>org.apache.kafka.common.metrics.Metrics.removeMetric</callsite><line>539</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.error</logcall> <parameter>java.lang.String(name)"Error when registering metric on " + reporter.getClass().getName()-java.lang.Exception(name)e</parameter><constant>Error when registering metric on </constant><level>error</level><callsite>org.apache.kafka.common.metrics.Metrics.registerMetric</callsite><line>570</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.trace</logcall> <parameter>java.lang.String(name)Registered metric named {}-org.apache.kafka.common.MetricName(name)metricName</parameter><constant>Registered metric named {}</constant><level>trace</level><callsite>org.apache.kafka.common.metrics.Metrics.registerMetric</callsite><line>573</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.debug</logcall> <parameter>java.lang.String(name)Removing expired sensor {}-java.lang.String(name)sensorEntry.getKey()</parameter><constant>Removing expired sensor {}</constant><level>debug</level><callsite>org.apache.kafka.common.metrics.Metrics.run</callsite><line>607</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.error</logcall> <parameter>java.lang.String(name)"Error when closing " + reporter.getClass().getName()-java.lang.Exception(name)e</parameter><constant>Error when closing </constant><level>error</level><callsite>org.apache.kafka.common.metrics.Metrics.close</callsite><line>658</line><superclass>null</superclass><logcall>org.apache.kafka.common.metrics.Logger.warn</logcall> <parameter>java.lang.String(name)Error getting JMX attribute '{}'-java.lang.String(name)name-java.lang.Exception(name)e</parameter><constant>Error getting JMX attribute '{}'</constant><level>warn</level><callsite>org.apache.kafka.common.metrics.JmxReporter.getAttributes</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Failed to send SSL Close message-java.io.IOException(name)ie</parameter><constant>Failed to send SSL Close message</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.close</callsite><line>181</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake NEED_TASK channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake NEED_TASK channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.doHandshake</callsite><line>306</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake NEED_WRAP channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake NEED_WRAP channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.doHandshake</callsite><line>311</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake NEED_WRAP channelId {}, handshakeResult {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-javax.net.ssl.SSLEngineResult(name)handshakeResult-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake NEED_WRAP channelId {}, handshakeResult {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.doHandshake</callsite><line>328</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake NEED_UNWRAP channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake NEED_UNWRAP channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.doHandshake</callsite><line>337</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake NEED_UNWRAP channelId {}, handshakeResult {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-javax.net.ssl.SSLEngineResult(name)handshakeResult-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake NEED_UNWRAP channelId {}, handshakeResult {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.doHandshake</callsite><line>359</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)SSL handshake completed successfully with peerHost '{}' peerPort {} peerPrincipal '{}' cipherSuite '{}'-java.lang.String(name)session.getPeerHost()-int(name)session.getPeerPort()-java.security.Principal(name)peerPrincipal()-java.lang.String(name)session.getCipherSuite()</parameter><constant>SSL handshake completed successfully with peerHost '{}' peerPort {} peerPrincipal '{}' cipherSuite '{}'</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeFinished</callsite><line>424</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake FINISHED channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {} -java.lang.String(name)channelId-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>SSLHandshake FINISHED channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {} </constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeFinished</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake handshakeWrap {}-java.lang.String(name)channelId</parameter><constant>SSLHandshake handshakeWrap {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeWrap</callsite><line>442</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake handshakeUnwrap {}-java.lang.String(name)channelId</parameter><constant>SSLHandshake handshakeUnwrap {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeUnwrap</callsite><line>469</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)SSLHandshake handshakeUnwrap: handshakeStatus {} status {}-javax.net.ssl.HandshakeStatus(name)handshakeStatus-javax.net.ssl.Status(name)result.getStatus()</parameter><constant>SSLHandshake handshakeUnwrap: handshakeStatus {} status {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeUnwrap</callsite><line>489</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)Renegotiation requested, but it is not supported, channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}-java.lang.String(name)channelId-int(name)appReadBuffer.position()-int(name)netReadBuffer.position()-int(name)netWriteBuffer.position()</parameter><constant>Renegotiation requested, but it is not supported, channelId {}, appReadBuffer pos {}, netReadBuffer pos {}, netWriteBuffer pos {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.SslTransportLayer.read</callsite><line>539</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)SSL peer is not authenticated, returning ANONYMOUS instead</parameter><constant>SSL peer is not authenticated, returning ANONYMOUS instead</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.peerPrincipal</callsite><line>734</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)SSLEngine.closeInBound() raised an exception.-javax.net.ssl.SSLException(name)e</parameter><constant>SSLEngine.closeInBound() raised an exception.</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeFailure</callsite><line>832</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Failed to flush all bytes before closing channel-java.io.IOException(name)e</parameter><constant>Failed to flush all bytes before closing channel</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.handshakeFailure</callsite><line>845</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)SSLException while unwrapping data after IOException, original IOException will be propagated-javax.net.ssl.SSLException(name)sslException</parameter><constant>SSLException while unwrapping data after IOException, original IOException will be propagated</constant><level>debug</level><callsite>org.apache.kafka.common.network.SslTransportLayer.maybeProcessHandshakeFailure</callsite><line>872</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.info</logcall> <parameter>java.lang.String(name)Failed to create channel due to -java.lang.Exception(name)e</parameter><constant>Failed to create channel due to </constant><level>info</level><callsite>org.apache.kafka.common.network.SslChannelBuilder.buildChannel</callsite><line>105</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.info</logcall> <parameter>java.lang.String(name)Failed to create channel due to -java.lang.Exception(name)e</parameter><constant>Failed to create channel due to </constant><level>info</level><callsite>org.apache.kafka.common.network.SaslChannelBuilder.buildChannel</callsite><line>210</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Immediately connected to node {}-java.lang.String(name)id</parameter><constant>Immediately connected to node {}</constant><level>debug</level><callsite>org.apache.kafka.common.network.Selector.connect</callsite><line>263</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected exception during send, closing connection {} and rethrowing exception {}-java.lang.String(name)connectionId-java.lang.Exception(name)e</parameter><constant>Unexpected exception during send, closing connection {} and rethrowing exception {}</constant><level>error</level><callsite>org.apache.kafka.common.network.Selector.send</callsite><line>403</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)Broker no longer low on memory - unmuting incoming sockets</parameter><constant>Broker no longer low on memory - unmuting incoming sockets</constant><level>trace</level><callsite>org.apache.kafka.common.network.Selector.poll</callsite><line>456</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Created socket with SO_RCVBUF = {}, SO_SNDBUF = {}, SO_TIMEOUT = {} to node {}-int(name)socketChannel.socket().getReceiveBufferSize()-int(name)socketChannel.socket().getSendBufferSize()-int(name)socketChannel.socket().getSoTimeout()-java.lang.String(name)channel.id()</parameter><constant>Created socket with SO_RCVBUF = {}, SO_SNDBUF = {}, SO_TIMEOUT = {} to node {}</constant><level>debug</level><callsite>org.apache.kafka.common.network.Selector.pollSelectionKeys</callsite><line>535</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.warn</logcall> <parameter>java.lang.String(name)Should never happen: re-authentication latency for a re-authenticated channel was null; continuing...</parameter><constant>Should never happen: re-authentication latency for a re-authenticated channel was null; continuing...</constant><level>warn</level><callsite>org.apache.kafka.common.network.Selector.pollSelectionKeys</callsite><line>554</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Connection with {} disconnected-java.lang.String(name)desc-java.lang.Exception(name)e</parameter><constant>Connection with {} disconnected</constant><level>debug</level><callsite>org.apache.kafka.common.network.Selector.pollSelectionKeys</callsite><line>607</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.warn</logcall> <parameter>java.lang.String(name)Unexpected error from {}; closing connection-java.lang.String(name)desc-java.lang.Exception(name)e</parameter><constant>Unexpected error from {}; closing connection</constant><level>warn</level><callsite>org.apache.kafka.common.network.Selector.pollSelectionKeys</callsite><line>620</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)About to close the idle connection from {} due to being idle for {} millis-java.lang.String(name)connectionId-long(name)(currentTimeNanos - expiredConnection.getValue()) / 1000 / 1000</parameter><constant>About to close the idle connection from {} due to being idle for {} millis</constant><level>trace</level><callsite>org.apache.kafka.common.network.Selector.maybeCloseOldestConnection</callsite><line>747</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.error</logcall> <parameter>java.lang.String(name)Exception handling close on authentication failure node {}-java.lang.String(name)channel.id()-java.lang.Exception(name)e</parameter><constant>Exception handling close on authentication failure node {}</constant><level>error</level><callsite>org.apache.kafka.common.network.Selector.handleCloseOnAuthenticationFailure</callsite><line>827</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.debug</logcall> <parameter>java.lang.String(name)Tracking closing connection {} to process outstanding requests-java.lang.String(name)channel.id()</parameter><constant>Tracking closing connection {} to process outstanding requests</constant><level>debug</level><callsite>org.apache.kafka.common.network.Selector.close</callsite><line>860</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.error</logcall> <parameter>java.lang.String(name)Exception closing connection to node {}:-java.lang.String(name)channel.id()-java.io.IOException(name)e</parameter><constant>Exception closing connection to node {}:</constant><level>error</level><callsite>org.apache.kafka.common.network.Selector.doClose</callsite><line>880</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to create channel due to -java.lang.Exception(name)e</parameter><constant>Failed to create channel due to </constant><level>warn</level><callsite>org.apache.kafka.common.network.PlaintextChannelBuilder.buildChannel</callsite><line>59</line><superclass>null</superclass><logcall>org.apache.kafka.common.network.Logger.trace</logcall> <parameter>java.lang.String(name)Broker low on memory - could not allocate buffer of size {} for source {}-int(name)requestedBufferSize-java.lang.String(name)source</parameter><constant>Broker low on memory - could not allocate buffer of size {} for source {}</constant><level>trace</level><callsite>org.apache.kafka.common.network.NetworkReceive.readFrom</callsite><line>114</line><superclass>null</superclass><logcall>org.apache.kafka.common.protocol.Logger.warn</logcall> <parameter>java.lang.String(name)Unexpected error code: {}.-short(name)code</parameter><constant>Unexpected error code: {}.</constant><level>warn</level><callsite>org.apache.kafka.common.protocol.Errors.forCode</callsite><line>405</line><superclass>null</superclass><logcall>org.apache.kafka.common.record.Logger.error</logcall> <parameter>java.lang.String(name)mismatch in sending bytes over socket; expected: {} actual: {}-long(name)size-long(name)totalWritten</parameter><constant>mismatch in sending bytes over socket; expected: {} actual: {}</constant><level>error</level><callsite>org.apache.kafka.common.record.MultiRecordsSend.writeTo</callsite><line>105</line><superclass>null</superclass><logcall>org.apache.kafka.common.record.Logger.trace</logcall> <parameter>java.lang.String(name)Bytes written as part of multi-send call: {}, total bytes written so far: {}, expected bytes to write: {}-int(name)totalWrittenPerCall-long(name)totalWritten-long(name)size</parameter><constant>Bytes written as part of multi-send call: {}, total bytes written so far: {}, expected bytes to write: {}</constant><level>trace</level><callsite>org.apache.kafka.common.record.MultiRecordsSend.writeTo</callsite><line>107</line><superclass>null</superclass><logcall>org.apache.kafka.common.record.Logger.debug</logcall> <parameter>java.lang.String(name)Constructed overflow message batch for partition {} with length={}-org.apache.kafka.common.TopicPartition(name)topicPartition()-int(name)remaining</parameter><constant>Constructed overflow message batch for partition {} with length={}</constant><level>debug</level><callsite>org.apache.kafka.common.record.LazyDownConversionRecordsSend.buildOverflowBatch</callsite><line>64</line><superclass>org.apache.kafka.common.record.RecordsSend</superclass><logcall>org.apache.kafka.common.record.Logger.debug</logcall> <parameter>java.lang.String(name)Down-converted records for partition {} with length={}-org.apache.kafka.common.TopicPartition(name)topicPartition()-int(name)convertedRecords.sizeInBytes()</parameter><constant>Down-converted records for partition {} with length={}</constant><level>debug</level><callsite>org.apache.kafka.common.record.LazyDownConversionRecordsSend.writeTo</callsite><line>80</line><superclass>org.apache.kafka.common.record.RecordsSend</superclass><logcall>org.apache.kafka.common.record.Logger.debug</logcall> <parameter>java.lang.String(name)Received end transaction marker value version {}. Parsing as version {}-short(name)version-short(name)0</parameter><constant>Received end transaction marker value version {}. Parsing as version {}0</constant><level>debug</level><callsite>org.apache.kafka.common.record.EndTransactionMarker.deserializeValue</callsite><line>117</line><superclass>null</superclass><logcall>org.apache.kafka.common.record.Logger.warn</logcall> <parameter>java.lang.String(name)Record batch from {} with last offset {} exceeded max record batch size {} after cleaning (new size is {}). Consumers with version earlier than 0.10.1.0 may need to increase their fetch sizes.-org.apache.kafka.common.TopicPartition(name)partition-long(name)batch.lastOffset()-int(name)maxRecordBatchSize-int(name)filteredBatchSize</parameter><constant>Record batch from {} with last offset {} exceeded max record batch size {} after cleaning (new size is {}). Consumers with version earlier than 0.10.1.0 may need to increase their fetch sizes.</constant><level>warn</level><callsite>org.apache.kafka.common.record.MemoryRecords.filterTo</callsite><line>208</line><superclass>org.apache.kafka.common.record.AbstractRecords</superclass><logcall>org.apache.kafka.common.record.Logger.debug</logcall> <parameter>java.lang.String(name)Received unknown control record key version {}. Parsing as version {}-short(name)version-short(name)0</parameter><constant>Received unknown control record key version {}. Parsing as version {}0</constant><level>debug</level><callsite>org.apache.kafka.common.record.ControlRecordType.parseTypeId</callsite><line>84</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.Logger.warn</logcall> <parameter>java.lang.String(name)Server config {} should be prefixed with SASL mechanism name, ignoring config-java.lang.String(name)sasl.jaas.config</parameter><constant>Server config {} should be prefixed with SASL mechanism name, ignoring configsasl.jaas.config</constant><level>warn</level><callsite>org.apache.kafka.common.security.JaasContext.loadServerContext</callsite><line>69</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.Logger.debug</logcall> <parameter>java.lang.String(name)System property 'java.security.auth.login.config' and Kafka SASL property 'sasl.jaas.config' are not set, using default JAAS configuration.</parameter><constant>System property 'java.security.auth.login.config' and Kafka SASL property 'sasl.jaas.config' are not set, using default JAAS configuration.</constant><level>debug</level><callsite>org.apache.kafka.common.security.JaasContext.defaultContext</callsite><line>106</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.Logger.debug</logcall> <parameter>java.lang.String(name)System property 'java.security.auth.login.config' is not set, using default JAAS configuration.</parameter><constant>System property 'java.security.auth.login.config' is not set, using default JAAS configuration.</constant><level>debug</level><callsite>org.apache.kafka.common.security.JaasContext.defaultContext</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.Logger.error</logcall> <parameter>java.lang.String(name)JAAS configuration is present, but system property zookeeper.sasl.client is set to false, which disables SASL in the ZooKeeper client</parameter><constant>JAAS configuration is present, but system property zookeeper.sasl.client is set to false, which disables SASL in the ZooKeeper client</constant><level>error</level><callsite>org.apache.kafka.common.security.JaasUtils.isZkSecurityEnabled</callsite><line>48</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.info</logcall> <parameter>java.lang.String(name)Successfully logged in.</parameter><constant>Successfully logged in.</constant><level>info</level><callsite>org.apache.kafka.common.security.authenticator.AbstractLogin.login</callsite><line>61</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name){} for mechanism={}: {}-java.lang.String(name)connections.max.reauth.ms-java.lang.String(name)mechanism-java.lang.Long(name)connectionsMaxReauthMsByMechanism.get(mechanism)</parameter><constant>{} for mechanism={}: {}connections.max.reauth.ms</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.SaslServerAuthenticator</callsite><line>178</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Creating SaslServer for {} with mechanism {}-org.apache.kafka.common.security.kerberos.KerberosName(name)kerberosName-java.lang.String(name)saslMechanism</parameter><constant>Creating SaslServer for {} with mechanism {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.createSaslKerberosServer</callsite><line>215</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.warn</logcall> <parameter>java.lang.String(name)Cannot add private credential to subject; clients authentication may fail-org.ietf.jgss.GSSException(name)ex</parameter><constant>Cannot add private credential to subject; clients authentication may fail</constant><level>warn</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.createSaslKerberosServer</callsite><line>234</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Failed during {}: {}-java.lang.String(name)reauthInfo.authenticationOrReauthenticationText()-java.lang.String(name)e.getMessage()</parameter><constant>Failed during {}: {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.authenticate</callsite><line>306</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Beginning re-authentication: {}-org.apache.kafka.common.security.authenticator.SaslServerAuthenticator(name)this</parameter><constant>Beginning re-authentication: {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.reauthenticate</callsite><line>350</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Set SASL server state to {} during {}-org.apache.kafka.common.security.authenticator.SaslState(name)saslState-java.lang.String(name)reauthInfo.authenticationOrReauthenticationText()</parameter><constant>Set SASL server state to {} during {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.setSaslState</callsite><line>381</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Handling Kafka request {} during {}-org.apache.kafka.common.protocol.ApiKeys(name)apiKey-java.lang.String(name)reauthInfo.authenticationOrReauthenticationText()</parameter><constant>Handling Kafka request {} during {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.handleKafkaRequest</callsite><line>511</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Received client packet of length {} starting with bytes 0x{}, process as GSSAPI packet-int(name)requestBytes.length-java.lang.StringBuilder(name)tokenBuilder</parameter><constant>Received client packet of length {} starting with bytes 0x{}, process as GSSAPI packet</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.handleKafkaRequest</callsite><line>533</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)First client packet is not a SASL mechanism request, using default mechanism GSSAPI</parameter><constant>First client packet is not a SASL mechanism request, using default mechanism GSSAPI</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.handleKafkaRequest</callsite><line>536</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Using SASL mechanism '{}' provided by client-java.lang.String(name)clientMechanism</parameter><constant>Using SASL mechanism '{}' provided by client</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.handleHandshakeRequest</callsite><line>557</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)SASL mechanism '{}' requested by client is not supported-java.lang.String(name)clientMechanism</parameter><constant>SASL mechanism '{}' requested by client is not supported</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.handleHandshakeRequest</callsite><line>562</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)badMechanismErrorMessage</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.saslMechanismUnchanged</callsite><line>665</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Authentication complete; session max lifetime from broker config={} ms, credential expiration={} ({} ms); session expiration = {} ({} ms), sending {} ms to client-java.lang.Long(name)connectionsMaxReauthMs-java.util.Date(name)new Date(credentialExpirationMs)-java.lang.Long(name)Long.valueOf(credentialExpirationMs.longValue() - authenticationEndMs)-java.util.Date(name)new Date(authenticationEndMs + retvalSessionLifetimeMs)-long(name)retvalSessionLifetimeMs-long(name)retvalSessionLifetimeMs</parameter><constant>Authentication complete; session max lifetime from broker config={} ms, credential expiration={} ({} ms); session expiration = {} ({} ms), sending {} ms to client</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.calcCompletionTimesAndReturnSessionLifetimeMs</callsite><line>692</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Authentication complete; session max lifetime from broker config={} ms, credential expiration={} ({} ms); no session expiration, sending 0 ms to client-java.lang.Long(name)connectionsMaxReauthMs-java.util.Date(name)new Date(credentialExpirationMs)-java.lang.Long(name)Long.valueOf(credentialExpirationMs.longValue() - authenticationEndMs)</parameter><constant>Authentication complete; session max lifetime from broker config={} ms, credential expiration={} ({} ms); no session expiration, sending 0 ms to client</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.calcCompletionTimesAndReturnSessionLifetimeMs</callsite><line>699</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Authentication complete; session max lifetime from broker config={} ms, no credential expiration; session expiration = {} ({} ms), sending {} ms to client-java.lang.Long(name)connectionsMaxReauthMs-java.util.Date(name)new Date(authenticationEndMs + retvalSessionLifetimeMs)-long(name)retvalSessionLifetimeMs-long(name)retvalSessionLifetimeMs</parameter><constant>Authentication complete; session max lifetime from broker config={} ms, no credential expiration; session expiration = {} ({} ms), sending {} ms to client</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.calcCompletionTimesAndReturnSessionLifetimeMs</callsite><line>705</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Authentication complete; session max lifetime from broker config={} ms, no credential expiration; no session expiration, sending 0 ms to client-java.lang.Long(name)connectionsMaxReauthMs</parameter><constant>Authentication complete; session max lifetime from broker config={} ms, no credential expiration; no session expiration, sending 0 ms to client</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerAuthenticator.calcCompletionTimesAndReturnSessionLifetimeMs</callsite><line>710</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.trace</logcall> <parameter>java.lang.String(name){} acquired-org.apache.kafka.common.security.authenticator.LoginManager(name)this</parameter><constant>{} acquired</constant><level>trace</level><callsite>org.apache.kafka.common.security.authenticator.LoginManager.acquire</callsite><line>134</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.trace</logcall> <parameter>java.lang.String(name){} released-org.apache.kafka.common.security.authenticator.LoginManager(name)this</parameter><constant>{} released</constant><level>trace</level><callsite>org.apache.kafka.common.security.authenticator.LoginManager.release</callsite><line>155</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Set SASL client state to {}-org.apache.kafka.common.security.authenticator.SaslState(name)saslState</parameter><constant>Set SASL client state to {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.setSaslState</callsite><line>351</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Invalid SASL mechanism response, server may be expecting only GSSAPI tokens</parameter><constant>Invalid SASL mechanism response, server may be expecting only GSSAPI tokens</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.receiveKafkaResponse</callsite><line>524</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Finished {} with session expiration in {} ms and session re-authentication on or after {} ms-java.lang.String(name)authenticationOrReauthenticationText()-java.lang.Long(name)positiveSessionLifetimeMs-long(name)sessionLifetimeMsToUse</parameter><constant>Finished {} with session expiration in {} ms and session re-authentication on or after {} ms</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.setAuthenticationEndAndSessionReauthenticationTimes</callsite><line>625</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.debug</logcall> <parameter>java.lang.String(name)Finished {} with no session expiration and no session re-authentication-java.lang.String(name)authenticationOrReauthenticationText()</parameter><constant>Finished {} with no session expiration and no session re-authentication</constant><level>debug</level><callsite>org.apache.kafka.common.security.authenticator.SaslClientAuthenticator.setAuthenticationEndAndSessionReauthenticationTimes</callsite><line>629</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.trace</logcall> <parameter>java.lang.String(name)Client supplied realm: {} -java.lang.String(name)rc.getDefaultText()</parameter><constant>Client supplied realm: {} </constant><level>trace</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler.handleRealmCallback</callsite><line>63</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.authenticator.Logger.info</logcall> <parameter>java.lang.String(name)Successfully authenticated client: authenticationID={}; authorizationID={}.-java.lang.String(name)authenticationID-java.lang.String(name)authorizationID</parameter><constant>Successfully authenticated client: authenticationID={}; authorizationID={}.</constant><level>info</level><callsite>org.apache.kafka.common.security.authenticator.SaslServerCallbackHandler.handleAuthorizeCallback</callsite><line>70</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.debug</logcall> <parameter>java.lang.String(name)[Principal={}]: It is not a Kerberos ticket-java.lang.String(name)principal</parameter><constant>[Principal={}]: It is not a Kerberos ticket</constant><level>debug</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.login</callsite><line>126</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.debug</logcall> <parameter>java.lang.String(name)[Principal={}]: It is a Kerberos ticket-java.lang.String(name)principal</parameter><constant>[Principal={}]: It is a Kerberos ticket</constant><level>debug</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.login</callsite><line>131</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Error while waiting for Login thread to shutdown.-java.lang.String(name)principal-java.lang.InterruptedException(name)e</parameter><constant>[Principal={}]: Error while waiting for Login thread to shutdown.</constant><level>warn</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.close</callsite><line>270</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: TGT valid starting at: {}-java.lang.String(name)principal-java.util.Date(name)tgt.getStartTime()</parameter><constant>[Principal={}]: TGT valid starting at: {}</constant><level>info</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.getRefreshTime</callsite><line>308</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: TGT expires: {}-java.lang.String(name)principal-java.util.Date(name)tgt.getEndTime()</parameter><constant>[Principal={}]: TGT expires: {}</constant><level>info</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.getRefreshTime</callsite><line>309</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.debug</logcall> <parameter>java.lang.String(name)Found TGT with client principal '{}' and server principal '{}'.-java.lang.String(name)ticket.getClient().getName()-java.lang.String(name)ticket.getServer().getName()</parameter><constant>Found TGT with client principal '{}' and server principal '{}'.</constant><level>debug</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.getTGT</callsite><line>325</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Not attempting to re-login since the last re-login was attempted less than {} seconds before.-java.lang.String(name)principal-long(name)minTimeBeforeRelogin / 1000</parameter><constant>[Principal={}]: Not attempting to re-login since the last re-login was attempted less than {} seconds before.</constant><level>warn</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.hasSufficientTimeElapsed</callsite><line>336</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.info</logcall> <parameter>java.lang.String(name)Initiating logout for {}-java.lang.String(name)principal</parameter><constant>Initiating logout for {}</constant><level>info</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.reLogin</callsite><line>358</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.info</logcall> <parameter>java.lang.String(name)Initiating re-login for {}-java.lang.String(name)principal</parameter><constant>Initiating re-login for {}</constant><level>info</level><callsite>org.apache.kafka.common.security.kerberos.KerberosLogin.reLogin</callsite><line>368</line><superclass>org.apache.kafka.common.security.authenticator.AbstractLogin</superclass><logcall>org.apache.kafka.common.security.kerberos.Logger.trace</logcall> <parameter>java.lang.String(name)Kerberos return code could not be determined from {} due to {}-java.lang.Exception(name)exception-java.lang.Exception(name)e</parameter><constant>Kerberos return code could not be determined from {} due to {}</constant><level>trace</level><callsite>org.apache.kafka.common.security.kerberos.KerberosError.fromException</callsite><line>87</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Logged in without a token, this login cannot be used to establish client connections</parameter><constant>Logged in without a token, this login cannot be used to establish client connections</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.login</callsite><line>305</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Login succeeded; invoke commit() to commit it; current committed token count={}-int(name)committedTokenCount()</parameter><constant>Login succeeded; invoke commit() to commit it; current committed token count={}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.login</callsite><line>308</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.error</logcall> <parameter>java.lang.String(name)e.getMessage()-java.lang.Exception(name)e</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.identifyToken</callsite><line>318</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.info</logcall> <parameter>java.lang.String(name)Login failed: {} : {} (URI={})-java.lang.String(name)tokenCallback.errorCode()-java.lang.String(name)tokenCallback.errorDescription()-java.lang.String(name)tokenCallback.errorUri()</parameter><constant>Login failed: {} : {} (URI={})</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.identifyToken</callsite><line>324</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.error</logcall> <parameter>java.lang.String(name)e.getMessage()-java.io.IOException(name)e</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.identifyExtensions</callsite><line>339</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)CallbackHandler {} does not support SASL extensions. No extensions will be added-java.lang.String(name)callbackHandler.getClass().getName()</parameter><constant>CallbackHandler {} does not support SASL extensions. No extensions will be added</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.identifyExtensions</callsite><line>343</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.error</logcall> <parameter>java.lang.String(name)SASL Extensions cannot be null. Check whether your callback handler is explicitly setting them as null.</parameter><constant>SASL Extensions cannot be null. Check whether your callback handler is explicitly setting them as null.</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.identifyExtensions</callsite><line>346</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Nothing here to log out</parameter><constant>Nothing here to log out</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>357</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.trace</logcall> <parameter>java.lang.String(name)Logging out my token; current committed token count = {}-int(name)committedTokenCount()</parameter><constant>Logging out my token; current committed token count = {}</constant><level>trace</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>361</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Done logging out my token; committed token count is now {}-int(name)committedTokenCount()</parameter><constant>Done logging out my token; committed token count is now {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>370</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)No tokens to logout for this login</parameter><constant>No tokens to logout for this login</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>372</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.trace</logcall> <parameter>java.lang.String(name)Logging out my extensions</parameter><constant>Logging out my extensions</constant><level>trace</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>375</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Done logging out my extensions</parameter><constant>Done logging out my extensions</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>378</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)No extensions to logout for this login</parameter><constant>No extensions to logout for this login</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.logout</callsite><line>380</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Nothing here to commit</parameter><constant>Nothing here to commit</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.commit</callsite><line>389</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.trace</logcall> <parameter>java.lang.String(name)Committing my token; current committed token count = {}-int(name)committedTokenCount()</parameter><constant>Committing my token; current committed token count = {}</constant><level>trace</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.commit</callsite><line>394</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Done committing my token; committed token count is now {}-int(name)committedTokenCount()</parameter><constant>Done committing my token; committed token count is now {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.commit</callsite><line>398</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)No tokens to commit, this login cannot be used to establish client connections</parameter><constant>No tokens to commit, this login cannot be used to establish client connections</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.commit</callsite><line>400</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Login aborted</parameter><constant>Login aborted</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.abort</callsite><line>415</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.Logger.debug</logcall> <parameter>java.lang.String(name)Nothing here to abort</parameter><constant>Nothing here to abort</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule.abort</callsite><line>421</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Sending %%x01 response to server after receiving an error: {}-java.lang.String(name)jsonErrorResponse</parameter><constant>Sending %%x01 response to server after receiving an error: {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslClient.evaluateChallenge</callsite><line>102</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Successfully authenticated as {}-java.lang.String(name)callback.token().principalName()</parameter><constant>Successfully authenticated as {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslClient.evaluateChallenge</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Setting SASL/{} client state to {}-java.lang.String(name)OAUTHBEARER-org.apache.kafka.common.security.oauthbearer.internals.State(name)state</parameter><constant>Setting SASL/{} client state to {}OAUTHBEARER</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslClient.setState</callsite><line>155</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Extensions callback is not supported by client callback handler {}, no extensions will be added-javax.security.auth.callback.CallbackHandler(name)callbackHandler()</parameter><constant>Extensions callback is not supported by client callback handler {}, no extensions will be added</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslClient.retrieveCustomExtensions</callsite><line>164</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Found expiring credential with principal '{}'.-java.lang.String(name)token.principalName()</parameter><constant>Found expiring credential with principal '{}'.</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerRefreshingLogin.configure</callsite><line>105</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Found {} OAuth Bearer tokens in Subject's private credentials; the oldest expires at {}, will use the newest, which expires at {}-int(name)sortedByLifetime.size()-java.util.Date(name)new Date(sortedByLifetime.first().lifetimeMs())-java.util.Date(name)new Date(sortedByLifetime.last().lifetimeMs())</parameter><constant>Found {} OAuth Bearer tokens in Subject's private credentials; the oldest expires at {}, will use the newest, which expires at {}</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslClientCallbackHandler.handleCallback</callsite><line>126</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Received %x01 response from client after it received our error</parameter><constant>Received %x01 response from client after it received our error</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.evaluateResponse</callsite><line>88</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)e.getMessage()</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.evaluateResponse</callsite><line>97</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)errorMessage</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.process</callsite><line>164</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Successfully authenticate User={}-java.lang.String(name)token.principalName()</parameter><constant>Successfully authenticate User={}</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.process</callsite><line>181</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)errorMessage</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.processExtensions</callsite><line>198</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.Logger.debug</logcall> <parameter>java.lang.String(name)msg-java.lang.Exception(name)e</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.OAuthBearerSaslServer.handleCallbackError</callsite><line>218</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential re-login thread started.-java.lang.String(name)principalLogText()</parameter><constant>[Principal={}]: Expiring credential re-login thread started.</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>72</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential re-login sleep time was calculated to be in the past! Will explicitly adjust. ({})-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(nextRefreshMs)</parameter><constant>[Principal={}]: Expiring credential re-login sleep time was calculated to be in the past! Will explicitly adjust. ({})</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>87</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential re-login sleeping until: {}-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(nextRefreshMs)</parameter><constant>[Principal={}]: Expiring credential re-login sleeping until: {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>91</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential re-login thread has been interrupted and will exit.-java.lang.String(name)principalLogText()</parameter><constant>[Principal={}]: Expiring credential re-login thread has been interrupted and will exit.</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>95</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.error</logcall> <parameter>java.lang.String(name)e.getMessage()-org.apache.kafka.common.security.oauthbearer.internals.expiring.ExitRefresherThreadDueToIllegalStateException(name)e</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)String.format("[Principal=%s]: LoginException during login retry; will sleep %d seconds before trying again.",principalLogText(),DELAY_SECONDS_BEFORE_NEXT_RETRY_WHEN_RELOGIN_FAILS)-javax.security.auth.login.LoginException(name)loginException</parameter><constant>[Principal=%s]: LoginException during login retry; will sleep %d seconds before trying again.</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>113</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.error</logcall> <parameter>java.lang.String(name)[Principal={}]: Interrupted while trying to perform a subsequent expiring credential re-login after one or more initial re-login failures: re-login thread exiting now: {}-java.lang.String(name)principalLogText()-java.lang.String(name)String.valueOf(loginException.getMessage())</parameter><constant>[Principal={}]: Interrupted while trying to perform a subsequent expiring credential re-login after one or more initial re-login failures: re-login thread exiting now: {}</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.run</callsite><line>120</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)Successfully logged in.</parameter><constant>Successfully logged in.</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.login</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.debug</logcall> <parameter>java.lang.String(name)No Expiring Credential</parameter><constant>No Expiring Credential</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.login</callsite><line>212</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.error</logcall> <parameter>java.lang.String(name)[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Not starting refresh thread. This process is likely unable to authenticate SASL connections (for example, it is unlikely to be able to authenticate a connection with a Kafka Broker).-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(nowMs)-java.util.Date(name)new Date(expireTimeMs)</parameter><constant>[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Not starting refresh thread. This process is likely unable to authenticate SASL connections (for example, it is unlikely to be able to authenticate a connection with a Kafka Broker).</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.login</callsite><line>224</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.debug</logcall> <parameter>java.lang.String(name)[Principal={}]: It is an expiring credential-java.lang.String(name)principalLogText()</parameter><constant>[Principal={}]: It is an expiring credential</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.login</callsite><line>234</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Interrupted while waiting for re-login thread to shutdown.-java.lang.String(name)principalLogText()-java.lang.InterruptedException(name)e</parameter><constant>[Principal={}]: Interrupted while waiting for re-login thread to shutdown.</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.close</callsite><line>253</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: No Expiring credential found: will try again at {}-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(retvalNextRefreshMs)</parameter><constant>[Principal={}]: No Expiring credential found: will try again at {}</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>280</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.error</logcall> <parameter>java.lang.String(name)[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Exiting refresh thread.-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(relativeToMs)-java.util.Date(name)new Date(expireTimeMs)</parameter><constant>[Principal={}]: Current clock: {} is later than expiry {}. This may indicate a clock skew problem. Check that this host's and remote host's clocks are in sync. Exiting refresh thread.</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>288</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential already expired at {}: will try to refresh again at {}-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(expireTimeMs)-java.util.Date(name)new Date(retvalNextRefreshMs)</parameter><constant>[Principal={}]: Expiring credential already expired at {}: will try to refresh again at {}</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>302</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential refresh thread exiting because the expiring credential's current expiration time ({}) exceeds the latest possible refresh time ({}). This process will not be able to authenticate new SASL connections after that time (for example, it will not be able to authenticate a new connection with a Kafka Broker).-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(expireTimeMs)-java.util.Date(name)new Date(absoluteLastRefreshTimeMs.longValue())</parameter><constant>[Principal={}]: Expiring credential refresh thread exiting because the expiring credential's current expiration time ({}) exceeds the latest possible refresh time ({}). This process will not be able to authenticate new SASL connections after that time (for example, it will not be able to authenticate a new connection with a Kafka Broker).</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>309</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential valid from {} to {}-java.lang.String(name)expiringCredential.principalName()-java.util.Date(name)new java.util.Date(startMs)-java.util.Date(name)new java.util.Date(expireTimeMs)</parameter><constant>[Principal={}]: Expiring credential valid from {} to {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>318</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.warn</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential expires at {}, so buffer times of {} and {} seconds at the front and back, respectively, cannot be accommodated.  We will refresh at {}.-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(expireTimeMs)-long(name)refreshMinPeriodSeconds-long(name)clientRefreshBufferSeconds-java.util.Date(name)new Date(retvalRefreshMs)</parameter><constant>[Principal={}]: Expiring credential expires at {}, so buffer times of {} and {} seconds at the front and back, respectively, cannot be accommodated.  We will refresh at {}.</constant><level>warn</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>331</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Proposed refresh time of {} extends into the desired buffer time of {} seconds before expiration, so refresh it at the desired buffer begin point, at {}-java.lang.String(name)expiringCredential.principalName()-java.util.Date(name)new Date(proposedRefreshMs)-long(name)clientRefreshBufferSeconds-java.util.Date(name)new Date(beginningOfEndBufferTimeMs)</parameter><constant>[Principal={}]: Proposed refresh time of {} extends into the desired buffer time of {} seconds before expiration, so refresh it at the desired buffer begin point, at {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>342</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)[Principal={}]: Expiring credential re-login thread time adjusted from {} to {} since the former is sooner than the minimum refresh interval ({} seconds from now).-java.lang.String(name)principalLogText()-java.util.Date(name)new Date(proposedRefreshMs)-java.util.Date(name)new Date(endOfMinRefreshBufferTime)-long(name)refreshMinPeriodSeconds</parameter><constant>[Principal={}]: Expiring credential re-login thread time adjusted from {} to {} since the former is sooner than the minimum refresh interval ({} seconds from now).</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.refreshMs</callsite><line>351</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)Initiating logout for {}-java.lang.String(name)principalLogTextPriorToLogout</parameter><constant>Initiating logout for {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.reLogin</callsite><line>368</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.info</logcall> <parameter>java.lang.String(name)Initiating re-login for {}, logout() still needs to be called on a previous login = {}-java.lang.String(name)principalName-boolean(name)optionalCredentialToLogout != null</parameter><constant>Initiating re-login for {}, logout() still needs to be called on a previous login = {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.reLogin</callsite><line>388</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.error</logcall> <parameter>java.lang.String(name)No Expiring Credential after a supposedly-successful re-login</parameter><constant>No Expiring Credential after a supposedly-successful re-login</constant><level>error</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.reLogin</callsite><line>413</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.expiring.Logger.debug</logcall> <parameter>java.lang.String(name)[Principal={}]: It is an expiring credential after re-login as expected-java.lang.String(name)principalLogText()</parameter><constant>[Principal={}]: It is an expiring credential after re-login as expected</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.expiring.ExpiringCredentialRefreshingLogin.reLogin</callsite><line>426</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.unsecured.Logger.debug</logcall> <parameter>java.lang.String(name)Token not provided, this login cannot be used to establish client connections</parameter><constant>Token not provided, this login cannot be used to establish client connections</constant><level>debug</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.unsecured.OAuthBearerUnsecuredLoginCallbackHandler.handleTokenCallback</callsite><line>186</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.unsecured.Logger.info</logcall> <parameter>java.lang.String(name)Retrieved token with principal {}-java.lang.String(name)jws.principalName()</parameter><constant>Retrieved token with principal {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.unsecured.OAuthBearerUnsecuredLoginCallbackHandler.handleTokenCallback</callsite><line>218</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.oauthbearer.internals.unsecured.Logger.info</logcall> <parameter>java.lang.String(name)Successfully validated token with principal {}: {}-java.lang.String(name)unsecuredJwt.principalName()-java.lang.String(name)unsecuredJwt.claims().toString()</parameter><constant>Successfully validated token with principal {}: {}</constant><level>info</level><callsite>org.apache.kafka.common.security.oauthbearer.internals.unsecured.OAuthBearerUnsecuredValidatorCallbackHandler.handleCallback</callsite><line>173</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.scram.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Unsupported extensions will be ignored, supported {}, provided {}-java.util.Set<String>(name)SUPPORTED_EXTENSIONS-java.util.Set<String>(name)scramExtensions.map().keySet()</parameter><constant>Unsupported extensions will be ignored, supported {}, provided {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.scram.internals.ScramSaslServer.evaluateResponse</callsite><line>104</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.scram.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Setting SASL/{} server state to {}-org.apache.kafka.common.security.scram.internals.ScramMechanism(name)mechanism-org.apache.kafka.common.security.scram.internals.State(name)state</parameter><constant>Setting SASL/{} server state to {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.scram.internals.ScramSaslServer.setState</callsite><line>220</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.scram.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Extensions callback is not supported by client callback handler {}, no extensions will be added-javax.security.auth.callback.CallbackHandler(name)callbackHandler</parameter><constant>Extensions callback is not supported by client callback handler {}, no extensions will be added</constant><level>debug</level><callsite>org.apache.kafka.common.security.scram.internals.ScramSaslClient.evaluateChallenge</callsite><line>107</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.scram.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Setting SASL/{} client state to {}-org.apache.kafka.common.security.scram.internals.ScramMechanism(name)mechanism-org.apache.kafka.common.security.scram.internals.State(name)state</parameter><constant>Setting SASL/{} client state to {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.scram.internals.ScramSaslClient.setState</callsite><line>185</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.ssl.Logger.warn</logcall> <parameter>java.lang.String(name)Unrecognized client authentication configuration {}.  Falling back to NONE.  Recognized client authentication configurations are {}.-java.lang.String(name)key-java.lang.String(name)String.join(", ",SslClientAuth.VALUES.stream().map(null).collect(Collectors.toList()))</parameter><constant>Unrecognized client authentication configuration {}.  Falling back to NONE.  Recognized client authentication configurations are {}.</constant><level>warn</level><callsite>org.apache.kafka.common.security.ssl.SslEngineBuilder.createSslClientAuth</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.ssl.Logger.debug</logcall> <parameter>java.lang.String(name)Created SSL context with keystore {}, truststore {}-org.apache.kafka.common.security.ssl.SecurityStore(name)keystore-org.apache.kafka.common.security.ssl.SecurityStore(name)truststore</parameter><constant>Created SSL context with keystore {}, truststore {}</constant><level>debug</level><callsite>org.apache.kafka.common.security.ssl.SslEngineBuilder.createSSLContext</callsite><line>157</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.ssl.Logger.error</logcall> <parameter>java.lang.String(name)"Modification time of key store could not be obtained: " + path-java.io.IOException(name)e</parameter><constant>Modification time of key store could not be obtained: </constant><level>error</level><callsite>org.apache.kafka.common.security.ssl.SslEngineBuilder.lastModifiedMs</callsite><line>297</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.ssl.Logger.info</logcall> <parameter>java.lang.String(name)Created new {} SSL engine builder with keystore {} truststore {}-org.apache.kafka.common.network.Mode(name)mode-org.apache.kafka.common.security.ssl.SecurityStore(name)newSslEngineBuilder.keystore()-org.apache.kafka.common.security.ssl.SecurityStore(name)newSslEngineBuilder.truststore()</parameter><constant>Created new {} SSL engine builder with keystore {} truststore {}</constant><level>info</level><callsite>org.apache.kafka.common.security.ssl.SslFactory.reconfigure</callsite><line>120</line><superclass>null</superclass><logcall>org.apache.kafka.common.security.ssl.Logger.debug</logcall> <parameter>java.lang.String(name)Validation of dynamic config update of SSLFactory failed.-java.lang.Exception(name)e</parameter><constant>Validation of dynamic config update of SSLFactory failed.</constant><level>debug</level><callsite>org.apache.kafka.common.security.ssl.SslFactory.createNewSslEngineBuilder</callsite><line>165</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)"Registered signal handlers for " + String.join(", ",SIGNALS)</parameter><constant>Registered signal handlers for  | , </constant><level>info</level><callsite>org.apache.kafka.common.utils.LoggingSignalHandler.register</callsite><line>72</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)Terminating process due to signal {}-java.lang.Object(name)signal</parameter><constant>Terminating process due to signal {}</constant><level>info</level><callsite>org.apache.kafka.common.utils.LoggingSignalHandler.createSignalHandler</callsite><line>89</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Error reading the error stream-java.io.IOException(name)ioe</parameter><constant>Error reading the error stream</constant><level>warn</level><callsite>org.apache.kafka.common.utils.Shell.runCommand</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Interrupted while reading the error stream-java.lang.InterruptedException(name)ie</parameter><constant>Interrupted while reading the error stream</constant><level>warn</level><callsite>org.apache.kafka.common.utils.Shell.runCommand</callsite><line>124</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Error while closing the input stream-java.io.IOException(name)ioe</parameter><constant>Error while closing the input stream</constant><level>warn</level><callsite>org.apache.kafka.common.utils.Shell.runCommand</callsite><line>142</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Error while closing the error stream-java.io.IOException(name)ioe</parameter><constant>Error while closing the error stream</constant><level>warn</level><callsite>org.apache.kafka.common.utils.Shell.runCommand</callsite><line>150</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Non-atomic move of {} to {} succeeded after atomic move failed due to {}-java.nio.file.Path(name)source-java.nio.file.Path(name)target-java.lang.String(name)outer.getMessage()</parameter><constant>Non-atomic move of {} to {} succeeded after atomic move failed due to {}</constant><level>debug</level><callsite>org.apache.kafka.common.utils.Utils.atomicMoveWithFallback</callsite><line>807</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to close {} with type {}-java.lang.String(name)name-java.lang.String(name)closeable.getClass().getName()-java.lang.Throwable(name)t</parameter><constant>Failed to close {} with type {}</constant><level>warn</level><callsite>org.apache.kafka.common.utils.Utils.closeQuietly</callsite><line>847</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close {} with type {}-java.lang.String(name)name-java.lang.String(name)closeable.getClass().getName()-java.lang.Throwable(name)t</parameter><constant>Failed to close {} with type {}</constant><level>error</level><callsite>org.apache.kafka.common.utils.Utils.closeQuietly</callsite><line>858</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Error registering AppInfo mbean-javax.management.JMException(name)e</parameter><constant>Error registering AppInfo mbean</constant><level>warn</level><callsite>org.apache.kafka.common.utils.AppInfoParser.registerAppInfo</callsite><line>68</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)Error unregistering AppInfo mbean-javax.management.JMException(name)e</parameter><constant>Error unregistering AppInfo mbean</constant><level>warn</level><callsite>org.apache.kafka.common.utils.AppInfoParser.unregisterAppInfo</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)Kafka version: {}-java.lang.String(name)AppInfoParser.getVersion()</parameter><constant>Kafka version: {}</constant><level>info</level><callsite>org.apache.kafka.common.utils.AppInfoParser.AppInfo</callsite><line>117</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)Kafka commitId: {}-java.lang.String(name)AppInfoParser.getCommitId()</parameter><constant>Kafka commitId: {}</constant><level>info</level><callsite>org.apache.kafka.common.utils.AppInfoParser.AppInfo</callsite><line>118</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)Kafka startTimeMs: {}-long(name)startTimeMs</parameter><constant>Kafka startTimeMs: {}</constant><level>info</level><callsite>org.apache.kafka.common.utils.AppInfoParser.AppInfo</callsite><line>119</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught exception in thread '{}':-java.lang.String(name)name-java.lang.Throwable(name)e</parameter><constant>Uncaught exception in thread '{}':</constant><level>error</level><callsite>org.apache.kafka.common.utils.KafkaThread.configureThread</callsite><line>51</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)addPrefix(message)</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>504</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>511</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>518</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)addPrefix(message)-Object[](name)args</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>525</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>532</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>539</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>546</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>553</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-Object[](name)argArray</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>560</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>trace</level><callsite>org.apache.kafka.common.utils.LogContext.trace</callsite><line>567</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)addPrefix(message)</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>574</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>581</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>588</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)addPrefix(message)-Object[](name)args</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>595</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>602</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>609</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>616</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>623</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-Object[](name)arguments</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>630</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.debug</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>debug</level><callsite>org.apache.kafka.common.utils.LogContext.debug</callsite><line>637</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)addPrefix(message)</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>643</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>648</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>653</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)addPrefix(message)-Object[](name)args</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>658</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>663</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>668</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>673</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>678</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-Object[](name)arguments</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>683</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.warn</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.common.utils.LogContext.warn</callsite><line>688</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)addPrefix(message)</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>693</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>698</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>703</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)addPrefix(message)-Object[](name)args</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>708</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>713</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>718</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>723</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>728</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-Object[](name)arguments</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>733</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.error</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.common.utils.LogContext.error</callsite><line>738</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)addPrefix(message)</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>743</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>748</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)addPrefix(message)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>753</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)addPrefix(message)-Object[](name)args</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>758</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>763</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>768</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>773</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-java.lang.Object(name)arg1-java.lang.Object(name)arg2</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>778</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(format)-Object[](name)arguments</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>783</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.info</logcall> <parameter>org.apache.kafka.common.utils.Marker(name)marker-java.lang.String(name)addPrefix(msg)-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.common.utils.LogContext.info</callsite><line>788</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)Invoking {} at {}-java.util.concurrent.Callable<T>(name)callable-java.lang.Long(name)now</parameter><constant>Invoking {} at {}</constant><level>trace</level><callsite>org.apache.kafka.common.utils.MockScheduler.schedule</callsite><line>105</line><superclass>null</superclass><logcall>org.apache.kafka.common.utils.Logger.trace</logcall> <parameter>java.lang.String(name)Scheduling {} for {} ms from now.-java.util.concurrent.Callable<T>(name)callable-long(name)delayMs</parameter><constant>Scheduling {} for {} ms from now.</constant><level>trace</level><callsite>org.apache.kafka.common.utils.MockScheduler.schedule</callsite><line>117</line><superclass>null</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Writing line to {}: {}-java.lang.String(name)logFilename()-java.lang.Object(name)record.value()</parameter><constant>Writing line to {}: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSinkTask.put</callsite><line>79</line><superclass>org.apache.kafka.connect.sink.SinkTask</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Flushing output stream for {}-java.lang.String(name)logFilename()</parameter><constant>Flushing output stream for {}</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSinkTask.flush</callsite><line>86</line><superclass>org.apache.kafka.connect.sink.SinkTask</superclass><logcall>org.apache.kafka.connect.file.Logger.debug</logcall> <parameter>java.lang.String(name)Found previous offset, trying to skip to file offset {}-java.lang.Object(name)lastRecordedOffset</parameter><constant>Found previous offset, trying to skip to file offset {}</constant><level>debug</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>89</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.error</logcall> <parameter>java.lang.String(name)Error while trying to seek to previous offset in file {}: -java.lang.String(name)filename-java.io.IOException(name)e</parameter><constant>Error while trying to seek to previous offset in file {}: </constant><level>error</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>96</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.debug</logcall> <parameter>java.lang.String(name)Skipped to offset {}-java.lang.Object(name)lastRecordedOffset</parameter><constant>Skipped to offset {}</constant><level>debug</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>100</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.debug</logcall> <parameter>java.lang.String(name)Opened {} for reading-java.lang.String(name)logFilename()</parameter><constant>Opened {} for reading</constant><level>debug</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>107</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.warn</logcall> <parameter>java.lang.String(name)Couldn't find file {} for FileStreamSourceTask, sleeping to wait for it to be created-java.lang.String(name)logFilename()</parameter><constant>Couldn't find file {} for FileStreamSourceTask, sleeping to wait for it to be created</constant><level>warn</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>109</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.error</logcall> <parameter>java.lang.String(name)Error while trying to open file {}: -java.lang.String(name)filename-java.io.IOException(name)e</parameter><constant>Error while trying to open file {}: </constant><level>error</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>115</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Read {} bytes from {}-int(name)nread-java.lang.String(name)logFilename()</parameter><constant>Read {} bytes from {}</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>136</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Read a line from {}-java.lang.String(name)logFilename()</parameter><constant>Read a line from {}</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.poll</callsite><line>150</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Stopping</parameter><constant>Stopping</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.stop</callsite><line>209</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.trace</logcall> <parameter>java.lang.String(name)Closed input stream</parameter><constant>Closed input stream</constant><level>trace</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.stop</callsite><line>214</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.file.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close FileStreamSourceTask stream: -java.io.IOException(name)e</parameter><constant>Failed to close FileStreamSourceTask stream: </constant><level>error</level><callsite>org.apache.kafka.connect.file.FileStreamSourceTask.stop</callsite><line>217</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.log4j.helpers.LogLog.debug</logcall> <parameter>java.lang.String(name)"Kafka producer connected to " + brokerList</parameter><constant>Kafka producer connected to </constant><level>debug</level><callsite>org.apache.kafka.log4jappender.KafkaLog4jAppender.activateOptions</callsite><line>297</line><superclass>org.apache.log4j.AppenderSkeleton</superclass><logcall>org.apache.log4j.helpers.LogLog.debug</logcall> <parameter>java.lang.String(name)"Logging for topic: " + topic</parameter><constant>Logging for topic: </constant><level>debug</level><callsite>org.apache.kafka.log4jappender.KafkaLog4jAppender.activateOptions</callsite><line>298</line><superclass>org.apache.log4j.AppenderSkeleton</superclass><logcall>org.apache.log4j.helpers.LogLog.debug</logcall> <parameter>java.lang.String(name)"[" + new Date(event.getTimeStamp()) + "]"+ message</parameter><constant>[ | ]</constant><level>debug</level><callsite>org.apache.kafka.log4jappender.KafkaLog4jAppender.append</callsite><line>308</line><superclass>org.apache.log4j.AppenderSkeleton</superclass><logcall>org.apache.log4j.helpers.LogLog.debug</logcall> <parameter>java.lang.String(name)Exception while getting response-java.lang.Exception(name)ex</parameter><constant>Exception while getting response</constant><level>debug</level><callsite>org.apache.kafka.log4jappender.KafkaLog4jAppender.append</callsite><line>317</line><superclass>org.apache.log4j.AppenderSkeleton</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Usage: ConnectDistributed worker.properties</parameter><constant>Usage: ConnectDistributed worker.properties</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.main</callsite><line>65</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.error</logcall> <parameter>java.lang.String(name)Stopping due to error-java.lang.Throwable(name)t</parameter><constant>Stopping due to error</constant><level>error</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.main</callsite><line>84</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Scanning for plugin classes. This might take a moment ...</parameter><constant>Scanning for plugin classes. This might take a moment ...</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.startConnect</callsite><line>90</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka cluster ID: {}-java.lang.String(name)kafkaClusterId</parameter><constant>Kafka cluster ID: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.startConnect</callsite><line>96</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect distributed worker initialization took {}ms-long(name)time.hiResClockMs() - initStart</parameter><constant>Kafka Connect distributed worker initialization took {}ms</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.startConnect</callsite><line>128</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.error</logcall> <parameter>java.lang.String(name)Failed to start Connect-java.lang.Exception(name)e</parameter><constant>Failed to start Connect</constant><level>error</level><callsite>org.apache.kafka.connect.cli.ConnectDistributed.startConnect</callsite><line>132</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]</parameter><constant>Usage: ConnectStandalone worker.properties connector1.properties [connector2.properties ...]</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>63</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect standalone worker initializing ...</parameter><constant>Kafka Connect standalone worker initializing ...</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>69</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Scanning for plugin classes. This might take a moment ...</parameter><constant>Scanning for plugin classes. This might take a moment ...</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>78</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka cluster ID: {}-java.lang.String(name)kafkaClusterId</parameter><constant>Kafka cluster ID: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>84</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect standalone worker initialization took {}ms-long(name)time.hiResClockMs() - initStart</parameter><constant>Kafka Connect standalone worker initialization took {}ms</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>100</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.error</logcall> <parameter>java.lang.String(name)Failed to create job for {}-java.lang.String(name)connectorPropsFile</parameter><constant>Failed to create job for {}</constant><level>error</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.info</logcall> <parameter>java.lang.String(name)Created connector {}-java.lang.String(name)info.result().name()</parameter><constant>Created connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>112</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.error</logcall> <parameter>java.lang.String(name)Stopping after connector error-java.lang.Throwable(name)t</parameter><constant>Stopping after connector error</constant><level>error</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>121</line><superclass>null</superclass><logcall>org.apache.kafka.connect.cli.Logger.error</logcall> <parameter>java.lang.String(name)Stopping due to error-java.lang.Throwable(name)t</parameter><constant>Stopping due to error</constant><level>error</level><callsite>org.apache.kafka.connect.cli.ConnectStandalone.main</callsite><line>130</line><superclass>null</superclass><logcall>org.apache.kafka.connect.connector.policy.Logger.info</logcall> <parameter>java.lang.String(name)Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden</parameter><constant>Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden</constant><level>info</level><callsite>org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy.configure</callsite><line>44</line><superclass>org.apache.kafka.connect.connector.policy.AbstractConnectorClientConfigOverridePolicy</superclass><logcall>org.apache.kafka.connect.connector.policy.Logger.info</logcall> <parameter>java.lang.String(name)Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden</parameter><constant>Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden</constant><level>info</level><callsite>org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy.configure</callsite><line>45</line><superclass>org.apache.kafka.connect.connector.policy.AbstractConnectorClientConfigOverridePolicy</superclass><logcall>org.apache.kafka.connect.connector.policy.Logger.info</logcall> <parameter>java.lang.String(name)Setting up Principal policy for ConnectorClientConfigOverride. This will allow `sasl` client configuration to be overridden.</parameter><constant>Setting up Principal policy for ConnectorClientConfigOverride. This will allow `sasl` client configuration to be overridden.</constant><level>info</level><callsite>org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy.configure</callsite><line>54</line><superclass>org.apache.kafka.connect.connector.policy.AbstractConnectorClientConfigOverridePolicy</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name)Registering Connect metrics with JMX for worker '{}'-java.lang.String(name)workerId</parameter><constant>Registering Connect metrics with JMX for worker '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.ConnectMetrics.ConnectMetrics</callsite><line>83</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name)Unregistering Connect metrics with JMX for worker '{}'-java.lang.String(name)workerId</parameter><constant>Unregistering Connect metrics with JMX for worker '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.ConnectMetrics.stop</callsite><line>155</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Setting offsets for topic partitions {}-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-java.util.Map<TopicPartition,Long>(name)offsets</parameter><constant>{} Setting offsets for topic partitions {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.offset</callsite><line>63</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Setting offset for topic partition {} to {}-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-org.apache.kafka.common.TopicPartition(name)tp-long(name)offset</parameter><constant>{} Setting offset for topic partition {} to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.offset</callsite><line>69</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Setting timeout to {} ms-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-long(name)timeoutMs</parameter><constant>{} Setting timeout to {} ms</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.timeout</callsite><line>87</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Connector is paused, so not pausing consumer's partitions {}-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-TopicPartition[](name)partitions</parameter><constant>{} Connector is paused, so not pausing consumer's partitions {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.pause</callsite><line>115</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Pausing partitions {}. Connector is not paused.-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-TopicPartition[](name)partitions</parameter><constant>{} Pausing partitions {}. Connector is not paused.</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.pause</callsite><line>118</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Connector is paused, so not resuming consumer's partitions {}-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-TopicPartition[](name)partitions</parameter><constant>{} Connector is paused, so not resuming consumer's partitions {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.resume</callsite><line>133</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Resuming partitions: {}-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this-TopicPartition[](name)partitions</parameter><constant>{} Resuming partitions: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.resume</callsite><line>136</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Requesting commit-org.apache.kafka.connect.runtime.WorkerSinkTaskContext(name)this</parameter><constant>{} Requesting commit</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTaskContext.requestCommit</callsite><line>149</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka Connect instance created</parameter><constant>Kafka Connect instance created</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.Connect.Connect</callsite><line>42</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect starting</parameter><constant>Kafka Connect starting</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Connect.start</callsite><line>50</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect started</parameter><constant>Kafka Connect started</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Connect.start</callsite><line>56</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect stopping</parameter><constant>Kafka Connect stopping</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Connect.stop</callsite><line>66</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Kafka Connect stopped</parameter><constant>Kafka Connect stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Connect.stop</callsite><line>71</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Interrupted waiting for Kafka Connect to shutdown</parameter><constant>Interrupted waiting for Kafka Connect to shutdown</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Connect.awaitStop</callsite><line>82</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Interrupted in shutdown hook while waiting for Kafka Connect startup to finish</parameter><constant>Interrupted in shutdown hook while waiting for Kafka Connect startup to finish</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Connect.run</callsite><line>98</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Scheduling a restart of connector {} in {} ms-java.lang.String(name)connectorName-long(name)ttl</parameter><constant>Scheduling a restart of connector {} in {} ms</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerConfigTransformer.scheduleReload</callsite><line>89</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during connector restart: -java.lang.Throwable(name)error</parameter><constant>Unexpected error during connector restart: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConfigTransformer.scheduleReload</callsite><line>94</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)b.toString()</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerInfo.logAll</callsite><line>71</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Graceful shutdown of offset commitOffsets thread timed out.</parameter><constant>Graceful shutdown of offset commitOffsets thread timed out.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter.close</callsite><line>71</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name)Offset commit thread was cancelled by another thread while removing connector task with id: {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Offset commit thread was cancelled by another thread while removing connector task with id: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter.remove</callsite><line>102</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Committing offsets-org.apache.kafka.connect.runtime.WorkerSourceTask(name)workerTask</parameter><constant>{} Committing offsets</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter.commit</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to commit offsets-org.apache.kafka.connect.runtime.WorkerSourceTask(name)workerTask</parameter><constant>{} Failed to commit offsets</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter.commit</callsite><line>114</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Unhandled exception when committing: -org.apache.kafka.connect.runtime.WorkerSourceTask(name)workerTask-java.lang.Throwable(name)t</parameter><constant>{} Unhandled exception when committing: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.SourceTaskOffsetCommitter.commit</callsite><line>119</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release. The specified value '{}' matches the default, so this property can be safely removed from the worker configuration.-java.lang.String(name)propName-java.lang.String(name)prefixNotice-java.lang.String(name)propValue</parameter><constant>Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release. The specified value '{}' matches the default, so this property can be safely removed from the worker configuration.</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerConfig.logDeprecatedProperty</callsite><line>332</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release. The specified value '{}' does NOT match the default and recommended value '{}'.-java.lang.String(name)propName-java.lang.String(name)prefixNotice-java.lang.String(name)propValue-java.lang.String(name)defaultValue</parameter><constant>Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release. The specified value '{}' does NOT match the default and recommended value '{}'.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerConfig.logDeprecatedProperty</callsite><line>340</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release.-java.lang.String(name)propName-java.lang.String(name)prefixNotice</parameter><constant>Worker configuration property '{}'{} is deprecated and may be removed in an upcoming release.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerConfig.logDeprecatedProperty</callsite><line>349</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task failed initialization and will not be started.-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Task failed initialization and will not be started.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.initialize</callsite><line>141</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not stop task-java.lang.Throwable(name)t</parameter><constant>Could not stop task</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.close</callsite><line>160</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not close consumer-java.lang.Throwable(name)t</parameter><constant>Could not close consumer</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.close</callsite><line>166</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not close transformation chain-java.lang.Throwable(name)t</parameter><constant>Could not close transformation chain</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.close</callsite><line>172</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Commit of offsets timed out-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Commit of offsets timed out</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.iteration</callsite><line>217</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Consumer woken up-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Consumer woken up</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.iteration</callsite><line>226</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Received out of order commit callback for sequence number {}, but most recent sequence number is {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-long(name)seqno-int(name)commitSeqno</parameter><constant>{} Received out of order commit callback for sequence number {}, but most recent sequence number is {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onCommitCompleted</callsite><line>253</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Commit of offsets threw an unexpected exception for sequence number {}: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-long(name)seqno-java.util.Map<TopicPartition,OffsetAndMetadata>(name)committedOffsets-java.lang.Throwable(name)error</parameter><constant>{} Commit of offsets threw an unexpected exception for sequence number {}: {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onCommitCompleted</callsite><line>259</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Finished offset commit successfully in {} ms for sequence number {}: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-long(name)durationMillis-long(name)seqno-java.util.Map<TopicPartition,OffsetAndMetadata>(name)committedOffsets</parameter><constant>{} Finished offset commit successfully in {} ms for sequence number {}: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onCommitCompleted</callsite><line>264</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Setting last committed offsets to {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.util.Map<TopicPartition,OffsetAndMetadata>(name)committedOffsets</parameter><constant>{} Setting last committed offsets to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onCommitCompleted</callsite><line>267</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Initializing and starting task for topics {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-String[](name)topics</parameter><constant>{} Initializing and starting task for topics {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart</callsite><line>291</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Initializing and starting task for topics regex {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.String(name)topicsRegexStr</parameter><constant>{} Initializing and starting task for topics regex {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart</callsite><line>296</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Sink task finished initialization and start-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Sink task finished initialization and start</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart</callsite><line>301</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Polling consumer with timeout {} ms-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-long(name)timeoutMs</parameter><constant>{} Polling consumer with timeout {} ms</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.poll</callsite><line>315</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Polling returned {} messages-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-int(name)msgs.count()</parameter><constant>{} Polling returned {} messages</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.poll</callsite><line>318</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Committing offsets synchronously using sequence number {}: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-int(name)seqno-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets</parameter><constant>{} Committing offsets synchronously using sequence number {}: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.doCommitSync</callsite><line>330</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Committing offsets asynchronously using sequence number {}: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-int(name)seqno-java.util.Map<TopicPartition,OffsetAndMetadata>(name)offsets</parameter><constant>{} Committing offsets asynchronously using sequence number {}: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.doCommitAsync</callsite><line>344</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Calling task.preCommit with current offsets: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.util.Map<TopicPartition,OffsetAndMetadata>(name)currentOffsets</parameter><constant>{} Calling task.preCommit with current offsets: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>377</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Offset commit failed during close-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Offset commit failed during close</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>381</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Offset commit failed, rewinding to last committed offsets-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Offset commit failed, rewinding to last committed offsets</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>384</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Rewinding topic partition {} to offset {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.common.TopicPartition(name)entry.getKey()-long(name)entry.getValue().offset()</parameter><constant>{} Rewinding topic partition {} to offset {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>386</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Closing the task before committing the offsets: {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.util.Map<TopicPartition,OffsetAndMetadata>(name)currentOffsets</parameter><constant>{} Closing the task before committing the offsets: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>395</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Skipping offset commit, task opted-out by returning no offsets from preCommit-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Skipping offset commit, task opted-out by returning no offsets from preCommit</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>401</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Ignoring invalid task provided offset {}/{} -- not yet consumed, taskOffset={} currentOffset={}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.clients.consumer.OffsetAndMetadata(name)taskProvidedOffset-long(name)taskOffset-long(name)currentOffset</parameter><constant>{} Ignoring invalid task provided offset {}/{} -- not yet consumed, taskOffset={} currentOffset={}</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>416</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Ignoring invalid task provided offset {}/{} -- partition not assigned, assignment={}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.common.TopicPartition(name)partition-org.apache.kafka.clients.consumer.OffsetAndMetadata(name)taskProvidedOffset-java.util.Set<TopicPartition>(name)consumer.assignment()</parameter><constant>{} Ignoring invalid task provided offset {}/{} -- partition not assigned, assignment={}</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>420</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Skipping offset commit, no change since last commit-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this</parameter><constant>{} Skipping offset commit, no change since last commit</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.commitOffsets</callsite><line>426</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Consuming and converting message in topic '{}' partition {} at offset {} and timestamp {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.String(name)msg.topic()-int(name)msg.partition()-long(name)msg.offset()-long(name)msg.timestamp()</parameter><constant>{} Consuming and converting message in topic '{}' partition {} at offset {} and timestamp {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages</callsite><line>459</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Converters and transformations returned null, possibly because of too many retries, so dropping record in topic '{}' partition {} at offset {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.String(name)msg.topic()-int(name)msg.partition()-long(name)msg.offset()</parameter><constant>{} Converters and transformations returned null, possibly because of too many retries, so dropping record in topic '{}' partition {} at offset {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.convertMessages</callsite><line>473</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Applying transformations to record in topic '{}' partition {} at offset {} and timestamp {} with key {} and value {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.String(name)msg.topic()-int(name)msg.partition()-long(name)msg.offset()-java.lang.Long(name)timestamp-java.lang.Object(name)keyAndSchema.value()-java.lang.Object(name)valueAndSchema.value()</parameter><constant>{} Applying transformations to record in topic '{}' partition {} at offset {} and timestamp {} with key {} and value {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.convertAndTransformRecord</callsite><line>504</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Delivering batch of {} messages to task-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-int(name)messageBatch.size()</parameter><constant>{} Delivering batch of {} messages to task</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages</callsite><line>536</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} RetriableException from SinkTask:-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.connect.errors.RetriableException(name)e</parameter><constant>{} RetriableException from SinkTask:</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages</callsite><line>551</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted.-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages</callsite><line>558</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Rewind {} to offset {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.common.TopicPartition(name)tp-java.lang.Long(name)offset</parameter><constant>{} Rewind {} to offset {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.rewind</callsite><line>573</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Cannot rewind {} to null offset-org.apache.kafka.connect.runtime.WorkerSinkTask(name)this-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>{} Cannot rewind {} to null offset</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.rewind</callsite><line>578</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Partitions assigned {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)WorkerSinkTask.this-java.util.Collection<TopicPartition>(name)partitions</parameter><constant>{} Partitions assigned {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onPartitionsAssigned</callsite><line>623</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Assigned topic partition {} with offset {}-org.apache.kafka.connect.runtime.WorkerSinkTask(name)WorkerSinkTask.this-org.apache.kafka.common.TopicPartition(name)tp-long(name)pos</parameter><constant>{} Assigned topic partition {} with offset {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onPartitionsAssigned</callsite><line>630</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Partitions revoked-org.apache.kafka.connect.runtime.WorkerSinkTask(name)WorkerSinkTask.this</parameter><constant>{} Partitions revoked</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSinkTask.onPartitionsRevoked</callsite><line>664</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task threw an uncaught and unrecoverable exception during shutdown-org.apache.kafka.connect.runtime.WorkerTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Task threw an uncaught and unrecoverable exception during shutdown</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerTask.doClose</callsite><line>158</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task threw an uncaught and unrecoverable exception-org.apache.kafka.connect.runtime.WorkerTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Task threw an uncaught and unrecoverable exception</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerTask.doRun</callsite><line>179</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task is being killed and will not recover until manually restarted-org.apache.kafka.connect.runtime.WorkerTask(name)this</parameter><constant>{} Task is being killed and will not recover until manually restarted</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerTask.doRun</callsite><line>180</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Worker starting</parameter><constant>Worker starting</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.start</callsite><line>182</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Worker started</parameter><constant>Worker started</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.start</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Worker stopping</parameter><constant>Worker stopping</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.stop</callsite><line>194</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Shutting down connectors {} uncleanly; herder should have shut down connectors before the Worker is stopped-java.util.Set<String>(name)connectors.keySet()</parameter><constant>Shutting down connectors {} uncleanly; herder should have shut down connectors before the Worker is stopped</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.Worker.stop</callsite><line>200</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Shutting down tasks {} uncleanly; herder should have shut down tasks before the Worker is stopped-java.util.Set<ConnectorTaskId>(name)tasks.keySet()</parameter><constant>Shutting down tasks {} uncleanly; herder should have shut down tasks before the Worker is stopped</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.Worker.stop</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Worker stopped</parameter><constant>Worker stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.stop</callsite><line>215</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Creating connector {} of type {}-java.lang.String(name)connName-java.lang.String(name)connClass</parameter><constant>Creating connector {} of type {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startConnector</callsite><line>246</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Instantiated connector {} with version {} of type {}-java.lang.String(name)connName-java.lang.String(name)connector.version()-java.lang.Class<>(name)connector.getClass()</parameter><constant>Instantiated connector {} with version {} of type {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startConnector</callsite><line>249</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Failed to start connector {}-java.lang.String(name)connName-java.lang.Throwable(name)t</parameter><constant>Failed to start connector {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Worker.startConnector</callsite><line>255</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Finished creating connector {}-java.lang.String(name)connName</parameter><constant>Finished creating connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startConnector</callsite><line>268</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name)Reconfiguring connector tasks for {}-java.lang.String(name)connName</parameter><constant>Reconfiguring connector tasks for {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs</callsite><line>304</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Stopping connector {}-java.lang.String(name)connName</parameter><constant>Stopping connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.stopConnector</callsite><line>353</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Ignoring stop request for unowned connector {}-java.lang.String(name)connName</parameter><constant>Ignoring stop request for unowned connector {}</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.Worker.stopConnector</callsite><line>357</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Stopped connector {}-java.lang.String(name)connName</parameter><constant>Stopped connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.stopConnector</callsite><line>369</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Creating task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Creating task {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>414</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Instantiated task {} with version {} of type {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id-java.lang.String(name)task.version()-java.lang.String(name)taskClass.getName()</parameter><constant>Instantiated task {} with version {} of type {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the key converter {} for task {} using the worker config-java.lang.Class<>(name)keyConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the key converter {} for task {} using the worker config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>441</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the key converter {} for task {} using the connector config-java.lang.Class<>(name)keyConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the key converter {} for task {} using the connector config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>443</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the value converter {} for task {} using the worker config-java.lang.Class<>(name)valueConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the value converter {} for task {} using the worker config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>447</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the value converter {} for task {} using the connector config-java.lang.Class<>(name)valueConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the value converter {} for task {} using the connector config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>449</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the header converter {} for task {} using the worker config-java.lang.Class<>(name)headerConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the header converter {} for task {} using the worker config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>454</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Set up the header converter {} for task {} using the connector config-java.lang.Class<>(name)headerConverter.getClass()-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Set up the header converter {} for task {} using the connector config</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>456</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Failed to start task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id-java.lang.Throwable(name)t</parameter><constant>Failed to start task {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Worker.startTask</callsite><line>464</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Initializing: {}-org.apache.kafka.connect.runtime.TransformationChain<SourceRecord>(name)transformationChain</parameter><constant>Initializing: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.buildWorkerTask</callsite><line>507</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Initializing: {}-org.apache.kafka.connect.runtime.TransformationChain<SinkRecord>(name)transformationChain</parameter><constant>Initializing: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.buildWorkerTask</callsite><line>522</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Tasks must be a subclass of either SourceTask or SinkTask-org.apache.kafka.connect.connector.Task(name)task</parameter><constant>Tasks must be a subclass of either SourceTask or SinkTask</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Worker.buildWorkerTask</callsite><line>533</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Ignoring stop request for unowned task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId</parameter><constant>Ignoring stop request for unowned task {}</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.Worker.stopTask</callsite><line>680</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Stopping task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)task.id()</parameter><constant>Stopping task {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.stopTask</callsite><line>684</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Ignoring await stop request for non-present task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId</parameter><constant>Ignoring await stop request for non-present task {}</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.Worker.awaitStopTask</callsite><line>710</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name)Graceful stop of task {} failed.-org.apache.kafka.connect.util.ConnectorTaskId(name)task.id()</parameter><constant>Graceful stop of task {} failed.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.Worker.awaitStopTask</callsite><line>715</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name)Graceful stop of task {} succeeded.-org.apache.kafka.connect.util.ConnectorTaskId(name)task.id()</parameter><constant>Graceful stop of task {} succeeded.</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.Worker.awaitStopTask</callsite><line>718</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name)Setting connector {} state to {}-java.lang.String(name)connName-org.apache.kafka.connect.runtime.TargetState(name)state</parameter><constant>Setting connector {} state to {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.Worker.setTargetState</callsite><line>791</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Task failed initialization and will not be started.-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Task failed initialization and will not be started.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.initialize</callsite><line>143</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not close producer-java.lang.Throwable(name)t</parameter><constant>Could not close producer</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.close</callsite><line>157</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not close transformation chain-java.lang.Throwable(name)t</parameter><constant>Could not close transformation chain</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.close</callsite><line>163</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name)Could not stop task-java.lang.Throwable(name)t</parameter><constant>Could not stop task</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.tryStop</callsite><line>190</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Source task finished initialization and start-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Source task finished initialization and start</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.execute</callsite><line>200</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Nothing to send to Kafka. Polling source for additional records-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Nothing to send to Kafka. Polling source for additional records</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.execute</callsite><line>219</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name)"{} About to send " + toSend.size() + " records to Kafka"-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} About to send  |  records to Kafka</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.execute</callsite><line>228</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} failed to poll records from SourceTask. Will retry operation.-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-org.apache.kafka.common.KafkaException(name)e</parameter><constant>{} failed to poll records from SourceTask. Will retry operation.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.poll</callsite><line>247</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Appending record with key {}, value {}-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-java.lang.Object(name)record.key()-java.lang.Object(name)record.value()</parameter><constant>{} Appending record with key {}, value {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords</callsite><line>301</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} failed to send record to {}:-org.apache.kafka.connect.runtime.WorkerSourceTask(name)WorkerSourceTask.this-java.lang.String(name)topic-java.lang.Exception(name)e</parameter><constant>{} failed to send record to {}:</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords</callsite><line>330</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Failed record: {}-org.apache.kafka.connect.runtime.WorkerSourceTask(name)WorkerSourceTask.this-org.apache.kafka.connect.source.SourceRecord(name)preTransformRecord</parameter><constant>{} Failed record: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords</callsite><line>331</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Wrote record successfully: topic {} partition {} offset {}-org.apache.kafka.connect.runtime.WorkerSourceTask(name)WorkerSourceTask.this-java.lang.String(name)recordMetadata.topic()-int(name)recordMetadata.partition()-long(name)recordMetadata.offset()</parameter><constant>{} Wrote record successfully: topic {} partition {} offset {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords</callsite><line>333</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Failed to send {}, backing off before retrying:-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-org.apache.kafka.clients.producer.ProducerRecord<byte[],byte[]>(name)producerRecord-org.apache.kafka.common.errors.RetriableException(name)e</parameter><constant>{} Failed to send {}, backing off before retrying:</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.sendRecords</callsite><line>345</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Exception thrown while calling task.commitRecord()-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Exception thrown while calling task.commitRecord()</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitTaskRecord</callsite><line>377</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} CRITICAL Saw callback for record that was not present in the outstanding message set: {}-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-org.apache.kafka.clients.producer.ProducerRecord<byte[],byte[]>(name)record</parameter><constant>{} CRITICAL Saw callback for record that was not present in the outstanding message set: {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.recordSent</callsite><line>388</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Committing offsets-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Committing offsets</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>398</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} flushing {} outstanding messages for offset commit-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-int(name)outstandingMessages.size()</parameter><constant>{} flushing {} outstanding messages for offset commit</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>415</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to flush, timed out while waiting for producer to flush outstanding {} messages-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-int(name)outstandingMessages.size()</parameter><constant>{} Failed to flush, timed out while waiting for producer to flush outstanding {} messages</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>420</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Interrupted while flushing messages, offsets will not be committed-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Interrupted while flushing messages, offsets will not be committed</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>430</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Finished offset commitOffsets successfully in {} ms-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-long(name)durationMillis</parameter><constant>{} Finished offset commitOffsets successfully in {} ms</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>445</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to flush offsets to storage: -org.apache.kafka.connect.runtime.WorkerSourceTask(name)WorkerSourceTask.this-java.lang.Throwable(name)error</parameter><constant>{} Failed to flush offsets to storage: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>458</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name){} Finished flushing offsets to storage-org.apache.kafka.connect.runtime.WorkerSourceTask(name)WorkerSourceTask.this</parameter><constant>{} Finished flushing offsets to storage</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>460</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Flush of offsets interrupted, cancelling-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Flush of offsets interrupted, cancelling</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>478</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Flush of offsets threw an unexpected exception: -org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-java.util.concurrent.ExecutionException(name)e</parameter><constant>{} Flush of offsets threw an unexpected exception: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>483</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Timed out waiting to flush offsets to storage-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this</parameter><constant>{} Timed out waiting to flush offsets to storage</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>488</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.info</logcall> <parameter>java.lang.String(name){} Finished commitOffsets successfully in {} ms-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-long(name)durationMillis</parameter><constant>{} Finished commitOffsets successfully in {} ms</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitOffsets</callsite><line>497</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Exception thrown while calling task.commit()-org.apache.kafka.connect.runtime.WorkerSourceTask(name)this-java.lang.Throwable(name)t</parameter><constant>{} Exception thrown while calling task.commit()</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerSourceTask.commitSourceTask</callsite><line>509</line><superclass>org.apache.kafka.connect.runtime.WorkerTask</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Initializing connector {} with config {}-org.apache.kafka.connect.runtime.WorkerConnector(name)this-java.lang.String(name)connName-java.util.Map<String,String>(name)config</parameter><constant>{} Initializing connector {} with config {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.initialize</callsite><line>79</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Connector raised an error-org.apache.kafka.connect.runtime.WorkerConnector(name)WorkerConnector.this-java.lang.Exception(name)e</parameter><constant>{} Connector raised an error</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.initialize</callsite><line>92</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Error initializing connector-org.apache.kafka.connect.runtime.WorkerConnector(name)this-java.lang.Throwable(name)t</parameter><constant>{} Error initializing connector</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.initialize</callsite><line>98</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Error while starting connector-org.apache.kafka.connect.runtime.WorkerConnector(name)this-java.lang.Throwable(name)t</parameter><constant>{} Error while starting connector</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.doStart</callsite><line>119</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Error while shutting down connector-org.apache.kafka.connect.runtime.WorkerConnector(name)this-java.lang.Throwable(name)t</parameter><constant>{} Error while shutting down connector</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.pause</callsite><line>164</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.error</logcall> <parameter>java.lang.String(name){} Error while shutting down connector-org.apache.kafka.connect.runtime.WorkerConnector(name)this-java.lang.Throwable(name)t</parameter><constant>{} Error while shutting down connector</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.shutdown</callsite><line>177</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.warn</logcall> <parameter>java.lang.String(name){} Cannot transition connector to {} since it has failed-org.apache.kafka.connect.runtime.WorkerConnector(name)this-org.apache.kafka.connect.runtime.TargetState(name)targetState</parameter><constant>{} Cannot transition connector to {} since it has failed</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.transitionTo</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.debug</logcall> <parameter>java.lang.String(name){} Transition connector to {}-org.apache.kafka.connect.runtime.WorkerConnector(name)this-org.apache.kafka.connect.runtime.TargetState(name)targetState</parameter><constant>{} Transition connector to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.WorkerConnector.transitionTo</callsite><line>191</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.Logger.trace</logcall> <parameter>java.lang.String(name)Applying transformation {} to {}-java.lang.String(name)transformation.getClass().getName()-R(name)record</parameter><constant>Applying transformation {} to {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.TransformationChain.apply</callsite><line>47</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Deserialized new assignment: {}-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)newAssignment</parameter><constant>Deserialized new assignment: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinComplete</callsite><line>169</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)After revocations snapshot of assignment: {}-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)assignmentSnapshot</parameter><constant>After revocations snapshot of assignment: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinComplete</callsite><line>184</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Augmented new assignment: {}-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)newAssignment</parameter><constant>Augmented new assignment: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinComplete</callsite><line>188</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Rebalance started</parameter><constant>Rebalance started</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinPrepare</callsite><line>203</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Revoking previous assignment {}-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)assignmentSnapshot</parameter><constant>Revoking previous assignment {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinPrepare</callsite><line>206</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Cooperative rebalance triggered. Keeping assignment {} until it's explicitly revoked.-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)assignmentSnapshot</parameter><constant>Cooperative rebalance triggered. Keeping assignment {} until it's explicitly revoked.</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerCoordinator.onJoinPrepare</callsite><line>210</line><superclass>org.apache.kafka.clients.consumer.internals.AbstractCoordinator</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Herder starting</parameter><constant>Herder starting</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.run</callsite><line>238</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Herder started</parameter><constant>Herder started</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.run</callsite><line>242</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Herder stopped</parameter><constant>Herder stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.run</callsite><line>250</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Uncaught exception in herder work thread, exiting: -java.lang.Throwable(name)t</parameter><constant>Uncaught exception in herder work thread, exiting: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.run</callsite><line>253</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Scheduled rebalance at: {} (now: {} nextRequestTimeoutMs: {}) -long(name)scheduledRebalance-long(name)now-long(name)nextRequestTimeoutMs</parameter><constant>Scheduled rebalance at: {} (now: {} nextRequestTimeoutMs: {}) </constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick</callsite><line>306</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: {})-boolean(name)needsReconfigRebalance</parameter><constant>Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: {})</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.updateConfigsWithEager</callsite><line>378</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: {})-boolean(name)needsReconfigRebalance</parameter><constant>Requesting rebalance due to reconfiguration of tasks (needsReconfigRebalance: {})</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.updateConfigsWithIncrementalCooperative</callsite><line>421</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Received target state change for unknown connector: {}-java.lang.String(name)connector</parameter><constant>Received target state change for unknown connector: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.processTargetStateChanges</callsite><line>473</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Handling task config update by restarting tasks {}-java.util.List<ConnectorTaskId>(name)tasksToStop</parameter><constant>Handling task config update by restarting tasks {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.processTaskConfigUpdatesWithIncrementalCooperative</callsite><line>498</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Stopping connectors and tasks that are still assigned to this worker.</parameter><constant>Stopping connectors and tasks that are still assigned to this worker.</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.halt</callsite><line>507</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Herder stopping</parameter><constant>Herder stopping</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.stop</callsite><line>533</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Herder stopped</parameter><constant>Herder stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.stop</callsite><line>553</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector listing request</parameter><constant>Submitting connector listing request</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.connectors</callsite><line>558</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector info request {}-java.lang.String(name)connName</parameter><constant>Submitting connector info request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.connectorInfo</callsite><line>577</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector config read request {}-java.lang.String(name)connName</parameter><constant>Submitting connector config read request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.connectorConfig</callsite><line>606</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Handling connector config request {}-java.lang.String(name)connName</parameter><constant>Handling connector config request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.deleteConnectorConfig</callsite><line>624</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Removing connector config {} {}-java.lang.String(name)connName-java.util.Set<String>(name)configState.connectors()</parameter><constant>Removing connector config {} {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.deleteConnectorConfig</callsite><line>633</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector config write request {}-java.lang.String(name)connName</parameter><constant>Submitting connector config write request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.putConnectorConfig</callsite><line>664</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Handling connector config request {}-java.lang.String(name)connName</parameter><constant>Handling connector config request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.putConnectorConfig</callsite><line>673</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector config {} {} {}-java.lang.String(name)connName-boolean(name)allowReplace-java.util.Set<String>(name)configState.connectors()</parameter><constant>Submitting connector config {} {} {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.putConnectorConfig</callsite><line>685</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting connector task reconfiguration request {}-java.lang.String(name)connName</parameter><constant>Submitting connector task reconfiguration request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.requestTaskReconfiguration</callsite><line>703</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during task reconfiguration: -java.lang.Throwable(name)error</parameter><constant>Unexpected error during task reconfiguration: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.requestTaskReconfiguration</callsite><line>717</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Task reconfiguration for {} failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.-java.lang.String(name)connName</parameter><constant>Task reconfiguration for {} failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.requestTaskReconfiguration</callsite><line>718</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting get task configuration request {}-java.lang.String(name)connName</parameter><constant>Submitting get task configuration request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.taskConfigs</callsite><line>727</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Submitting put task configuration request {}-java.lang.String(name)connName</parameter><constant>Submitting put task configuration request {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.putTaskConfigs</callsite><line>755</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Returning early because rebalance is marked as resolved (rebalanceResolved: true)</parameter><constant>Returning early because rebalance is marked as resolved (rebalanceResolved: true)</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>879</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.warn</logcall> <parameter>java.lang.String(name)Join group completed, but assignment failed and we are the leader. Reading to end of config and retrying.</parameter><constant>Join group completed, but assignment failed and we are the leader. Reading to end of config and retrying.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>899</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.warn</logcall> <parameter>java.lang.String(name)Join group completed, but assignment failed and we lagging. Reading to end of config and retrying.</parameter><constant>Join group completed, but assignment failed and we lagging. Reading to end of config and retrying.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>902</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.warn</logcall> <parameter>java.lang.String(name)Join group completed, but assignment failed. We were up to date, so just retrying.</parameter><constant>Join group completed, but assignment failed. We were up to date, so just retrying.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>905</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.warn</logcall> <parameter>java.lang.String(name)Catching up to assignment's config offset.</parameter><constant>Catching up to assignment's config offset.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>909</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Requesting rebalance because scheduled rebalance timeout has been reached (now: {} scheduledRebalance: {}-long(name)scheduledRebalance-long(name)now</parameter><constant>Requesting rebalance because scheduled rebalance timeout has been reached (now: {} scheduledRebalance: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>916</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Current config state offset {} does not match group assignment {}. Forcing rebalance.-long(name)configState.offset()-long(name)assignment.offset()</parameter><constant>Current config state offset {} does not match group assignment {}. Forcing rebalance.</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.handleRebalanceCompleted</callsite><line>942</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Current config state offset {} is behind group assignment {}, reading to end of config log-long(name)configState.offset()-long(name)assignment.offset()</parameter><constant>Current config state offset {} is behind group assignment {}, reading to end of config log</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.readConfigToEnd</callsite><line>970</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Finished reading to end of log and updated config snapshot, new config log offset: {}-long(name)configState.offset()</parameter><constant>Finished reading to end of log and updated config snapshot, new config log offset: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.readConfigToEnd</callsite><line>974</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.warn</logcall> <parameter>java.lang.String(name)Didn't reach end of config log quickly enough-java.util.concurrent.TimeoutException(name)e</parameter><constant>Didn't reach end of config log quickly enough</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.readConfigToEnd</callsite><line>979</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Starting connectors and tasks using config offset {}-long(name)assignment.offset()</parameter><constant>Starting connectors and tasks using config offset {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.startWork</callsite><line>1000</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Finished starting connectors and tasks</parameter><constant>Finished starting connectors and tasks</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.startWork</callsite><line>1021</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Starting task {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId</parameter><constant>Starting task {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask</callsite><line>1035</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Couldn't instantiate task {} because it has an invalid task configuration. This task will not execute until reconfigured.-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId-java.lang.Throwable(name)t</parameter><constant>Couldn't instantiate task {} because it has an invalid task configuration. This task will not execute until reconfigured.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.getTaskStartingCallable</callsite><line>1053</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Starting connector {}-java.lang.String(name)connectorName</parameter><constant>Starting connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector</callsite><line>1075</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)"Couldn't instantiate connector " + connectorName + " because it has an invalid connector "+ "configuration. This connector will not execute until reconfigured."-java.lang.Throwable(name)t</parameter><constant>Couldn't instantiate connector  |  because it has an invalid connector  | configuration. This connector will not execute until reconfigured.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.getConnectorStartingCallable</callsite><line>1097</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)"Failed to shut down connector " + connectorName-java.lang.Throwable(name)t</parameter><constant>Failed to shut down connector </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.getConnectorStoppingCallable</callsite><line>1113</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Failed to reconfigure connector's tasks, retrying after backoff:-java.lang.Throwable(name)error</parameter><constant>Failed to reconfigure connector's tasks, retrying after backoff:</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry</callsite><line>1129</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during connector task reconfiguration: -java.lang.Throwable(name)error</parameter><constant>Unexpected error during connector task reconfiguration: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry</callsite><line>1140</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Task reconfiguration for {} failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.-java.lang.String(name)connName</parameter><constant>Task reconfiguration for {} failed unexpectedly, this connector will not be properly reconfigured unless manually triggered.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry</callsite><line>1141</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Skipping reconfiguration of connector {} since it is not running-java.lang.String(name)connName</parameter><constant>Skipping reconfiguration of connector {} since it is not running</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector</callsite><line>1155</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Change in connector task count from {} to {}, writing updated task configurations-int(name)currentNumTasks-int(name)taskProps.size()</parameter><constant>Change in connector task count from {} to {}, writing updated task configurations</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector</callsite><line>1172</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Change in task configurations, writing updated task configurations</parameter><constant>Change in task configurations, writing updated task configurations</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector</callsite><line>1178</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.error</logcall> <parameter>java.lang.String(name)Request to leader to reconfigure connector tasks failed-org.apache.kafka.connect.errors.ConnectException(name)e</parameter><constant>Request to leader to reconfigure connector tasks failed</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector</callsite><line>1208</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Connector {} config removed-java.lang.String(name)connector</parameter><constant>Connector {} config removed</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onConnectorConfigRemove</callsite><line>1255</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Connector {} config updated-java.lang.String(name)connector</parameter><constant>Connector {} config updated</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onConnectorConfigUpdate</callsite><line>1268</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Tasks {} configs updated-java.util.Collection<ConnectorTaskId>(name)tasks</parameter><constant>Tasks {} configs updated</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onTaskConfigUpdate</callsite><line>1283</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Connector {} target state change-java.lang.String(name)connector</parameter><constant>Connector {} target state change</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onConnectorTargetStateChange</callsite><line>1302</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Cleaning status information for connector {}-java.lang.String(name)connector</parameter><constant>Cleaning status information for connector {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.updateDeletedConnectorStatus</callsite><line>1373</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Joined group at generation {} and got assignment: {}-int(name)generation-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)assignment</parameter><constant>Joined group at generation {} and got assignment: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onAssigned</callsite><line>1397</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Finished stopping tasks in preparation for rebalance</parameter><constant>Finished stopping tasks in preparation for rebalance</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onRevoked</callsite><line>1447</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Wasn't unable to resume work after last rebalance, can skip stopping connectors and tasks</parameter><constant>Wasn't unable to resume work after last rebalance, can skip stopping connectors and tasks</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.DistributedHerder.onRevoked</callsite><line>1449</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Performing task assignment</parameter><constant>Performing task assignment</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.performAssignment</callsite><line>56</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.</parameter><constant>Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.ensureLeaderConfig</callsite><line>78</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Assigning connector {} to {}-java.lang.String(name)connectorId-java.lang.String(name)connectorAssignedTo</parameter><constant>Assigning connector {} to {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.performTaskAssignment</callsite><line>104</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Assigning task {} to {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId-java.lang.String(name)taskAssignedTo</parameter><constant>Assigning task {} to {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.performTaskAssignment</callsite><line>115</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Assignment: {} -> {}-java.lang.String(name)member-org.apache.kafka.connect.runtime.distributed.Assignment(name)assignment</parameter><constant>Assignment: {} -> {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.fillAssignmentsAndSerialize</callsite><line>150</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Finished assignment</parameter><constant>Finished assignment</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.fillAssignmentsAndSerialize</callsite><line>153</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Max config offset root: {}, local snapshot config offsets root: {}-java.lang.Long(name)maxOffset-long(name)coordinator.configSnapshot().offset()</parameter><constant>Max config offset root: {}, local snapshot config offsets root: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.EagerAssignor.findMaxMemberConfigOffset</callsite><line>171</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Performing task assignment</parameter><constant>Performing task assignment</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performAssignment</callsite><line>85</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Member configs: {}-java.util.Map<String,ExtendedWorkerState>(name)memberConfigs</parameter><constant>Member configs: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performAssignment</callsite><line>93</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Max config offset root: {}, local snapshot config offsets root: {}-long(name)maxOffset-long(name)coordinator.configSnapshot().offset()</parameter><constant>Max config offset root: {}, local snapshot config offsets root: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performAssignment</callsite><line>99</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.info</logcall> <parameter>java.lang.String(name)Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.</parameter><constant>Was selected to perform assignments, but do not have latest config found in sync request. Returning an empty configuration to trigger re-sync.</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.ensureLeaderConfig</callsite><line>121</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Previous assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)previousAssignment</parameter><constant>Previous assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>151</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Configured assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)configured</parameter><constant>Configured assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>163</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Active assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)activeAssignments</parameter><constant>Active assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>168</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Deleted assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)deleted</parameter><constant>Deleted assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>185</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Remaining (excluding deleted) active assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)remainingActive</parameter><constant>Remaining (excluding deleted) active assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>190</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Lost assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)lostAssignments</parameter><constant>Lost assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>195</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)New assignments: {}-org.apache.kafka.connect.runtime.distributed.ConnectorsAndTasks(name)newSubmissions</parameter><constant>New assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>200</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Complete (ignoring deletions) worker assignments: {}-java.util.List<WorkerLoad>(name)completeWorkerAssignment</parameter><constant>Complete (ignoring deletions) worker assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>204</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Complete (ignoring deletions) connector assignments: {}-java.util.Map<String,Collection<String>>(name)connectorAssignments</parameter><constant>Complete (ignoring deletions) connector assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>209</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Complete (ignoring deletions) task assignments: {}-java.util.Map<String,Collection<ConnectorTaskId>>(name)taskAssignments</parameter><constant>Complete (ignoring deletions) task assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>214</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Connector and task to delete assignments: {}-java.util.Map<String,ConnectorsAndTasks>(name)toRevoke</parameter><constant>Connector and task to delete assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>220</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Can leader revoke tasks in this assignment? {} (delay: {})-boolean(name)canRevoke-int(name)delay</parameter><constant>Can leader revoke tasks in this assignment? {} (delay: {})</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>237</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Connector and task to revoke assignments: {}-java.util.Map<String,ConnectorsAndTasks>(name)toRevoke</parameter><constant>Connector and task to revoke assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>242</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Current complete assignments: {}-java.util.List<WorkerLoad>(name)currentWorkerAssignment</parameter><constant>Current complete assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>261</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)New complete assignments: {}-java.util.List<WorkerLoad>(name)completeWorkerAssignment</parameter><constant>New complete assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>262</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Incremental connector assignments: {}-java.util.Map<String,Collection<String>>(name)incrementalConnectorAssignments</parameter><constant>Incremental connector assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>276</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Incremental task assignments: {}-java.util.Map<String,Collection<ConnectorTaskId>>(name)incrementalTaskAssignments</parameter><constant>Incremental task assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Actual assignments: {}-java.util.Map<String,ExtendedAssignment>(name)assignments</parameter><constant>Actual assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskAssignment</callsite><line>288</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Connectors and tasks to delete assignments: {}-java.util.Map<String,ConnectorsAndTasks>(name)toRevoke</parameter><constant>Connectors and tasks to delete assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.computeDeleted</callsite><line>313</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)"Found the following connectors and tasks missing from previous assignments: " + lostAssignments</parameter><constant>Found the following connectors and tasks missing from previous assignments: </constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.handleLostAssignments</callsite><line>350</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)No task revocation required; workers with existing load: {} workers with no load {} total workers {}-int(name)existingWorkersNum-int(name)newWorkersNum-int(name)totalWorkersNum</parameter><constant>No task revocation required; workers with existing load: {} workers with no load {} total workers {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>437</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Task revocation is required; workers with existing load: {} workers with no load {} total workers {}-int(name)existingWorkersNum-int(name)newWorkersNum-int(name)totalWorkersNum</parameter><constant>Task revocation is required; workers with existing load: {} workers with no load {} total workers {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>445</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Previous rounded down (floor) average number of connectors per worker {}-int(name)totalActiveConnectorsNum / existingWorkersNum</parameter><constant>Previous rounded down (floor) average number of connectors per worker {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>450</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)New rounded down (floor) average number of connectors per worker {}-int(name)floorConnectors</parameter><constant>New rounded down (floor) average number of connectors per worker {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>452</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Previous rounded down (floor) average number of tasks per worker {}-int(name)totalActiveTasksNum / existingWorkersNum</parameter><constant>Previous rounded down (floor) average number of tasks per worker {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>454</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)New rounded down (floor) average number of tasks per worker {}-int(name)floorTasks</parameter><constant>New rounded down (floor) average number of tasks per worker {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.performTaskRevocation</callsite><line>456</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Filling assignment: {} -> {}-java.lang.String(name)member-org.apache.kafka.connect.runtime.distributed.ExtendedAssignment(name)assignment</parameter><constant>Filling assignment: {} -> {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.fillAssignments</callsite><line>504</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Finished assignment</parameter><constant>Finished assignment</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.fillAssignments</callsite><line>507</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Received assignments: {}-java.util.Map<String,ExtendedWorkerState>(name)memberConfigs</parameter><constant>Received assignments: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.assignment</callsite><line>549</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Assigning connector {} to {}-java.lang.String(name)connector-java.lang.String(name)worker.worker()</parameter><constant>Assigning connector {} to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.assignConnectors</callsite><line>587</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Assigning task {} to {}-org.apache.kafka.connect.util.ConnectorTaskId(name)task-java.lang.String(name)worker.worker()</parameter><constant>Assigning task {} to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.IncrementalCooperativeAssignor.assignTasks</callsite><line>617</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)Connect group member created</parameter><constant>Connect group member created</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerGroupMember.WorkerGroupMember</callsite><line>139</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.trace</logcall> <parameter>java.lang.String(name)Stopping the Connect group member.</parameter><constant>Stopping the Connect group member.</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerGroupMember.stop</callsite><line>208</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.distributed.Logger.debug</logcall> <parameter>java.lang.String(name)The Connect group member has stopped.</parameter><constant>The Connect group member has stopped.</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.distributed.WorkerGroupMember.stop</callsite><line>218</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.error</logcall> <parameter>java.lang.String(name)Topic {} doesn't exist. Will attempt to create topic.-java.lang.String(name)topic</parameter><constant>Topic {} doesn't exist. Will attempt to create topic.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.createAndSetup</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.error</logcall> <parameter>java.lang.String(name)Could not serialize stacktrace.-java.io.IOException(name)e</parameter><constant>Could not serialize stacktrace.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.errors.DeadLetterQueueReporter.stacktrace</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.error</logcall> <parameter>java.lang.String(name)message(context)-java.lang.Throwable(name)context.error()</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.errors.LogReporter.report</callsite><line>62</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.debug</logcall> <parameter>java.lang.String(name)ProcessingContext is already in failed state. Ignoring requested operation.</parameter><constant>ProcessingContext is already in failed state. Ignoring requested operation.</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execute</callsite><line>98</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.trace</logcall> <parameter>java.lang.String(name)Caught a retriable exception while executing {} operation with {}-org.apache.kafka.connect.runtime.errors.Stage(name)context.stage()-java.lang.Class<>(name)context.executingClass()</parameter><constant>Caught a retriable exception while executing {} operation with {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry</callsite><line>130</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.trace</logcall> <parameter>java.lang.String(name)Thread was interrupted. Marking operation as failed.</parameter><constant>Thread was interrupted. Marking operation as failed.</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry</callsite><line>135</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.trace</logcall> <parameter>java.lang.String(name)Can't retry. start={}, attempt={}, deadline={}-long(name)startTime-int(name)attempt-long(name)deadline</parameter><constant>Can't retry. start={}, attempt={}, deadline={}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.execAndRetry</callsite><line>141</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.errors.Logger.debug</logcall> <parameter>java.lang.String(name)Sleeping for {} millis-long(name)delay</parameter><constant>Sleeping for {} millis</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.errors.RetryWithToleranceOperator.backoff</callsite><line>220</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.trace</logcall> <parameter>java.lang.String(name)Class '{}' not found. Delegating to parent-java.lang.String(name)name</parameter><constant>Class '{}' not found. Delegating to parent</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.isolation.PluginClassLoader.loadClass</callsite><line>100</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Configuring the header converter with configuration keys:{}{}-java.lang.String(name)System.lineSeparator()-java.util.Set<String>(name)converterConfig.keySet()</parameter><constant>Configuring the header converter with configuration keys:{}{}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.Plugins.newHeaderConverter</callsite><line>323</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Getting plugin class loader for connector: '{}'-java.lang.String(name)connectorClassOrAlias</parameter><constant>Getting plugin class loader for connector: '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.connectorLoader</callsite><line>140</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.error</logcall> <parameter>java.lang.String(name)Plugin class loader for connector: '{}' was not found. Returning: {}-java.lang.String(name)connectorClassOrAlias-org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader(name)this</parameter><constant>Plugin class loader for connector: '{}' was not found. Returning: {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.connectorLoader</callsite><line>146</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.info</logcall> <parameter>java.lang.String(name)Added plugin '{}'-java.lang.String(name)pluginClassName</parameter><constant>Added plugin '{}'</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.addPlugins</callsite><line>174</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.error</logcall> <parameter>java.lang.String(name)Invalid path in plugin path: {}. Ignoring.-java.lang.String(name)path-java.lang.Exception(name)e</parameter><constant>Invalid path in plugin path: {}. Ignoring.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader</callsite><line>212</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.error</logcall> <parameter>java.lang.String(name)Could not get listing for plugin path: {}. Ignoring.-java.lang.String(name)path-java.io.IOException(name)e</parameter><constant>Could not get listing for plugin path: {}. Ignoring.</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader</callsite><line>214</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.error</logcall> <parameter>java.lang.String(name)Could not instantiate plugins in: {}. Ignoring: {}-java.lang.String(name)path-java.lang.ReflectiveOperationException(name)e</parameter><constant>Could not instantiate plugins in: {}. Ignoring: {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader</callsite><line>216</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.info</logcall> <parameter>java.lang.String(name)Loading plugin from: {}-java.nio.file.Path(name)pluginLocation</parameter><constant>Loading plugin from: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.registerPlugin</callsite><line>222</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Loading plugin urls: {}-java.lang.String(name)Arrays.toString(urls)</parameter><constant>Loading plugin urls: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.registerPlugin</callsite><line>229</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.info</logcall> <parameter>java.lang.String(name)Registered loader: {}-java.lang.ClassLoader(name)loader</parameter><constant>Registered loader: {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins</callsite><line>245</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Registered java.sql.Driver: {} to java.sql.DriverManager-java.sql.Driver(name)driver</parameter><constant>Registered java.sql.Driver: {} to java.sql.DriverManager</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.loadJdbcDrivers</callsite><line>281</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Ignoring java.sql.Driver classes listed in resources but not present in class loader's classpath: -java.lang.Throwable(name)t</parameter><constant>Ignoring java.sql.Driver classes listed in resources but not present in class loader's classpath: </constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.loadJdbcDrivers</callsite><line>287</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping {} as it is not concrete implementation-java.lang.Class<>(name)plugin</parameter><constant>Skipping {} as it is not concrete implementation</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.getPluginDesc</callsite><line>333</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.trace</logcall> <parameter>java.lang.String(name)Retrieving loaded class '{}' from '{}'-java.lang.String(name)fullName-java.lang.ClassLoader(name)pluginLoader</parameter><constant>Retrieving loaded class '{}' from '{}'</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.loadClass</callsite><line>369</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.info</logcall> <parameter>java.lang.String(name)Added alias '{}' to plugin '{}'-java.lang.String(name)simple-java.lang.String(name)plugin.className()</parameter><constant>Added alias '{}' to plugin '{}'</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.addAliases</callsite><line>394</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.info</logcall> <parameter>java.lang.String(name)Added aliases '{}' and '{}' to plugin '{}'-java.lang.String(name)simple-java.lang.String(name)pruned-java.lang.String(name)plugin.className()</parameter><constant>Added aliases '{}' and '{}' to plugin '{}'</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.addAliases</callsite><line>397</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.warn</logcall> <parameter>java.lang.String(name)could not create Vfs.Dir from url. ignoring the exception and continuing-org.apache.kafka.connect.runtime.isolation.ReflectionsException(name)e</parameter><constant>could not create Vfs.Dir from url. ignoring the exception and continuing</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scan</callsite><line>423</line><superclass>java.net.URLClassLoader</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.warn</logcall> <parameter>java.lang.String(name)Resolving symbolic link '{}' failed. Ignoring this path.-java.nio.file.Path(name)adjacent-java.io.IOException(name)e</parameter><constant>Resolving symbolic link '{}' failed. Ignoring this path.</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.isolation.PluginUtils.pluginUrls</callsite><line>263</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.isolation.Logger.warn</logcall> <parameter>java.lang.String(name)Plugin path contains both java archives and class files. Returning only the archives</parameter><constant>Plugin path contains both java archives and class files. Returning only the archives</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.isolation.PluginUtils.pluginUrls</callsite><line>297</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)"Added connector for " + listener</parameter><constant>Added connector for </constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.createConnectors</callsite><line>124</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)Initializing REST server</parameter><constant>Initializing REST server</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.initializeServer</callsite><line>168</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)Initializing REST resources</parameter><constant>Initializing REST resources</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.initializeResources</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)REST resources initialized; server is started and ready to handle requests</parameter><constant>REST resources initialized; server is started and ready to handle requests</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.initializeResources</callsite><line>233</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)Stopping REST server</parameter><constant>Stopping REST server</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.stop</callsite><line>241</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.warn</logcall> <parameter>java.lang.String(name)"Error while invoking close on " + connectRestExtension.getClass()-java.io.IOException(name)e</parameter><constant>Error while invoking close on </constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.stop</callsite><line>248</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.info</logcall> <parameter>java.lang.String(name)REST server stopped</parameter><constant>REST server stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.RestServer.stop</callsite><line>258</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.warn</logcall> <parameter>java.lang.String(name)The resource {} is already registered-java.lang.Object(name)component</parameter><constant>The resource {} is already registered</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.rest.ConnectRestConfigurable.allowedToRegister</callsite><line>125</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.warn</logcall> <parameter>java.lang.String(name)The resource {} is already registered-java.lang.Class<>(name)componentClass</parameter><constant>The resource {} is already registered</constant><level>warn</level><callsite>org.apache.kafka.connect.runtime.rest.ConnectRestConfigurable.allowedToRegister</callsite><line>133</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.error</logcall> <parameter>java.lang.String(name)Failed to start RestClient: -java.lang.Exception(name)e</parameter><constant>Failed to start RestClient: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.rest.RestClient.httpRequest</callsite><line>75</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.trace</logcall> <parameter>java.lang.String(name)Sending {} with input {} to {}-java.lang.String(name)method-java.lang.String(name)serializedBody-java.lang.String(name)url</parameter><constant>Sending {} with input {} to {}</constant><level>trace</level><callsite>org.apache.kafka.connect.runtime.rest.RestClient.httpRequest</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.debug</logcall> <parameter>java.lang.String(name)Request's response code: {}-int(name)responseCode</parameter><constant>Request's response code: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.rest.RestClient.httpRequest</callsite><line>96</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.error</logcall> <parameter>java.lang.String(name)IO error forwarding REST request: -java.lang.Exception(name)e</parameter><constant>IO error forwarding REST request: </constant><level>error</level><callsite>org.apache.kafka.connect.runtime.rest.RestClient.httpRequest</callsite><line>111</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.Logger.error</logcall> <parameter>java.lang.String(name)Failed to stop HTTP client-java.lang.Exception(name)e</parameter><constant>Failed to stop HTTP client</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.rest.RestClient.httpRequest</callsite><line>118</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.resources.Logger.info</logcall> <parameter>java.lang.String(name)Ignoring unknown expanion type {}-java.lang.String(name)expansion</parameter><constant>Ignoring unknown expanion type {}</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource.listConnectors</callsite><line>106</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.resources.Logger.debug</logcall> <parameter>java.lang.String(name)Unable to get connector info for {} on this worker-java.lang.String(name)connector</parameter><constant>Unable to get connector info for {} on this worker</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource.listConnectors</callsite><line>113</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.rest.resources.Logger.debug</logcall> <parameter>java.lang.String(name)Forwarding request {} {} {}-java.lang.String(name)forwardUrl-java.lang.String(name)method-java.lang.Object(name)body</parameter><constant>Forwarding request {} {} {}</constant><level>debug</level><callsite>org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource.completeOrForwardRequest</callsite><line>308</line><superclass>null</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.info</logcall> <parameter>java.lang.String(name)Herder starting</parameter><constant>Herder starting</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.start</callsite><line>91</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.info</logcall> <parameter>java.lang.String(name)Herder started</parameter><constant>Herder started</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.start</callsite><line>93</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.info</logcall> <parameter>java.lang.String(name)Herder stopping</parameter><constant>Herder stopping</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.stop</callsite><line>98</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.info</logcall> <parameter>java.lang.String(name)Herder stopped</parameter><constant>Herder stopped</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.stop</callsite><line>115</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.error</logcall> <parameter>java.lang.String(name)Task that requested reconfiguration does not exist: {}-java.lang.String(name)connName</parameter><constant>Task that requested reconfiguration does not exist: {}</constant><level>error</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.requestTaskReconfiguration</callsite><line>224</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.runtime.standalone.Logger.info</logcall> <parameter>java.lang.String(name)Skipping update of connector {} since it is not running-java.lang.String(name)connName</parameter><constant>Skipping update of connector {} since it is not running</constant><level>info</level><callsite>org.apache.kafka.connect.runtime.standalone.StandaloneHerder.updateConnectorTasks</callsite><line>325</line><superclass>org.apache.kafka.connect.runtime.AbstractHerder</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Starting FileOffsetBackingStore with file {}-java.io.File(name)file</parameter><constant>Starting FileOffsetBackingStore with file {}</constant><level>info</level><callsite>org.apache.kafka.connect.storage.FileOffsetBackingStore.start</callsite><line>58</line><superclass>org.apache.kafka.connect.storage.MemoryOffsetBackingStore</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Stopped FileOffsetBackingStore</parameter><constant>Stopped FileOffsetBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.FileOffsetBackingStore.stop</callsite><line>66</line><superclass>org.apache.kafka.connect.storage.MemoryOffsetBackingStore</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Creating admin client to manage Connect internal status topic</parameter><constant>Creating admin client to manage Connect internal status topic</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.createKafkaBasedLog</callsite><line>160</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to write status update-java.lang.Exception(name)exception</parameter><constant>Failed to write status update</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.send</callsite><line>248</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Invalid connector status type {}-java.lang.Class<>(name)schemaAndValue.value().getClass()</parameter><constant>Invalid connector status type {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.parseConnectorStatus</callsite><line>322</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to deserialize connector status-java.lang.Exception(name)e</parameter><constant>Failed to deserialize connector status</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.parseConnectorStatus</callsite><line>334</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Invalid task status type {}-java.lang.Class<>(name)schemaAndValue.value().getClass()</parameter><constant>Invalid task status type {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.parseTaskStatus</callsite><line>343</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to deserialize task status-java.lang.Exception(name)e</parameter><constant>Failed to deserialize task status</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.parseTaskStatus</callsite><line>354</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Invalid task status key {}-java.lang.String(name)key</parameter><constant>Invalid task status key {}</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.parseConnectorTaskId</callsite><line>382</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Discarding record with invalid connector status key {}-java.lang.String(name)key</parameter><constant>Discarding record with invalid connector status key {}</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readConnectorStatus</callsite><line>390</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.trace</logcall> <parameter>java.lang.String(name)Removing status for connector {}-java.lang.String(name)connector</parameter><constant>Removing status for connector {}</constant><level>trace</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readConnectorStatus</callsite><line>395</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.trace</logcall> <parameter>java.lang.String(name)Received connector {} status update {}-java.lang.String(name)connector-org.apache.kafka.connect.runtime.ConnectorStatus(name)status</parameter><constant>Received connector {} status update {}</constant><level>trace</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readConnectorStatus</callsite><line>405</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Discarding record with invalid task status key {}-java.lang.String(name)key</parameter><constant>Discarding record with invalid task status key {}</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readTaskStatus</callsite><line>414</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.trace</logcall> <parameter>java.lang.String(name)Removing task status for {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id</parameter><constant>Removing task status for {}</constant><level>trace</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readTaskStatus</callsite><line>419</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to parse task status with key {}-java.lang.String(name)key</parameter><constant>Failed to parse task status with key {}</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readTaskStatus</callsite><line>426</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.trace</logcall> <parameter>java.lang.String(name)Received task {} status update {}-org.apache.kafka.connect.util.ConnectorTaskId(name)id-org.apache.kafka.connect.runtime.TaskStatus(name)status</parameter><constant>Received task {} status update {}</constant><level>trace</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.readTaskStatus</callsite><line>431</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.warn</logcall> <parameter>java.lang.String(name)Discarding record with invalid key {}-java.lang.String(name)key</parameter><constant>Discarding record with invalid key {}</constant><level>warn</level><callsite>org.apache.kafka.connect.storage.KafkaStatusBackingStore.read</callsite><line>445</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Starting KafkaConfigBackingStore</parameter><constant>Starting KafkaConfigBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.start</callsite><line>248</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Started KafkaConfigBackingStore</parameter><constant>Started KafkaConfigBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.start</callsite><line>253</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Closing KafkaConfigBackingStore</parameter><constant>Closing KafkaConfigBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.stop</callsite><line>258</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Closed KafkaConfigBackingStore</parameter><constant>Closed KafkaConfigBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.stop</callsite><line>260</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Writing connector configuration for connector '{}'-java.lang.String(name)connector</parameter><constant>Writing connector configuration for connector '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putConnectorConfig</callsite><line>299</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Removing connector configuration for connector '{}'-java.lang.String(name)connector</parameter><constant>Removing connector configuration for connector '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.removeConnectorConfig</callsite><line>312</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to remove connector configuration from Kafka: -java.lang.Exception(name)e</parameter><constant>Failed to remove connector configuration from Kafka: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.removeConnectorConfig</callsite><line>318</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to write connector configuration to Kafka: -java.lang.Exception(name)e</parameter><constant>Failed to write connector configuration to Kafka: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.updateConnectorConfig</callsite><line>333</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to write root configuration to Kafka: -java.lang.Exception(name)e</parameter><constant>Failed to write root configuration to Kafka: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putTaskConfigs</callsite><line>354</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Writing configuration for connector '{}' task {}-java.lang.String(name)connector-int(name)index</parameter><constant>Writing configuration for connector '{}' task {}</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putTaskConfigs</callsite><line>366</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Writing commit for connector '{}' with {} tasks.-java.lang.String(name)connector-int(name)taskCount</parameter><constant>Writing commit for connector '{}' with {} tasks.</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putTaskConfigs</callsite><line>383</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to write root configuration to Kafka: -java.lang.Exception(name)e</parameter><constant>Failed to write root configuration to Kafka: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putTaskConfigs</callsite><line>389</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Writing target state {} for connector {}-org.apache.kafka.connect.runtime.TargetState(name)state-java.lang.String(name)connector</parameter><constant>Writing target state {} for connector {}</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.putTargetState</callsite><line>408</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Creating admin client to manage Connect internal config topic</parameter><constant>Creating admin client to manage Connect internal config topic</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.createKafkaBasedLog</callsite><line>440</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected in consumer callback for KafkaConfigBackingStore: -java.lang.Throwable(name)error</parameter><constant>Unexpected in consumer callback for KafkaConfigBackingStore: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>454</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to convert config data to Kafka Connect format: -org.apache.kafka.connect.errors.DataException(name)e</parameter><constant>Failed to convert config data to Kafka Connect format: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>462</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Removed target state for connector {} due to null value in topic.-java.lang.String(name)connectorName</parameter><constant>Removed target state for connector {} due to null value in topic.</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>475</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Found target state ({}) in wrong format: {}-java.lang.String(name)record.key()-java.lang.Class<>(name)value.value().getClass()</parameter><constant>Found target state ({}) in wrong format: {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>485</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Setting target state for connector '{}' to {}-java.lang.String(name)connectorName-java.lang.Object(name)targetState</parameter><constant>Setting target state for connector '{}' to {}</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>497</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Invalid target state for connector '{}': {}-java.lang.String(name)connectorName-java.lang.Object(name)targetState</parameter><constant>Invalid target state for connector '{}': {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>500</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Successfully processed removal of connector '{}'-java.lang.String(name)connectorName</parameter><constant>Successfully processed removal of connector '{}'</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>517</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Found configuration for connector '{}' in wrong format: {}-java.lang.String(name)record.key()-java.lang.Class<>(name)value.value().getClass()</parameter><constant>Found configuration for connector '{}' in wrong format: {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>523</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Updating configuration for connector '{}'-java.lang.String(name)connectorName</parameter><constant>Updating configuration for connector '{}'</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>532</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Ignoring task configuration because {} couldn't be parsed as a task config key-java.lang.String(name)record.key()</parameter><constant>Ignoring task configuration because {} couldn't be parsed as a task config key</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>551</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Ignoring task configuration for task {} because it is unexpectedly null-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId</parameter><constant>Ignoring task configuration for task {} because it is unexpectedly null</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>555</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Ignoring task configuration for task {} because the value is not a Map but is {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId-java.lang.Class<>(name)value.value().getClass()</parameter><constant>Ignoring task configuration for task {} because the value is not a Map but is {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>559</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Invalid data for config of task {} 'properties' field should be a Map but is {}-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId-java.lang.Class<>(name)newTaskConfig.getClass()</parameter><constant>Invalid data for config of task {} 'properties' field should be a Map but is {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>565</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Storing new config for task {}; this will wait for a commit message before the new config will take effect.-org.apache.kafka.connect.util.ConnectorTaskId(name)taskId</parameter><constant>Storing new config for task {}; this will wait for a commit message before the new config will take effect.</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>574</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Ignoring connector tasks configuration commit for connector '{}' because it is in the wrong format: {}-java.lang.String(name)connectorName-java.lang.Object(name)value.value()</parameter><constant>Ignoring connector tasks configuration commit for connector '{}' because it is in the wrong format: {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>603</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)We have an incomplete set of task configs for connector '{}' probably due to compaction. So we are not doing anything with the new configuration.-java.lang.String(name)connectorName</parameter><constant>We have an incomplete set of task configs for connector '{}' probably due to compaction. So we are not doing anything with the new configuration.</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>618</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Discarding config update record with invalid key: {}-java.lang.String(name)record.key()</parameter><constant>Discarding config update record with invalid key: {}</constant><level>error</level><callsite>org.apache.kafka.connect.storage.KafkaConfigBackingStore.onCompletion</callsite><line>639</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)CRITICAL: Failed to serialize partition key when getting offsets for task with namespace {}. No value for this data will be returned, which may break the task or cause it to skip some data.-java.lang.String(name)namespace-java.lang.Throwable(name)t</parameter><constant>CRITICAL: Failed to serialize partition key when getting offsets for task with namespace {}. No value for this data will be returned, which may break the task or cause it to skip some data.</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageReaderImpl.offsets</callsite><line>70</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Failed to fetch offsets from namespace {}: -java.lang.String(name)namespace-java.lang.Exception(name)e</parameter><constant>Failed to fetch offsets from namespace {}: </constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageReaderImpl.offsets</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Should be able to map {} back to a requested partition-offset key, backing store may have returned invalid data-java.nio.ByteBuffer(name)rawEntry.getKey()</parameter><constant>Should be able to map {} back to a requested partition-offset key, backing store may have returned invalid data</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageReaderImpl.offsets</callsite><line>91</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)CRITICAL: Failed to deserialize offset data when getting offsets for task with namespace {}. No value for this data will be returned, which may break the task or cause it to skip some data. This could either be due to an error in the connector implementation or incompatible schema.-java.lang.String(name)namespace-java.lang.Throwable(name)t</parameter><constant>CRITICAL: Failed to deserialize offset data when getting offsets for task with namespace {}. No value for this data will be returned, which may break the task or cause it to skip some data. This could either be due to an error in the connector implementation or incompatible schema.</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageReaderImpl.offsets</callsite><line>102</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Creating admin client to manage Connect internal offset topic</parameter><constant>Creating admin client to manage Connect internal offset topic</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.KafkaOffsetBackingStore.createKafkaBasedLog</callsite><line>97</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Starting KafkaOffsetBackingStore</parameter><constant>Starting KafkaOffsetBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaOffsetBackingStore.start</callsite><line>108</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Finished reading offsets topic and starting KafkaOffsetBackingStore</parameter><constant>Finished reading offsets topic and starting KafkaOffsetBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaOffsetBackingStore.start</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Stopping KafkaOffsetBackingStore</parameter><constant>Stopping KafkaOffsetBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaOffsetBackingStore.stop</callsite><line>115</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.info</logcall> <parameter>java.lang.String(name)Stopped KafkaOffsetBackingStore</parameter><constant>Stopped KafkaOffsetBackingStore</constant><level>info</level><callsite>org.apache.kafka.connect.storage.KafkaOffsetBackingStore.stop</callsite><line>117</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Invalid call to OffsetStorageWriter flush() while already flushing, the framework should not allow this</parameter><constant>Invalid call to OffsetStorageWriter flush() while already flushing, the framework should not allow this</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageWriter.beginFlush</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)CRITICAL: Failed to serialize offset data, making it impossible to commit offsets under namespace {}. This likely won't recover unless the unserializable partition or offset information is overwritten.-java.lang.String(name)namespace</parameter><constant>CRITICAL: Failed to serialize offset data, making it impossible to commit offsets under namespace {}. This likely won't recover unless the unserializable partition or offset information is overwritten.</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageWriter.doFlush</callsite><line>157</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.error</logcall> <parameter>java.lang.String(name)Cause of serialization failure:-java.lang.Throwable(name)t</parameter><constant>Cause of serialization failure:</constant><level>error</level><callsite>org.apache.kafka.connect.storage.OffsetStorageWriter.doFlush</callsite><line>160</line><superclass>null</superclass><logcall>org.apache.kafka.connect.storage.Logger.debug</logcall> <parameter>java.lang.String(name)Submitting {} entries to backing store. The offsets are: {}-int(name)offsetsSerialized.size()-java.util.Map<Map<String,Object>,Map<String,Object>>(name)toFlush</parameter><constant>Submitting {} entries to backing store. The offsets are: {}</constant><level>debug</level><callsite>org.apache.kafka.connect.storage.OffsetStorageWriter.doFlush</callsite><line>166</line><superclass>null</superclass><logcall>org.apache.kafka.connect.tools.Logger.info</logcall> <parameter>java.lang.String(name)Started SchemaSourceTask {}-{} producing to topic {} resuming from seqno {}-java.lang.String(name)name-int(name)id-java.lang.String(name)topic-long(name)startingSeqno</parameter><constant>Started SchemaSourceTask {}-{} producing to topic {} resuming from seqno {}</constant><level>info</level><callsite>org.apache.kafka.connect.tools.SchemaSourceTask.start</callsite><line>114</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Started MockSourceTask at {} with failure scheduled in {} ms-long(name)startTimeMs-long(name)failureDelayMs</parameter><constant>Started MockSourceTask at {} with failure scheduled in {} ms</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockSourceTask.start</callsite><line>53</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Triggering source task failure</parameter><constant>Triggering source task failure</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockSourceTask.poll</callsite><line>62</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Started MockConnector with failure delay of {} ms-long(name)delayMs</parameter><constant>Started MockConnector with failure delay of {} ms</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockConnector.start</callsite><line>76</line><superclass>org.apache.kafka.connect.connector.Connector</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Triggering connector failure</parameter><constant>Triggering connector failure</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockConnector.start</callsite><line>81</line><superclass>org.apache.kafka.connect.connector.Connector</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Creating single task for MockConnector</parameter><constant>Creating single task for MockConnector</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockConnector.taskConfigs</callsite><line>95</line><superclass>org.apache.kafka.connect.connector.Connector</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Started MockSinkTask at {} with failure scheduled in {} ms-long(name)startTimeMs-long(name)failureDelayMs</parameter><constant>Started MockSinkTask at {} with failure scheduled in {} ms</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockSinkTask.start</callsite><line>54</line><superclass>org.apache.kafka.connect.sink.SinkTask</superclass><logcall>org.apache.kafka.connect.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Triggering sink task failure</parameter><constant>Triggering sink task failure</constant><level>debug</level><callsite>org.apache.kafka.connect.tools.MockSinkTask.put</callsite><line>64</line><superclass>org.apache.kafka.connect.sink.SinkTask</superclass><logcall>org.apache.kafka.connect.tools.Logger.info</logcall> <parameter>java.lang.String(name)Started VerifiableSourceTask {}-{} producing to topic {} resuming from seqno {}-java.lang.String(name)name-int(name)id-java.lang.String(name)topic-long(name)startingSeqno</parameter><constant>Started VerifiableSourceTask {}-{} producing to topic {} resuming from seqno {}</constant><level>info</level><callsite>org.apache.kafka.connect.tools.VerifiableSourceTask.start</callsite><line>90</line><superclass>org.apache.kafka.connect.source.SourceTask</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)"Starting KafkaBasedLog with topic " + topic</parameter><constant>Starting KafkaBasedLog with topic </constant><level>info</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.start</callsite><line>125</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)"Finished reading KafkaBasedLog for topic " + topic</parameter><constant>Finished reading KafkaBasedLog for topic </constant><level>info</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.start</callsite><line>158</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)"Started KafkaBasedLog for topic " + topic</parameter><constant>Started KafkaBasedLog for topic </constant><level>info</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.start</callsite><line>160</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)"Stopping KafkaBasedLog for topic " + topic</parameter><constant>Stopping KafkaBasedLog for topic </constant><level>info</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.stop</callsite><line>164</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.error</logcall> <parameter>java.lang.String(name)Failed to stop KafkaBasedLog producer-org.apache.kafka.common.KafkaException(name)e</parameter><constant>Failed to stop KafkaBasedLog producer</constant><level>error</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.stop</callsite><line>181</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.error</logcall> <parameter>java.lang.String(name)Failed to stop KafkaBasedLog consumer-org.apache.kafka.common.KafkaException(name)e</parameter><constant>Failed to stop KafkaBasedLog consumer</constant><level>error</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.stop</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)"Stopped KafkaBasedLog for topic " + topic</parameter><constant>Stopped KafkaBasedLog for topic </constant><level>info</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.stop</callsite><line>190</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.trace</logcall> <parameter>java.lang.String(name)Starting read to end log for topic {}-java.lang.String(name)topic</parameter><constant>Starting read to end log for topic {}</constant><level>trace</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.readToEnd</callsite><line>207</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.error</logcall> <parameter>java.lang.String(name)"Error polling: " + e</parameter><constant>Error polling: </constant><level>error</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.poll</callsite><line>268</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.trace</logcall> <parameter>java.lang.String(name)Reading to end of offset log</parameter><constant>Reading to end of offset log</constant><level>trace</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.readToLogEnd</callsite><line>273</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.trace</logcall> <parameter>java.lang.String(name)Reading to end of log offsets {}-java.util.Map<TopicPartition,Long>(name)endOffsets</parameter><constant>Reading to end of log offsets {}</constant><level>trace</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.readToLogEnd</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.trace</logcall> <parameter>java.lang.String(name){} started execution-org.apache.kafka.connect.util.WorkThread(name)this</parameter><constant>{} started execution</constant><level>trace</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.run</callsite><line>302</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.trace</logcall> <parameter>java.lang.String(name)Finished read to end log for topic {}-java.lang.String(name)topic</parameter><constant>Finished read to end log for topic {}</constant><level>trace</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.run</callsite><line>314</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected exception in {}-org.apache.kafka.connect.util.WorkThread(name)this-java.lang.Throwable(name)t</parameter><constant>Unexpected exception in {}</constant><level>error</level><callsite>org.apache.kafka.connect.util.KafkaBasedLog.run</callsite><line>339</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Created topic {} on brokers at {}-org.apache.kafka.clients.admin.NewTopic(name)topicsByName.get(topic)-java.lang.String(name)bootstrapServers</parameter><constant>Created topic {} on brokers at {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.TopicAdmin.createTopics</callsite><line>230</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Found existing topic '{}' on the brokers at {}-java.lang.String(name)topic-java.lang.String(name)bootstrapServers</parameter><constant>Found existing topic '{}' on the brokers at {}</constant><level>debug</level><callsite>org.apache.kafka.connect.util.TopicAdmin.createTopics</callsite><line>235</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Unable to create topic(s) '{}' since the brokers at {} do not support the CreateTopics API.-java.lang.String(name) Falling back to assume topic(s) exist or will be auto-created by the broker.-java.lang.String(name)topicNameList-java.lang.String(name)bootstrapServers</parameter><constant>Unable to create topic(s) '{}' since the brokers at {} do not support the CreateTopics API. Falling back to assume topic(s) exist or will be auto-created by the broker.</constant><level>debug</level><callsite>org.apache.kafka.connect.util.TopicAdmin.createTopics</callsite><line>239</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Not authorized to create topic(s) '{}'. Falling back to assume topic(s) exist or will be auto-created by the broker.-java.lang.String(name)topicNameList-java.lang.String(name)bootstrapServers</parameter><constant>Not authorized to create topic(s) '{}'. Falling back to assume topic(s) exist or will be auto-created by the broker.</constant><level>debug</level><callsite>org.apache.kafka.connect.util.TopicAdmin.createTopics</callsite><line>245</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Not authorized to create topic(s) '{}'. Falling back to assume topic(s) exist or will be auto-created by the broker.-java.lang.String(name)topicNameList-java.lang.String(name)bootstrapServers</parameter><constant>Not authorized to create topic(s) '{}'. Falling back to assume topic(s) exist or will be auto-created by the broker.</constant><level>debug</level><callsite>org.apache.kafka.connect.util.TopicAdmin.createTopics</callsite><line>251</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Creating Kafka admin client</parameter><constant>Creating Kafka admin client</constant><level>info</level><callsite>org.apache.kafka.connect.util.ConnectUtils.lookupKafkaClusterId</callsite><line>43</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Looking up Kafka cluster ID</parameter><constant>Looking up Kafka cluster ID</constant><level>debug</level><callsite>org.apache.kafka.connect.util.ConnectUtils.lookupKafkaClusterId</callsite><line>50</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Kafka cluster version is too old to return cluster ID</parameter><constant>Kafka cluster version is too old to return cluster ID</constant><level>info</level><callsite>org.apache.kafka.connect.util.ConnectUtils.lookupKafkaClusterId</callsite><line>54</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.debug</logcall> <parameter>java.lang.String(name)Fetching Kafka cluster ID</parameter><constant>Fetching Kafka cluster ID</constant><level>debug</level><callsite>org.apache.kafka.connect.util.ConnectUtils.lookupKafkaClusterId</callsite><line>57</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Kafka cluster ID: {}-java.lang.String(name)kafkaClusterId</parameter><constant>Kafka cluster ID: {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.ConnectUtils.lookupKafkaClusterId</callsite><line>59</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.Logger.error</logcall> <parameter>java.lang.String(name)Thread {} exiting with uncaught exception: -java.lang.String(name)getName()-java.lang.Throwable(name)e</parameter><constant>Thread {} exiting with uncaught exception: </constant><level>error</level><callsite>org.apache.kafka.connect.util.ShutdownableThread.run</callsite><line>83</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Starting graceful shutdown of thread {}-java.lang.String(name)getName()</parameter><constant>Starting graceful shutdown of thread {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.ShutdownableThread.startGracefulShutdown</callsite><line>118</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.connect.util.Logger.info</logcall> <parameter>java.lang.String(name)Forcing shutdown of thread {}-java.lang.String(name)getName()</parameter><constant>Forcing shutdown of thread {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.ShutdownableThread.forceShutdown</callsite><line>140</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Removing handle for {} task in connector {}-java.lang.String(name)taskId-java.lang.String(name)connectorName</parameter><constant>Removing handle for {} task in connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.ConnectorHandle.deleteTask</callsite><line>84</line><superclass>null</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Created task {} for connector {}-java.lang.String(name)taskId-org.apache.kafka.connect.integration.ConnectorHandle(name)connectorHandle</parameter><constant>Created task {} for connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.TaskHandle.TaskHandle</callsite><line>46</line><superclass>null</superclass><logcall>org.apache.kafka.connect.integration.Logger.debug</logcall> <parameter>java.lang.String(name)Task {} saw {} records, expected {} records-java.lang.String(name)taskId-long(name)expectedRecords - recordsRemainingLatch.getCount()-int(name)expectedRecords</parameter><constant>Task {} saw {} records, expected {} records</constant><level>debug</level><callsite>org.apache.kafka.connect.integration.TaskHandle.awaitRecords</callsite><line>151</line><superclass>null</superclass><logcall>org.apache.kafka.connect.integration.Logger.debug</logcall> <parameter>java.lang.String(name)Task {} saw {} records, expected {} records-java.lang.String(name)taskId-long(name)expectedCommits - recordsToCommitLatch.getCount()-int(name)expectedCommits</parameter><constant>Task {} saw {} records, expected {} records</constant><level>debug</level><callsite>org.apache.kafka.connect.integration.TaskHandle.awaitCommits</callsite><line>175</line><superclass>null</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Started {} connector {}-java.lang.String(name)this.getClass().getSimpleName()-java.lang.String(name)connectorName</parameter><constant>Started {} connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.start</callsite><line>57</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Stopped {} connector {}-java.lang.String(name)this.getClass().getSimpleName()-java.lang.String(name)connectorName</parameter><constant>Stopped {} connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.stop</callsite><line>79</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Configured {} connector {}-java.lang.String(name)this.getClass().getSimpleName()-java.lang.String(name)connectorName</parameter><constant>Configured {} connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.config</callsite><line>84</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Started {} task {} with properties {}-java.lang.String(name)this.getClass().getSimpleName()-java.lang.String(name)taskId-java.util.Map<String,String>(name)props</parameter><constant>Started {} task {} with properties {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.start</callsite><line>117</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Task {} committing offsets-java.lang.String(name)taskId</parameter><constant>Task {} committing offsets</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.commit</callsite><line>145</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.trace</logcall> <parameter>java.lang.String(name)Committing record: {}-org.apache.kafka.connect.source.SourceRecord(name)record</parameter><constant>Committing record: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.commitRecord</callsite><line>151</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Stopped {} task {}-java.lang.String(name)this.getClass().getSimpleName()-java.lang.String(name)taskId</parameter><constant>Stopped {} task {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSourceConnector.stop</callsite><line>157</line><superclass>org.apache.kafka.connect.runtime.TestSourceConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.info</logcall> <parameter>java.lang.String(name)Starting connector {}-java.lang.String(name)props.get("name")</parameter><constant>Starting connector {}</constant><level>info</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.start</callsite><line>55</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.debug</logcall> <parameter>java.lang.String(name)Starting task {}-java.lang.String(name)taskId</parameter><constant>Starting task {}</constant><level>debug</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.start</callsite><line>109</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.debug</logcall> <parameter>java.lang.String(name)Opening {} partitions-int(name)partitions.size()</parameter><constant>Opening {} partitions</constant><level>debug</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.open</callsite><line>114</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.trace</logcall> <parameter>java.lang.String(name)Task {} obtained record (key='{}' value='{}')-java.lang.String(name)taskId-java.lang.Object(name)rec.key()-java.lang.Object(name)rec.value()</parameter><constant>Task {} obtained record (key='{}' value='{}')</constant><level>trace</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.put</callsite><line>127</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.warn</logcall> <parameter>java.lang.String(name)preCommit was called with topic-partition {} that is not included in the assignments of this task {}-org.apache.kafka.common.TopicPartition(name)tp-java.util.Set<TopicPartition>(name)assignments</parameter><constant>preCommit was called with topic-partition {} that is not included in the assignments of this task {}</constant><level>warn</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.preCommit</callsite><line>136</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.integration.Logger.error</logcall> <parameter>java.lang.String(name)Forwarding to framework request to commit additional {} for {}-java.lang.Long(name)recordsSinceLastCommit-org.apache.kafka.common.TopicPartition(name)tp</parameter><constant>Forwarding to framework request to commit additional {} for {}</constant><level>error</level><callsite>org.apache.kafka.connect.integration.MonitorableSinkConnector.preCommit</callsite><line>140</line><superclass>org.apache.kafka.connect.runtime.TestSinkConnector</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.warn</logcall> <parameter>java.lang.String(name)Kafka did not shutdown gracefully</parameter><constant>Kafka did not shutdown gracefully</constant><level>warn</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.stop</callsite><line>145</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)Could not stop kafka-java.lang.Exception(name)e</parameter><constant>Could not stop kafka</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.stop</callsite><line>147</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.info</logcall> <parameter>java.lang.String(name)Started worker {}-org.apache.kafka.connect.util.clusters.WorkerHandle(name)worker</parameter><constant>Started worker {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.addWorker</callsite><line>163</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.info</logcall> <parameter>java.lang.String(name)Stopping worker {}-org.apache.kafka.connect.util.clusters.WorkerHandle(name)worker</parameter><constant>Stopping worker {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.stopWorker</callsite><line>196</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.warn</logcall> <parameter>java.lang.String(name)Worker {} did not shutdown gracefully-org.apache.kafka.connect.util.clusters.WorkerHandle(name)worker</parameter><constant>Worker {} did not shutdown gracefully</constant><level>warn</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.stopWorker</callsite><line>199</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)Could not stop connect-java.lang.Exception(name)e</parameter><constant>Could not stop connect</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.stopWorker</callsite><line>201</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.info</logcall> <parameter>java.lang.String(name)Starting Connect cluster '{}' with {} workers-java.lang.String(name)connectClusterName-int(name)numInitialWorkers</parameter><constant>Starting Connect cluster '{}' with {} workers</constant><level>info</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.startConnect</callsite><line>208</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)"Could not execute PUT request to " + url-java.io.IOException(name)e</parameter><constant>Could not execute PUT request to </constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.configureConnector</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)Could not read connector list-java.io.IOException(name)e</parameter><constant>Could not read connector list</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.connectors</callsite><line>312</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)Could not read connector state-java.io.IOException(name)e</parameter><constant>Could not read connector state</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.connectorStatus</callsite><line>331</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)Executing PUT request to URL={}. Payload={}-java.lang.String(name)url-java.lang.String(name)body</parameter><constant>Executing PUT request to URL={}. Payload={}</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executePut</callsite><line>357</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.info</logcall> <parameter>java.lang.String(name)PUT response for URL={} is {}-java.lang.String(name)url-java.lang.String(name)responseToString(is)</parameter><constant>PUT response for URL={} is {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executePut</callsite><line>367</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.info</logcall> <parameter>java.lang.String(name)PUT error response for URL={} is {}-java.lang.String(name)url-java.lang.String(name)responseToString(is)</parameter><constant>PUT error response for URL={} is {}</constant><level>info</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executePut</callsite><line>371</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)Executing GET request to URL={}.-java.lang.String(name)url</parameter><constant>Executing GET request to URL={}.</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executeGet</callsite><line>386</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)GET response for URL={} is {}-java.lang.String(name)url-java.lang.StringBuilder(name)response</parameter><constant>GET response for URL={} is {}</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executeGet</callsite><line>396</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)Executing DELETE request to URL={}-java.lang.String(name)url</parameter><constant>Executing DELETE request to URL={}</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedConnectCluster.executeDelete</callsite><line>409</line><superclass>null</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)Could not shutdown producer -java.lang.Exception(name)e</parameter><constant>Could not shutdown producer </constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.stop</callsite><line>140</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)msg-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.stop</callsite><line>149</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)msg-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.stop</callsite><line>160</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.error</logcall> <parameter>java.lang.String(name)msg-java.lang.Throwable(name)t</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.stop</callsite><line>169</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)Creating topic { name: {}, partitions: {}, replication: {}, config: {} }-java.lang.String(name)topic-int(name)partitions-int(name)replication-java.util.Map<String,String>(name)topicConfig</parameter><constant>Creating topic { name: {}, partitions: {}, replication: {}, config: {} }</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.createTopic</callsite><line>232</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.connect.util.clusters.Logger.debug</logcall> <parameter>java.lang.String(name)Consuming from {} for {} millis.-java.lang.String(name)Arrays.toString(topics)-long(name)allowedDuration</parameter><constant>Consuming from {} for {} millis.</constant><level>debug</level><callsite>org.apache.kafka.connect.util.clusters.EmbeddedKafkaCluster.consume</callsite><line>288</line><superclass>org.apache.kafka.connect.util.clusters.ExternalResource</superclass><logcall>org.apache.kafka.streams.Logger.debug</logcall> <parameter>java.lang.String(name)Cannot transit to {} within {}ms-org.apache.kafka.streams.State(name)targetState-long(name)waitMs</parameter><constant>Cannot transit to {} within {}ms</constant><level>debug</level><callsite>org.apache.kafka.streams.KafkaStreams.waitOnState</callsite><line>227</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.info</logcall> <parameter>java.lang.String(name)State transition from {} to {}-org.apache.kafka.streams.State(name)oldState-org.apache.kafka.streams.State(name)newState</parameter><constant>State transition from {} to {}</constant><level>info</level><callsite>org.apache.kafka.streams.KafkaStreams.setState</callsite><line>263</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.error</logcall> <parameter>java.lang.String(name)All stream threads have died. The instance will be in error state and should be closed.</parameter><constant>All stream threads have died. The instance will be in error state and should be closed.</constant><level>error</level><callsite>org.apache.kafka.streams.KafkaStreams.maybeSetError</callsite><line>423</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.error</logcall> <parameter>java.lang.String(name)Global thread has died. The instance will be in error state and should be closed.</parameter><constant>Global thread has died. The instance will be in error state and should be closed.</constant><level>error</level><callsite>org.apache.kafka.streams.KafkaStreams.onChange</callsite><line>473</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.warn</logcall> <parameter>java.lang.String(name)Negative cache size passed in. Reverting to cache size of 0 bytes.</parameter><constant>Negative cache size passed in. Reverting to cache size of 0 bytes.</constant><level>warn</level><callsite>org.apache.kafka.streams.KafkaStreams.KafkaStreams</callsite><line>683</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.debug</logcall> <parameter>java.lang.String(name)Starting Streams client</parameter><constant>Starting Streams client</constant><level>debug</level><callsite>org.apache.kafka.streams.KafkaStreams.start</callsite><line>788</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.debug</logcall> <parameter>java.lang.String(name)Stopping Streams client with timeoutMillis = {} ms. You are using deprecated method. Please, consider update your code.-long(name)timeoutMs</parameter><constant>Stopping Streams client with timeoutMillis = {} ms. You are using deprecated method. Please, consider update your code.</constant><level>debug</level><callsite>org.apache.kafka.streams.KafkaStreams.close</callsite><line>834</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.info</logcall> <parameter>java.lang.String(name)Already in the pending shutdown state, wait to complete shutdown</parameter><constant>Already in the pending shutdown state, wait to complete shutdown</constant><level>info</level><callsite>org.apache.kafka.streams.KafkaStreams.close</callsite><line>850</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.info</logcall> <parameter>java.lang.String(name)Streams client stopped completely</parameter><constant>Streams client stopped completely</constant><level>info</level><callsite>org.apache.kafka.streams.KafkaStreams.close</callsite><line>898</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.info</logcall> <parameter>java.lang.String(name)Streams client cannot stop completely within the timeout</parameter><constant>Streams client cannot stop completely within the timeout</constant><level>info</level><callsite>org.apache.kafka.streams.KafkaStreams.close</callsite><line>901</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.debug</logcall> <parameter>java.lang.String(name)Stopping Streams client with timeoutMillis = {} ms.-long(name)timeoutMs</parameter><constant>Stopping Streams client with timeoutMillis = {} ms.</constant><level>debug</level><callsite>org.apache.kafka.streams.KafkaStreams.close</callsite><line>924</line><superclass>null</superclass><logcall>org.apache.kafka.streams.Logger.debug</logcall> <parameter>java.lang.String(name)Using {} default value of {} as exactly once is enabled.-java.lang.String(name)commit.interval.ms-long(name)100</parameter><constant>Using {} default value of {} as exactly once is enabled.commit.interval.ms100</constant><level>debug</level><callsite>org.apache.kafka.streams.StreamsConfig.postProcessParsedConfig</callsite><line>855</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.streams.Logger.warn</logcall> <parameter>java.lang.String(name)String.format(nonConfigurableConfigMessage,"consumer",config,"",clientProvidedProps.get(config),CONSUMER_DEFAULT_OVERRIDES.get(config))</parameter><constant>consumer</constant><level>warn</level><callsite>org.apache.kafka.streams.StreamsConfig.checkIfUnexpectedUserSpecifiedConsumerConfig</callsite><line>916</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.streams.Logger.warn</logcall> <parameter>java.lang.String(name)String.format(nonConfigurableConfigMessage,"consumer",config,eosMessage,clientProvidedProps.get(config),CONSUMER_EOS_OVERRIDES.get(config))</parameter><constant>consumer</constant><level>warn</level><callsite>org.apache.kafka.streams.StreamsConfig.checkIfUnexpectedUserSpecifiedConsumerConfig</callsite><line>922</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.streams.Logger.warn</logcall> <parameter>java.lang.String(name)String.format(nonConfigurableConfigMessage,"producer",config,eosMessage,clientProvidedProps.get(config),PRODUCER_EOS_OVERRIDES.get(config))</parameter><constant>producer</constant><level>warn</level><callsite>org.apache.kafka.streams.StreamsConfig.checkIfUnexpectedUserSpecifiedConsumerConfig</callsite><line>928</line><superclass>org.apache.kafka.common.config.AbstractConfig</superclass><logcall>org.apache.kafka.streams.errors.Logger.error</logcall> <parameter>java.lang.String(name)Exception caught during Deserialization, taskId: {}, topic: {}, partition: {}, offset: {}-org.apache.kafka.streams.processor.TaskId(name)context.taskId()-java.lang.String(name)record.topic()-int(name)record.partition()-long(name)record.offset()-java.lang.Exception(name)exception</parameter><constant>Exception caught during Deserialization, taskId: {}, topic: {}, partition: {}, offset: {}</constant><level>error</level><callsite>org.apache.kafka.streams.errors.LogAndFailExceptionHandler.handle</callsite><line>39</line><superclass>null</superclass><logcall>org.apache.kafka.streams.errors.Logger.warn</logcall> <parameter>java.lang.String(name)Exception caught during Deserialization, taskId: {}, topic: {}, partition: {}, offset: {}-org.apache.kafka.streams.processor.TaskId(name)context.taskId()-java.lang.String(name)record.topic()-int(name)record.partition()-long(name)record.offset()-java.lang.Exception(name)exception</parameter><constant>Exception caught during Deserialization, taskId: {}, topic: {}, partition: {}, offset: {}</constant><level>warn</level><callsite>org.apache.kafka.streams.errors.LogAndContinueExceptionHandler.handle</callsite><line>39</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]-K(name)key-V(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamAggregate.process</callsite><line>83</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. topic=[{}] partition=[{}] offset=[{}]-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableSource.process</callsite><line>97</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Detected out-of-order KTable update for {} at offset {}, partition {}.-java.lang.String(name)store.name()-long(name)context().offset()-int(name)context().partition()</parameter><constant>Detected out-of-order KTable update for {} at offset {}, partition {}.</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableSource.process</callsite><line>111</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Adding nodes to topology {} child nodes {}-org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode(name)streamGraphNode-java.util.Collection<StreamsGraphNode>(name)streamGraphNode.children()</parameter><constant>Adding nodes to topology {} child nodes {}</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.buildAndOptimizeTopology</callsite><line>285</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Optimizing the Kafka Streams graph for repartition nodes</parameter><constant>Optimizing the Kafka Streams graph for repartition nodes</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.maybePerformOptimizations</callsite><line>302</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Marking KTable source nodes to optimize using source topic for changelogs </parameter><constant>Marking KTable source nodes to optimize using source topic for changelogs </constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.optimizeKTableSourceTopics</callsite><line>309</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Found the child node of the key changer {} from the repartition {}.-org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode(name)keyChangingNodeChild-org.apache.kafka.streams.kstream.internals.graph.OptimizableRepartitionNode(name)repartitionNodeToBeReplaced</parameter><constant>Found the child node of the key changer {} from the repartition {}.</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.maybeOptimizeRepartitionOperations</callsite><line>346</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Removing {} from {}  children {}-org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode(name)keyChangingNodeChild-org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode(name)keyChangingNode-java.util.Collection<StreamsGraphNode>(name)keyChangingNode.children()</parameter><constant>Removing {} from {}  children {}</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.maybeOptimizeRepartitionOperations</callsite><line>352</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Updated node {} children {}-org.apache.kafka.streams.kstream.internals.graph.StreamsGraphNode(name)optimizedSingleRepartition-java.util.Collection<StreamsGraphNode>(name)optimizedSingleRepartition.children()</parameter><constant>Updated node {} children {}</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.InternalStreamsBuilder.maybeOptimizeRepartitionOperations</callsite><line>371</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]-org.apache.kafka.streams.kstream.internals.Change<V1>(name)change-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableKTableOuterJoin.process</callsite><line>87</line><superclass>org.apache.kafka.streams.kstream.internals.KTableKTableAbstractJoin</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.info</logcall> <parameter>java.lang.String(name)Using grace period of [{}] as the suppress duration for node [{}].-java.time.Duration(name)Duration.ofMillis(grace)-java.lang.String(name)name</parameter><constant>Using grace period of [{}] as the suppress duration for node [{}].</constant><level>info</level><callsite>org.apache.kafka.streams.kstream.internals.KTableImpl.buildSuppress</callsite><line>523</line><superclass>org.apache.kafka.streams.kstream.internals.AbstractStream</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]-K(name)key-V1(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamKStreamJoin.process</callsite><line>83</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]-K(name)key-V(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamReduce.process</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. value=[{}] topic=[{}] partition=[{}] offset=[{}]-V(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamWindowAggregate.process</callsite><line>107</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping record for expired window. key=[{}] topic=[{}] partition=[{}] offset=[{}] timestamp=[{}] window=[{},{}) expiration=[{}] streamTime=[{}]-K(name)key-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()-long(name)context().timestamp()-java.lang.Long(name)windowStart-long(name)windowEnd-long(name)closeTime-long(name)observedStreamTime</parameter><constant>Skipping record for expired window. key=[{}] topic=[{}] partition=[{}] offset=[{}] timestamp=[{}] window=[{},{}) expiration=[{}] streamTime=[{}]</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamWindowAggregate.process</callsite><line>150</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]-org.apache.kafka.streams.kstream.internals.Change<V1>(name)change-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableKTableLeftJoin.process</callsite><line>88</line><superclass>org.apache.kafka.streams.kstream.internals.KTableKTableAbstractJoin</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. value=[{}] topic=[{}] partition=[{}] offset=[{}]-V(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamSessionWindowAggregate.process</callsite><line>108</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping record for expired window. key=[{}] topic=[{}] partition=[{}] offset=[{}] timestamp=[{}] window=[{},{}] expiration=[{}] streamTime=[{}]-K(name)key-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()-long(name)timestamp-long(name)mergedWindow.start()-long(name)mergedWindow.end()-long(name)closeTime-long(name)observedStreamTime</parameter><constant>Skipping record for expired window. key=[{}] topic=[{}] partition=[{}] offset=[{}] timestamp=[{}] window=[{},{}] expiration=[{}] streamTime=[{}]</constant><level>debug</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamSessionWindowAggregate.process</callsite><line>141</line><superclass>null</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]-K1(name)key-V1(name)value-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key or value. key=[{}] value=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KStreamKTableJoinProcessor.process</callsite><line>71</line><superclass>org.apache.kafka.streams.processor.AbstractProcessor</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]-org.apache.kafka.streams.kstream.internals.Change<V1>(name)change-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableKTableRightJoin.process</callsite><line>86</line><superclass>org.apache.kafka.streams.kstream.internals.KTableKTableAbstractJoin</superclass><logcall>org.apache.kafka.streams.kstream.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]-org.apache.kafka.streams.kstream.internals.Change<V1>(name)change-java.lang.String(name)context().topic()-int(name)context().partition()-long(name)context().offset()</parameter><constant>Skipping record due to null key. change=[{}] topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.kstream.internals.KTableKTableInnerJoin.process</callsite><line>89</line><superclass>org.apache.kafka.streams.kstream.internals.KTableKTableAbstractJoin</superclass><logcall>org.apache.kafka.streams.processor.Logger.error</logcall> <parameter>java.lang.String(name)Empty partitions for topic {}-java.lang.String(name)topic</parameter><constant>Empty partitions for topic {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.DefaultPartitionGrouper.maxNumPartitions</callsite><line>83</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.Logger.warn</logcall> <parameter>java.lang.String(name)Input record {} will be dropped because it has an invalid (negative) timestamp.-org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object>(name)record</parameter><constant>Input record {} will be dropped because it has an invalid (negative) timestamp.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.LogAndSkipOnInvalidTimestamp.onInvalidTimestamp</callsite><line>66</line><superclass>org.apache.kafka.streams.processor.ExtractRecordMetadataTimestamp</superclass><logcall>org.apache.kafka.streams.processor.Logger.error</logcall> <parameter>java.lang.String(name)message</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.FailOnInvalidTimestamp.onInvalidTimestamp</callsite><line>72</line><superclass>org.apache.kafka.streams.processor.ExtractRecordMetadataTimestamp</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Added restorer for changelog {}-org.apache.kafka.common.TopicPartition(name)restorer.partition()</parameter><constant>Added restorer for changelog {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.register</callsite><line>71</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Restoring StreamTasks failed. Deleting StreamTasks stores to recreate from scratch.-org.apache.kafka.clients.consumer.InvalidOffsetException(name)recoverableException</parameter><constant>Restoring StreamTasks failed. Deleting StreamTasks stores to recreate from scratch.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore</callsite><line>101</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Reinitializing StreamTask {} for changelog {}-org.apache.kafka.streams.processor.internals.StreamTask(name)task-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Reinitializing StreamTask {} for changelog {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.restore</callsite><line>105</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Could not fetch end offset for {}; will fall back to partition by partition fetching-java.util.Set<TopicPartition>(name)initializable</parameter><constant>Could not fetch end offset for {}; will fall back to partition by partition fetching</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.initialize</callsite><line>148</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)End offset cannot be found form the returned metadata; removing this partition from the current run loop</parameter><constant>End offset cannot be found form the returned metadata; removing this partition from the current run loop</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.initialize</callsite><line>174</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Start restoring state stores from changelog topics {}-java.util.Set<TopicPartition>(name)initialized</parameter><constant>Start restoring state stores from changelog topics {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.startRestoration</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Found checkpoint {} from changelog {} for store {}.-long(name)restorer.checkpoint()-org.apache.kafka.common.TopicPartition(name)partition-java.lang.String(name)restorer.storeName()</parameter><constant>Found checkpoint {} from changelog {} for store {}.</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.startRestoration</callsite><line>198</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Did not find checkpoint from changelog {} for store {}, rewinding to beginning.-org.apache.kafka.common.TopicPartition(name)partition-java.lang.String(name)restorer.storeName()</parameter><constant>Did not find checkpoint from changelog {} for store {}, rewinding to beginning.</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.startRestoration</callsite><line>207</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)No checkpoint found for task {} state store {} changelog {} with EOS turned on. Reinitializing the task and restore its state from the beginning.-org.apache.kafka.streams.processor.TaskId(name)task.id-java.lang.String(name)restorer.storeName()-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>No checkpoint found for task {} state store {} changelog {} with EOS turned on. Reinitializing the task and restore its state from the beginning.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.startRestoration</callsite><line>221</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Restoring task {}'s state store {} from beginning of the changelog {} -org.apache.kafka.streams.processor.TaskId(name)task.id-java.lang.String(name)restorer.storeName()-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Restoring task {}'s state store {} from beginning of the changelog {} </constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.startRestoration</callsite><line>230</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Restoring partition {} from offset {} to endOffset {}-org.apache.kafka.common.TopicPartition(name)partition-long(name)startingOffset-java.lang.Long(name)endOffset</parameter><constant>Restoring partition {} from offset {} to endOffset {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.logRestoreOffsets</callsite><line>247</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Could not fetch topic metadata within the timeout, will retry in the next run loop</parameter><constant>Could not fetch topic metadata within the timeout, will retry in the next run loop</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.refreshChangelogInfo</callsite><line>261</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Restored from {} to {} with {} records, ending offset is {}, next starting position is {}-org.apache.kafka.common.TopicPartition(name)restorer.partition()-java.lang.String(name)restorer.storeName()-int(name)records.size()-long(name)lastRestoredOffset-long(name)nextPosition</parameter><constant>Restored from {} to {} with {} records, ending offset is {}, next starting position is {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StoreChangelogReader.processNext</callsite><line>320</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)nodeToSourceTopics {}-java.util.Map<String,List<String>>(name)nodeToSourceTopics</parameter><constant>nodeToSourceTopics {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopologyBuilder.setRegexMatchedTopicsToSourceNodes</callsite><line>1068</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){}updating builder with {} topic(s) with possible matching regex subscription(s)-java.lang.String(name)logPrefix-org.apache.kafka.streams.processor.internals.SubscriptionUpdates(name)subscriptionUpdates</parameter><constant>{}updating builder with {} topic(s) with possible matching regex subscription(s)</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopologyBuilder.updateSubscriptions</callsite><line>1211</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){}found {} topics possibly matching regex-java.lang.String(name)logPrefix-java.util.Set<String>(name)topics</parameter><constant>{}found {} topics possibly matching regex</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopologyBuilder.updateSubscribedTopics</callsite><line>1873</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected state transition from {} to {}-org.apache.kafka.streams.processor.internals.State(name)oldState-org.apache.kafka.streams.processor.internals.State(name)newState</parameter><constant>Unexpected state transition from {} to {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.setState</callsite><line>157</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)State transition from {} to {}-org.apache.kafka.streams.processor.internals.State(name)oldState-org.apache.kafka.streams.processor.internals.State(name)newState</parameter><constant>State transition from {} to {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.setState</callsite><line>160</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Updating global state failed. You can restart KafkaStreams to recover from this error.-org.apache.kafka.clients.consumer.InvalidOffsetException(name)recoverableException</parameter><constant>Updating global state failed. You can restart KafkaStreams to recover from this error.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.pollAndUpdate</callsite><line>249</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close global consumer due to the following error:-java.lang.RuntimeException(name)e</parameter><constant>Failed to close global consumer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.close</callsite><line>261</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error happened during initialization of the global state store; this thread has shutdown</parameter><constant>Error happened during initialization of the global state store; this thread has shutdown</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.run</callsite><line>281</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Shutting down</parameter><constant>Shutting down</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.run</callsite><line>298</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close state maintainer due to the following error:-java.io.IOException(name)e</parameter><constant>Failed to close state maintainer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.run</callsite><line>303</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Shutdown complete</parameter><constant>Shutdown complete</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.run</callsite><line>310</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Could not lock global state directory. This could happen if multiple KafkaStreams instances are running on the same host using the same state directory.-org.apache.kafka.streams.errors.LockException(name)fatalException</parameter><constant>Could not lock global state directory. This could happen if multiple KafkaStreams instances are running on the same host using the same state directory.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStreamThread.initialize</callsite><line>351</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Source node {} extracted timestamp {} for record {}-java.lang.String(name)source.name()-long(name)timestamp-org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object>(name)deserialized</parameter><constant>Source node {} extracted timestamp {} for record {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.RecordQueue.updateHead</callsite><line>178</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to negative extracted timestamp. topic=[{}] partition=[{}] offset=[{}] extractedTimestamp=[{}] extractor=[{}]-java.lang.String(name)deserialized.topic()-int(name)deserialized.partition()-long(name)deserialized.offset()-long(name)timestamp-java.lang.String(name)timestampExtractor.getClass().getCanonicalName()</parameter><constant>Skipping record due to negative extracted timestamp. topic=[{}] partition=[{}] offset=[{}] extractedTimestamp=[{}] extractor=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.RecordQueue.updateHead</callsite><line>182</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Pausing partitions: {}-java.util.Collection<TopicPartition>(name)assignment</parameter><constant>Pausing partitions: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.createTasks</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Adding assigned tasks as active: {}-java.util.Map<TaskId,Set<TopicPartition>>(name)assignedActiveTasks</parameter><constant>Adding assigned tasks as active: {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStreamTasks</callsite><line>120</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to resume an active task {} due to the following error:-org.apache.kafka.streams.processor.TaskId(name)taskId-org.apache.kafka.streams.errors.StreamsException(name)e</parameter><constant>Failed to resume an active task {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStreamTasks</callsite><line>131</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Task {} owned partitions {} are not contained in the assignment {}-org.apache.kafka.streams.processor.TaskId(name)taskId-java.util.Set<TopicPartition>(name)partitions-java.util.Collection<TopicPartition>(name)assignment</parameter><constant>Task {} owned partitions {} are not contained in the assignment {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStreamTasks</callsite><line>135</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)New active tasks to be created: {}-java.util.Map<TaskId,Set<TopicPartition>>(name)newTasks</parameter><constant>New active tasks to be created: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStreamTasks</callsite><line>146</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Adding assigned standby tasks {}-java.util.Map<TaskId,Set<TopicPartition>>(name)assignedStandbyTasks</parameter><constant>Adding assigned standby tasks {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStandbyTasks</callsite><line>158</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)New standby tasks to be created: {}-java.util.Map<TaskId,Set<TopicPartition>>(name)newStandbyTasks</parameter><constant>New standby tasks to be created: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.addStandbyTasks</callsite><line>175</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Suspending all active tasks {} and standby tasks {}-java.util.Set<TaskId>(name)active.runningTaskIds()-java.util.Set<TaskId>(name)standby.runningTaskIds()</parameter><constant>Suspending all active tasks {} and standby tasks {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.suspendTasksAndState</callsite><line>238</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Shutting down all active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}-java.util.Set<TaskId>(name)active.runningTaskIds()-java.util.Set<TaskId>(name)standby.runningTaskIds()-java.util.Set<TaskId>(name)active.previousTaskIds()-java.util.Set<TaskId>(name)standby.previousTaskIds()</parameter><constant>Shutting down all active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.shutdown</callsite><line>263</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Resuming partitions {}-java.util.Set<TopicPartition>(name)assignment</parameter><constant>Resuming partitions {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.updateNewAndRestoringTasks</callsite><line>334</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Previous delete-records request has failed: {}. Try sending the new request now-java.util.Map<TopicPartition,KafkaFuture<DeletedRecords>>(name)deleteRecordsResult.lowWatermarks()</parameter><constant>Previous delete-records request has failed: {}. Try sending the new request now</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.maybePurgeCommitedRecords</callsite><line>445</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Sent delete-records request: {}-java.util.Map<TopicPartition,RecordsToDelete>(name)recordsToDelete</parameter><constant>Sent delete-records request: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.TaskManager.maybePurgeCommitedRecords</callsite><line>454</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Checkpointable offsets read from checkpoint: {}-java.util.Map<TopicPartition,Long>(name)checkpointableOffsets</parameter><constant>Checkpointable offsets read from checkpoint: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.ProcessorStateManager</callsite><line>100</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Created state store manager for task {} with the acquired state dir lock-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>Created state store manager for task {} with the acquired state dir lock</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.ProcessorStateManager</callsite><line>108</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Registering state store {} to its state manager-java.lang.String(name)storeName</parameter><constant>Registering state store {} to its state manager</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.register</callsite><line>126</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Preparing standby replica of persistent state store {} with changelog topic {}-java.lang.String(name)storeName-java.lang.String(name)topic</parameter><constant>Preparing standby replica of persistent state store {} with changelog topic {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.register</callsite><line>147</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Restoring state store {} from changelog topic {} at checkpoint {}-java.lang.String(name)storeName-java.lang.String(name)topic-java.lang.Long(name)checkpointableOffsets.get(storePartition)</parameter><constant>Restoring state store {} from changelog topic {} at checkpoint {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.register</callsite><line>152</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating store offset limit for partition {} to {}-org.apache.kafka.common.TopicPartition(name)partition-long(name)limit</parameter><constant>Updating store offset limit for partition {} to {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.putOffsetLimit</callsite><line>223</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Flushing all stores registered in the state manager</parameter><constant>Flushing all stores registered in the state manager</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush</callsite><line>242</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Flushing store {}-java.lang.String(name)store.name()</parameter><constant>Flushing store {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush</callsite><line>246</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to flush state store {}: -java.lang.String(name)store.name()-java.lang.Exception(name)e</parameter><constant>Failed to flush state store {}: </constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.flush</callsite><line>253</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing its state manager and all the registered state stores</parameter><constant>Closing its state manager and all the registered state stores</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.close</callsite><line>277</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing storage engine {}-java.lang.String(name)store.name()</parameter><constant>Closing storage engine {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.close</callsite><line>281</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close state store {}: -java.lang.String(name)store.name()-java.lang.Exception(name)e</parameter><constant>Failed to close state store {}: </constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.close</callsite><line>289</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Skipping to close non-initialized store {}-java.lang.String(name)entry.getKey()</parameter><constant>Skipping to close non-initialized store {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.close</callsite><line>292</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Checkpointable offsets updated with restored offsets: {}-java.util.Map<TopicPartition,Long>(name)this.checkpointableOffsets</parameter><constant>Checkpointable offsets updated with restored offsets: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.checkpoint</callsite><line>316</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Checkpointable offsets updated with active acked offsets: {}-java.util.Map<TopicPartition,Long>(name)this.checkpointableOffsets</parameter><constant>Checkpointable offsets updated with active acked offsets: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.checkpoint</callsite><line>338</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Writing checkpoint: {}-java.util.Map<TopicPartition,Long>(name)this.checkpointableOffsets</parameter><constant>Writing checkpoint: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.checkpoint</callsite><line>345</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to write offset checkpoint file to [{}]-org.apache.kafka.streams.state.internals.OffsetCheckpoint(name)checkpoint-java.io.IOException(name)e</parameter><constant>Failed to write offset checkpoint file to [{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.checkpoint</callsite><line>349</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Register global stores {}-java.util.List<StateStore>(name)stateStores</parameter><constant>Register global stores {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.ProcessorStateManager.registerGlobalStateStores</callsite><line>359</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to unlock the global state directory-java.io.IOException(name)e</parameter><constant>Failed to unlock the global state directory</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.initialize</callsite><line>115</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Restoring state for global store {}-java.lang.String(name)store.name()</parameter><constant>Restoring state for global store {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.register</callsite><line>171</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to get end offsets for topic partitions of global store {} after {} retry attempts. You can increase the number of retries via configuration parameter `retries`.-java.lang.String(name)store.name()-int(name)retries-org.apache.kafka.common.errors.TimeoutException(name)retryableException</parameter><constant>Failed to get end offsets for topic partitions of global store {} after {} retry attempts. You can increase the number of retries via configuration parameter `retries`.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.register</callsite><line>181</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})-java.util.List<TopicPartition>(name)topicPartitions-long(name)retryBackoffMs-int(name)attempts-int(name)retries-org.apache.kafka.common.errors.TimeoutException(name)retryableException</parameter><constant>Failed to get end offsets for partitions {}, backing off for {} ms to retry (attempt {} of {})</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.register</callsite><line>190</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to get partitions for topic {} after {} retry attempts due to timeout. The broker may be transiently unavailable at the moment. You can increase the number of retries via configuration parameter `retries`.-java.lang.String(name)sourceTopic-int(name)retries-org.apache.kafka.common.errors.TimeoutException(name)retryableException</parameter><constant>Failed to get partitions for topic {} after {} retry attempts due to timeout. The broker may be transiently unavailable at the moment. You can increase the number of retries via configuration parameter `retries`.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.topicPartitionsForStore</callsite><line>224</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Failed to get partitions for topic {} due to timeout. The broker may be transiently unavailable at the moment. Backing off for {} ms to retry (attempt {} of {})-java.lang.String(name)sourceTopic-long(name)retryBackoffMs-int(name)attempts-int(name)retries-org.apache.kafka.common.errors.TimeoutException(name)retryableException</parameter><constant>Failed to get partitions for topic {} due to timeout. The broker may be transiently unavailable at the moment. Backing off for {} ms to retry (attempt {} of {})</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.topicPartitionsForStore</callsite><line>235</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Restoring GlobalStore {} failed due to: {}. Deleting global store to recreate from scratch.-java.lang.String(name)storeName-java.lang.String(name)recoverableException.toString()</parameter><constant>Restoring GlobalStore {} failed due to: {}. Deleting global store to recreate from scratch.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.restoreState</callsite><line>293</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Flushing all global globalStores registered in the state manager</parameter><constant>Flushing all global globalStores registered in the state manager</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.flush</callsite><line>309</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Flushing global store={}-java.lang.String(name)store.name()</parameter><constant>Flushing global store={}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.flush</callsite><line>314</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing global storage engine {}-java.lang.String(name)entry.getKey()</parameter><constant>Closing global storage engine {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.close</callsite><line>338</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close global state store {}-java.lang.String(name)entry.getKey()-java.lang.Exception(name)e</parameter><constant>Failed to close global state store {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.close</callsite><line>342</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Skipping to close non-initialized store {}-java.lang.String(name)entry.getKey()</parameter><constant>Skipping to close non-initialized store {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.close</callsite><line>351</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to write offset checkpoint file to {} for global stores: {}-org.apache.kafka.streams.state.internals.OffsetCheckpoint(name)checkpoint-java.io.IOException(name)e</parameter><constant>Failed to write offset checkpoint file to {} for global stores: {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.GlobalStateManagerImpl.checkpoint</callsite><line>379</line><superclass>org.apache.kafka.streams.processor.internals.AbstractStateManager</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Closing all restoring stream tasks {}-java.util.Set<TaskId>(name)restoring.keySet()</parameter><constant>Closing all restoring stream tasks {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.closeAllRestoringTasks</callsite><line>70</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing restoring task {}-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Closing restoring task {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.closeAllRestoringTasks</callsite><line>74</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to remove restoring task {} due to the following error:-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)e</parameter><constant>Failed to remove restoring task {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.closeAllRestoringTasks</callsite><line>78</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Stream task changelog partitions that have completed restoring so far: {}-java.util.Collection<TopicPartition>(name)restored</parameter><constant>Stream task changelog partitions that have completed restoring so far: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.updateRestored</callsite><line>98</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Stream task {} completed restoration as all its changelog partitions {} have been applied to restore state-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.util.Collection<TopicPartition>(name)task.changelogPartitions()</parameter><constant>Stream task {} completed restoration as all its changelog partitions {} have been applied to restore state</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.updateRestored</callsite><line>106</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Stream task {} cannot resume processing yet since some of its changelog partitions have not completed restoring: {}-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.util.HashSet<TopicPartition>(name)outstandingPartitions</parameter><constant>Stream task {} cannot resume processing yet since some of its changelog partitions have not completed restoring: {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.updateRestored</callsite><line>113</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Committed active task {} per user request in-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Committed active task {} per user request in</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.maybeCommitPerUserRequested</callsite><line>148</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to commit {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to commit {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.maybeCommitPerUserRequested</callsite><line>151</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to commit StreamTask {} due to the following error:-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)t</parameter><constant>Failed to commit StreamTask {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.maybeCommitPerUserRequested</callsite><line>160</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to process stream task {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to process stream task {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process</callsite><line>203</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to process stream task {} due to the following error:-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)e</parameter><constant>Failed to process stream task {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.process</callsite><line>212</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to punctuate stream task {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to punctuate stream task {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.punctuate</callsite><line>236</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to punctuate stream task {} due to the following error:-org.apache.kafka.streams.processor.TaskId(name)task.id()-org.apache.kafka.common.KafkaException(name)e</parameter><constant>Failed to punctuate stream task {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedStreamsTasks.punctuate</callsite><line>245</line><superclass>org.apache.kafka.streams.processor.internals.AssignedTasks</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Downgrading metadata version from {} to 1 for upgrade from 0.10.0.x.-int(name)4</parameter><constant>Downgrading metadata version from {} to 1 for upgrade from 0.10.0.x.4</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>232</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Downgrading metadata version from {} to 2 for upgrade from {}.x.-int(name)4-java.lang.String(name)upgradeFrom</parameter><constant>Downgrading metadata version from {} to 2 for upgrade from {}.x.4</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>240</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)fatalException.getMessage()-org.apache.kafka.common.KafkaException(name)fatalException</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>251</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)fatalException.getMessage()-org.apache.kafka.common.KafkaException(name)fatalException</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>257</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)fatalException.getMessage()-org.apache.kafka.common.KafkaException(name)fatalException</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>266</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)fatalException.getMessage()-org.apache.kafka.common.KafkaException(name)fatalException</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.configure</callsite><line>273</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name){} is unknown yet during rebalance, please make sure they have been pre-created before starting the Streams application.-java.lang.String(name)topic</parameter><constant>{} is unknown yet during rebalance, please make sure they have been pre-created before starting the Streams application.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.errorAssignment</callsite><line>336</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Received a future (version probing) subscription (version: {}). Sending empty assignment back (with supported version {}).-int(name)futureMetadataVersion-int(name)4</parameter><constant>Received a future (version probing) subscription (version: {}). Sending empty assignment back (with supported version {}).4</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>415</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Downgrading metadata to version {}. Latest supported version is {}.-int(name)minReceivedMetadataVersion-int(name)4</parameter><constant>Downgrading metadata to version {}. Latest supported version is {}.4</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Constructed client metadata {} from the member subscriptions.-java.util.Map<UUID,ClientMetadata>(name)clientMetadataMap</parameter><constant>Constructed client metadata {} from the member subscriptions.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>433</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Missing source topic {} durign assignment. Returning error {}.-java.lang.String(name)topic-java.lang.String(name)Error.INCOMPLETE_SOURCE_TOPIC_METADATA.name()</parameter><constant>Missing source topic {} durign assignment. Returning error {}.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>447</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Created repartition topics {} from the parsed topology.-java.util.Collection<PartitionInfo>(name)allRepartitionTopicPartitions.values()</parameter><constant>Created repartition topics {} from the parsed topology.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>527</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Partition {} is assigned to more than one tasks: {}-org.apache.kafka.common.TopicPartition(name)partition-java.util.Map<TaskId,Set<TopicPartition>>(name)partitionsForTask</parameter><constant>Partition {} is assigned to more than one tasks: {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>548</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Partition {} is not assigned to any tasks: {} Possible causes of a partition not getting assigned is that another topic defined in the topology has not been created when starting your streams application, resulting in no tasks created for this topology at all.-org.apache.kafka.common.TopicPartition(name)partition-java.util.Map<TaskId,Set<TopicPartition>>(name)partitionsForTask</parameter><constant>Partition {} is not assigned to any tasks: {} Possible causes of a partition not getting assigned is that another topic defined in the topology has not been created when starting your streams application, resulting in no tasks created for this topology at all.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>562</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)No partitions found for topic {}-java.lang.String(name)topic</parameter><constant>No partitions found for topic {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>570</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)No tasks found for topic group {}-int(name)topicGroupId</parameter><constant>No tasks found for topic group {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>593</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Created state changelog topics {} from the parsed topology.-java.util.Collection<InternalTopicConfig>(name)changelogTopicMetadata.values()</parameter><constant>Created state changelog topics {} from the parsed topology.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>600</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Assigning tasks {} to clients {} with number of replicas {}-java.util.Set<TaskId>(name)partitionsForTask.keySet()-java.util.Map<UUID,ClientState>(name)states-int(name)numStandbyReplicas</parameter><constant>Assigning tasks {} to clients {} with number of replicas {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>610</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Assigned tasks to clients as {}.-java.util.Map<UUID,ClientState>(name)states</parameter><constant>Assigned tasks to clients as {}.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.assign</callsite><line>616</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Sent a version {} subscription and got version {} assignment back (successful version probing). Downgrading subscription metadata to received version and trigger new rebalance.-int(name)usedSubscriptionMetadataVersion-int(name)receivedAssignmentMetadataVersion</parameter><constant>Sent a version {} subscription and got version {} assignment back (successful version probing). Downgrading subscription metadata to received version and trigger new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.onAssignment</callsite><line>802</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Sent a version {} subscription and got version {} assignment back (successful version probing). Setting subscription metadata to leaders supported version {} and trigger new rebalance.-int(name)usedSubscriptionMetadataVersion-int(name)receivedAssignmentMetadataVersion-int(name)leaderSupportedVersion</parameter><constant>Sent a version {} subscription and got version {} assignment back (successful version probing). Setting subscription metadata to leaders supported version {} and trigger new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.onAssignment</callsite><line>808</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Sent a version {} subscription and group leader's latest supported version is {}. Upgrading subscription metadata version to {} for next rebalance.-int(name)usedSubscriptionMetadataVersion-int(name)leaderSupportedVersion-int(name)leaderSupportedVersion</parameter><constant>Sent a version {} subscription and group leader's latest supported version is {}. Upgrading subscription metadata version to {} for next rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.onAssignment</callsite><line>837</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Sent a version {} subscription and group leader's latest supported version is {}. Upgrading subscription metadata version to {} for next rebalance.-int(name)usedSubscriptionMetadataVersion-int(name)leaderSupportedVersion-int(name)leaderSupportedVersion</parameter><constant>Sent a version {} subscription and group leader's latest supported version is {}. Upgrading subscription metadata version to {} for next rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.onAssignment</callsite><line>849</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Starting to validate internal topics {} in partition assignor.-java.util.Map<String,InternalTopicConfig>(name)topicPartitions</parameter><constant>Starting to validate internal topics {} in partition assignor.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.prepareTopic</callsite><line>933</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Completed validating internal topics {} in partition assignor.-java.util.Map<String,InternalTopicConfig>(name)topicPartitions</parameter><constant>Completed validating internal topics {} in partition assignor.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.prepareTopic</callsite><line>952</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)str</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor.validate</callsite><line>983</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Initializing state stores</parameter><constant>Initializing state stores</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.initializeStateStores</callsite><line>238</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Resuming</parameter><constant>Resuming</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.resume</callsite><line>280</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Start processing one record [{}]-org.apache.kafka.streams.processor.internals.StampedRecord(name)record</parameter><constant>Start processing one record [{}]</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.process</callsite><line>345</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Completed processing one record [{}]-org.apache.kafka.streams.processor.internals.StampedRecord(name)record</parameter><constant>Completed processing one record [{}]</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.process</callsite><line>350</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Encountered error extracting stacktrace from this exception-java.io.IOException(name)ioe</parameter><constant>Encountered error extracting stacktrace from this exception</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.getStacktraceString</callsite><line>388</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Punctuating processor {} with timestamp {} and punctuation type {}-java.lang.String(name)node.name()-long(name)timestamp-org.apache.kafka.streams.processor.PunctuationType(name)type</parameter><constant>Punctuating processor {} with timestamp {} and punctuation type {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.punctuate</callsite><line>406</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Committing</parameter><constant>Committing</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.commit</callsite><line>453</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Flushing state and producer</parameter><constant>Flushing state and producer</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.flushState</callsite><line>502</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Initializing processor nodes of the topology</parameter><constant>Initializing processor nodes of the topology</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.initTopology</callsite><line>525</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Suspending</parameter><constant>Suspending</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.suspend</callsite><line>550</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close producer due to the following error:-java.lang.Throwable(name)e</parameter><constant>Failed to close producer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.maybeAbortTransactionAndCloseRecordCollector</callsite><line>626</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Closing processor topology</parameter><constant>Closing processor topology</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.closeTopology</callsite><line>634</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Could not close state manager due to the following error:-java.lang.RuntimeException(name)e</parameter><constant>Could not close state manager due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.closeSuspended</callsite><line>670</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing</parameter><constant>Closing</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.close</callsite><line>704</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Could not close task due to the following error:-java.lang.RuntimeException(name)e</parameter><constant>Could not close task due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.close</callsite><line>712</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Added records into the buffered queue of partition {}, new queue size is {}-org.apache.kafka.common.TopicPartition(name)partition-int(name)newQueueSize</parameter><constant>Added records into the buffered queue of partition {}, new queue size is {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.addRecords</callsite><line>731</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Timeout exception caught when initializing transactions for task {}. This might happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.-org.apache.kafka.streams.processor.TaskId(name)id-org.apache.kafka.common.errors.TimeoutException(name)retriable</parameter><constant>Timeout exception caught when initializing transactions for task {}. This might happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamTask.initializeTransactions</callsite><line>867</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Initializing {}s {}-java.lang.String(name)taskTypeName-java.util.Set<TaskId>(name)created.keySet()</parameter><constant>Initializing {}s {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.initializeNewTasks</callsite><line>67</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Transitioning {} {} to restoring-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)entry.getKey()</parameter><constant>Transitioning {} {} to restoring</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.initializeNewTasks</callsite><line>73</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Could not create {} {} due to {}; will retry-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)entry.getKey()-java.lang.String(name)e.toString()</parameter><constant>Could not create {} {} due to {}; will retry</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.initializeNewTasks</callsite><line>81</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Suspending running {} {}-java.lang.String(name)taskTypeName-java.util.Set<TaskId>(name)runningTaskIds()</parameter><constant>Suspending running {} {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.suspend</callsite><line>96</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Close created {} {}-java.lang.String(name)taskTypeName-java.util.Set<TaskId>(name)created.keySet()</parameter><constant>Close created {} {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.suspend</callsite><line>98</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close {}, {}-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)e</parameter><constant>Failed to close {}, {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeNonRunningTasks</callsite><line>114</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to suspend {} {} since it got migrated to another thread already. Closing it as zombie and move on.-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to suspend {} {} since it got migrated to another thread already. Closing it as zombie and move on.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.suspendTasks</callsite><line>132</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Suspending {} {} failed due to the following error:-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)e</parameter><constant>Suspending {} {} failed due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.suspendTasks</callsite><line>137</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)After suspending failed, closing the same {} {} failed again due to the following error:-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)f</parameter><constant>After suspending failed, closing the same {} {} failed again due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.suspendTasks</callsite><line>142</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to close zombie {} {} due to {}; ignore and proceed.-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.String(name)e.toString()</parameter><constant>Failed to close zombie {} {} due to {}; ignore and proceed.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeZombieTask</callsite><line>153</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Found suspended {} {}-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>Found suspended {} {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.maybeResumeSuspendedTask</callsite><line>169</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to resume {} {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to resume {} {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.maybeResumeSuspendedTask</callsite><line>178</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Resuming suspended {} {}-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Resuming suspended {} {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.maybeResumeSuspendedTask</callsite><line>187</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Couldn't resume task {} assigned partitions {}, task partitions {}-org.apache.kafka.streams.processor.TaskId(name)taskId-java.util.Set<TopicPartition>(name)partitions-java.util.Set<TopicPartition>(name)task.partitions()</parameter><constant>Couldn't resume task {} assigned partitions {}, task partitions {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.maybeResumeSuspendedTask</callsite><line>190</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Transitioning {} {} to running-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Transitioning {} {} to running</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.transitionToRunning</callsite><line>200</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to commit {} {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to commit {} {} since it got migrated to another thread already. Closing it as zombie before triggering a new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.commit</callsite><line>290</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to commit {} {} due to the following error:-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)t</parameter><constant>Failed to commit {} {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.commit</callsite><line>299</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing suspended and not re-assigned {} {}-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)suspendedTask.id()</parameter><constant>Closing suspended and not re-assigned {} {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeNonAssignedSuspendedTasks</callsite><line>321</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to remove suspended {} {} due to the following error:-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)suspendedTask.id()-java.lang.Exception(name)e</parameter><constant>Failed to remove suspended {} {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeNonAssignedSuspendedTasks</callsite><line>325</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Failed to close {} {} since it got migrated to another thread already. Closing it as zombie and move on.-java.lang.String(name)taskTypeName-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Failed to close {} {} since it got migrated to another thread already. Closing it as zombie and move on.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.close</callsite><line>339</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed while closing {} {} due to the following error:-java.lang.String(name)task.getClass().getSimpleName()-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)t</parameter><constant>Failed while closing {} {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.close</callsite><line>343</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Try to close {} {} unclean.-java.lang.String(name)task.getClass().getSimpleName()-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Try to close {} {} unclean.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeUnclean</callsite><line>366</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed while closing {} {} due to the following error:-java.lang.String(name)task.getClass().getSimpleName()-org.apache.kafka.streams.processor.TaskId(name)task.id()-java.lang.RuntimeException(name)fatalException</parameter><constant>Failed while closing {} {} due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AssignedTasks.closeUnclean</callsite><line>370</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Deserialization error callback failed after deserialization error for record {}-org.apache.kafka.clients.consumer.ConsumerRecord<byte[],byte[]>(name)rawRecord-java.lang.Exception(name)deserializationException</parameter><constant>Deserialization error callback failed after deserialization error for record {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.RecordDeserializer.deserialize</callsite><line>72</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record due to deserialization error. topic=[{}] partition=[{}] offset=[{}]-java.lang.String(name)rawRecord.topic()-int(name)rawRecord.partition()-long(name)rawRecord.offset()-java.lang.Exception(name)deserializationException</parameter><constant>Skipping record due to deserialization error. topic=[{}] partition=[{}] offset=[{}]</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.RecordDeserializer.deserialize</callsite><line>86</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to write offset checkpoint file to {} while re-initializing {}: {}-org.apache.kafka.streams.state.internals.OffsetCheckpoint(name)checkpoint-org.apache.kafka.common.utils.FixedOrderMap<String,Optional<StateStore>>(name)stateStores-java.io.IOException(name)fatalException</parameter><constant>Failed to write offset checkpoint file to {} while re-initializing {}: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AbstractStateManager.reinitializeStateStoresForPartitions</callsite><line>79</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to reinitialize store {}.-java.lang.String(name)storeName-java.io.IOException(name)fatalException</parameter><constant>Failed to reinitialize store {}.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AbstractStateManager.reinitializeStateStoresForPartitions</callsite><line>110</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to reinitialize store {}.-java.lang.String(name)storeName-java.io.IOException(name)fatalException</parameter><constant>Failed to reinitialize store {}.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.AbstractStateManager.reinitializeStateStoresForPartitions</callsite><line>117</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating store offset limits {} for changelog {}-long(name)offset-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Updating store offset limits {} for changelog {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AbstractTask.updateOffsetLimits</callsite><line>188</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Initializing state stores</parameter><constant>Initializing state stores</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AbstractTask.registerStateStores</callsite><line>226</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Initializing store {}-java.lang.String(name)store.name()</parameter><constant>Initializing store {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AbstractTask.registerStateStores</callsite><line>232</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Closing state manager</parameter><constant>Closing state manager</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.AbstractTask.closeStateManager</callsite><line>247</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Initializing state stores</parameter><constant>Initializing state stores</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.initializeStateStores</callsite><line>70</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Resuming</parameter><constant>Resuming</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.resume</callsite><line>90</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Committing</parameter><constant>Committing</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.commit</callsite><line>103</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Suspending</parameter><constant>Suspending</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.suspend</callsite><line>119</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing</parameter><constant>Closing</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.close</callsite><line>142</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Updating standby replicas of its state store for partition [{}]-org.apache.kafka.common.TopicPartition(name)partition</parameter><constant>Updating standby replicas of its state store for partition [{}]</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StandbyTask.update</callsite><line>168</line><superclass>org.apache.kafka.streams.processor.internals.AbstractTask</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name){} Found cached state dir lock for task {}-java.lang.String(name)logPrefix()-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>{} Found cached state dir lock for task {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.lock</callsite><line>141</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){} Acquired state dir lock for task {}-java.lang.String(name)logPrefix()-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>{} Acquired state dir lock for task {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.lock</callsite><line>171</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name){} Found cached state dir lock for the global task-java.lang.String(name)logPrefix()</parameter><constant>{} Found cached state dir lock for the global task</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.lockGlobalState</callsite><line>182</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){} Acquired global state dir lock-java.lang.String(name)logPrefix()</parameter><constant>{} Acquired global state dir lock</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.lockGlobalState</callsite><line>204</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){} Released global state dir lock-java.lang.String(name)logPrefix()</parameter><constant>{} Released global state dir lock</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.unlockGlobalState</callsite><line>218</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name){} Released state dir lock for task {}-java.lang.String(name)logPrefix()-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>{} Released state dir lock for task {}</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.unlock</callsite><line>229</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to delete global state directory due to an unexpected exception-java.lang.String(name)logPrefix()-java.io.IOException(name)e</parameter><constant>{} Failed to delete global state directory due to an unexpected exception</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.clean</callsite><line>250</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name){} Deleting obsolete state directory {} for task {} as {}ms has elapsed (cleanup delay is {}ms).-java.lang.String(name)logPrefix()-java.lang.String(name)dirName-org.apache.kafka.streams.processor.TaskId(name)id-long(name)now - lastModifiedMs-long(name)cleanupDelayMs</parameter><constant>{} Deleting obsolete state directory {} for task {} as {}ms has elapsed (cleanup delay is {}ms).</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.cleanRemovedTasks</callsite><line>287</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name){} Deleting state directory {} for task {} as user calling cleanup.-java.lang.String(name)logPrefix()-java.lang.String(name)dirName-org.apache.kafka.streams.processor.TaskId(name)id</parameter><constant>{} Deleting state directory {} for task {} as user calling cleanup.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.cleanRemovedTasks</callsite><line>295</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to get the state directory lock.-java.lang.String(name)logPrefix()-java.nio.channels.OverlappingFileLockException(name)e</parameter><constant>{} Failed to get the state directory lock.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.cleanRemovedTasks</callsite><line>307</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to delete the state directory.-java.lang.String(name)logPrefix()-java.io.IOException(name)e</parameter><constant>{} Failed to delete the state directory.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.cleanRemovedTasks</callsite><line>311</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name){} Failed to release the state directory lock.-java.lang.String(name)logPrefix()</parameter><constant>{} Failed to release the state directory lock.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StateDirectory.cleanRemovedTasks</callsite><line>319</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected state transition from {} to {}-org.apache.kafka.streams.processor.internals.State(name)oldState-org.apache.kafka.streams.processor.internals.State(name)newState</parameter><constant>Unexpected state transition from {} to {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.setState</callsite><line>205</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)State transition from {} to {}-org.apache.kafka.streams.processor.internals.State(name)oldState-org.apache.kafka.streams.processor.internals.State(name)newState</parameter><constant>State transition from {} to {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.setState</callsite><line>208</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)at state {}: partitions {} assigned at the end of consumer rebalance. 	current suspended active tasks: {} 	current suspended standby tasks: {} -org.apache.kafka.streams.processor.internals.State(name)streamThread.state-java.util.Collection<TopicPartition>(name)assignment-java.util.Set<TaskId>(name)taskManager.suspendedActiveTaskIds()-java.util.Set<TaskId>(name)taskManager.suspendedStandbyTaskIds()</parameter><constant>at state {}: partitions {} assigned at the end of consumer rebalance. 	current suspended active tasks: {} 	current suspended standby tasks: {} </constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsAssigned</callsite><line>255</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Received error code {} - shutdown-int(name)streamThread.assignmentErrorCode.get()</parameter><constant>Received error code {} - shutdown</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsAssigned</callsite><line>264</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Error caught during partition assignment, will abort the current process and re-throw at the end of rebalance: {}-java.lang.Throwable(name)t</parameter><constant>Error caught during partition assignment, will abort the current process and re-throw at the end of rebalance: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsAssigned</callsite><line>277</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)partition assignment took {} ms. 	current active tasks: {} 	current standby tasks: {} 	previous active tasks: {} -long(name)time.milliseconds() - start-java.util.Set<TaskId>(name)taskManager.activeTaskIds()-java.util.Set<TaskId>(name)taskManager.standbyTaskIds()-java.util.Set<TaskId>(name)taskManager.prevActiveTaskIds()</parameter><constant>partition assignment took {} ms. 	current active tasks: {} 	current standby tasks: {} 	previous active tasks: {} </constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsAssigned</callsite><line>284</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)at state {}: partitions {} revoked at the beginning of consumer rebalance. 	current assigned active tasks: {} 	current assigned standby tasks: {} -org.apache.kafka.streams.processor.internals.State(name)streamThread.state-java.util.Collection<TopicPartition>(name)assignment-java.util.Set<TaskId>(name)taskManager.activeTaskIds()-java.util.Set<TaskId>(name)taskManager.standbyTaskIds()</parameter><constant>at state {}: partitions {} revoked at the beginning of consumer rebalance. 	current assigned active tasks: {} 	current assigned standby tasks: {} </constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsRevoked</callsite><line>297</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Error caught during partition revocation, will abort the current process and re-throw at the end of rebalance: {}-java.lang.Throwable(name)t</parameter><constant>Error caught during partition revocation, will abort the current process and re-throw at the end of rebalance: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsRevoked</callsite><line>315</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)partition revocation took {} ms. 	suspended active tasks: {} 	suspended standby tasks: {}-long(name)time.milliseconds() - start-java.util.Set<TaskId>(name)taskManager.suspendedActiveTaskIds()-java.util.Set<TaskId>(name)taskManager.suspendedStandbyTaskIds()</parameter><constant>partition revocation took {} ms. 	suspended active tasks: {} 	suspended standby tasks: {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.onPartitionsRevoked</callsite><line>324</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Created task {} with assigned partitions {}-org.apache.kafka.streams.processor.TaskId(name)taskId-java.util.Set<TopicPartition>(name)partitions</parameter><constant>Created task {} with assigned partitions {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.createTasks</callsite><line>379</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Creating producer client for task {}-org.apache.kafka.streams.processor.TaskId(name)id</parameter><constant>Creating producer client for task {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.createProducer</callsite><line>449</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close producer due to the following error:-java.lang.Throwable(name)e</parameter><constant>Failed to close producer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.close</callsite><line>463</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Skipped standby task {} with assigned partitions {} since it does not have any state stores to materialize-org.apache.kafka.streams.processor.TaskId(name)taskId-java.util.Set<TopicPartition>(name)partitions</parameter><constant>Skipped standby task {} with assigned partitions {} since it does not have any state stores to materialize</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.createTask</callsite><line>509</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Creating restore consumer client</parameter><constant>Creating restore consumer client</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.create</callsite><line>573</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Creating shared producer client</parameter><constant>Creating shared producer client</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.create</callsite><line>583</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Creating consumer client</parameter><constant>Creating consumer client</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.create</callsite><line>623</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Starting</parameter><constant>Starting</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.run</callsite><line>743</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)StreamThread already shutdown. Not running</parameter><constant>StreamThread already shutdown. Not running</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.run</callsite><line>745</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Encountered the following unexpected Kafka exception during processing, this usually indicate Streams internal errors:-org.apache.kafka.common.KafkaException(name)e</parameter><constant>Encountered the following unexpected Kafka exception during processing, this usually indicate Streams internal errors:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.run</callsite><line>753</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Encountered the following error during processing:-java.lang.Exception(name)e</parameter><constant>Encountered the following error during processing:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.run</callsite><line>759</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Version probing detected. Triggering new rebalance.</parameter><constant>Version probing detected. Triggering new rebalance.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.runLoop</callsite><line>783</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Detected task {} that got migrated to another thread. This implies that this thread missed a rebalance and dropped out of the consumer group. Will try to rejoin the consumer group. Below is the detailed description of the task: {}-org.apache.kafka.streams.processor.TaskId(name)ignoreAndRejoinGroup.migratedTask().id()-java.lang.String(name)ignoreAndRejoinGroup.migratedTask().toString(">")</parameter><constant>Detected task {} that got migrated to another thread. This implies that this thread missed a rebalance and dropped out of the consumer group. Will try to rejoin the consumer group. Below is the detailed description of the task: {}</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.runLoop</callsite><line>787</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected state {} during normal iteration-org.apache.kafka.streams.processor.internals.State(name)state</parameter><constant>Unexpected state {} during normal iteration</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.runOnce</callsite><line>829</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)logMessage-java.lang.String(name)topic-java.lang.String(name)resetPolicy</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.addToResetList</callsite><line>971</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unable to locate active task for received-record partition {}. Current tasks: {}-org.apache.kafka.common.TopicPartition(name)partition-java.lang.String(name)taskManager.toString(">")</parameter><constant>Unable to locate active task for received-record partition {}. Current tasks: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.addRecordsToTasks</callsite><line>987</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Stream task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Stream task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.addRecordsToTasks</callsite><line>994</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)-java.util.Set<TaskId>(name)taskManager.activeTaskIds()-java.util.Set<TaskId>(name)taskManager.standbyTaskIds()-long(name)now - lastCommitMs-long(name)commitTimeMs</parameter><constant>Committing all active tasks {} and standby tasks {} since {}ms has elapsed (commit interval is {}ms)</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeCommit</callsite><line>1029</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Committed all active tasks {} and standby tasks {} in {}ms-java.util.Set<TaskId>(name)taskManager.activeTaskIds()-java.util.Set<TaskId>(name)taskManager.standbyTaskIds()-long(name)intervalCommitLatency</parameter><constant>Committed all active tasks {} and standby tasks {} in {}ms</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeCommit</callsite><line>1042</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1074</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Updated standby tasks {} in {}ms-java.util.Set<TaskId>(name)taskManager.standbyTaskIds()-long(name)time.milliseconds() - now</parameter><constant>Updated standby tasks {} in {}ms</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1091</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1113</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Updating StandbyTasks failed. Deleting StandbyTasks stores to recreate from scratch.-org.apache.kafka.clients.consumer.InvalidOffsetException(name)recoverableException</parameter><constant>Updating StandbyTasks failed. Deleting StandbyTasks stores to recreate from scratch.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1126</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.-org.apache.kafka.streams.processor.TaskId(name)task.id()</parameter><constant>Standby task {} is already closed, probably because it got unexpectedly migrated to another thread already. Notifying the thread to trigger a new rebalance immediately.</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1132</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Reinitializing StandbyTask {} from changelogs {}-org.apache.kafka.streams.processor.internals.StandbyTask(name)task-java.util.Set<TopicPartition>(name)recoverableException.partitions()</parameter><constant>Reinitializing StandbyTask {} from changelogs {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.maybeUpdateStandbyTasks</callsite><line>1137</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Informed to shut down</parameter><constant>Informed to shut down</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.shutdown</callsite><line>1168</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Shutting down</parameter><constant>Shutting down</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown</callsite><line>1182</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close task manager due to the following error:-java.lang.Throwable(name)e</parameter><constant>Failed to close task manager due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown</callsite><line>1187</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close consumer due to the following error:-java.lang.Throwable(name)e</parameter><constant>Failed to close consumer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown</callsite><line>1192</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Failed to close restore consumer due to the following error:-java.lang.Throwable(name)e</parameter><constant>Failed to close restore consumer due to the following error:</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown</callsite><line>1197</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Shutdown complete</parameter><constant>Shutdown complete</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.StreamThread.completeShutdown</callsite><line>1202</line><superclass>java.lang.Thread</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)errorLogMessage-java.lang.String(name)topic-java.lang.String(name)exception.getMessage()-java.lang.Exception(name)exception</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError</callsite><line>136</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Failed message: key {} value {} timestamp {}-K(name)key-V(name)value-java.lang.Long(name)timestamp</parameter><constant>Failed message: key {} value {} timestamp {}</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.recordSendError</callsite><line>139</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error sending record to topic {} due to {}; No more records will be sent and no more offsets will be recorded for this task. Enable TRACE logging to view failed record key and value.-java.lang.String(name)topic-java.lang.String(name)exception.getMessage()-java.lang.Exception(name)exception</parameter><constant>Error sending record to topic {} due to {}; No more records will be sent and no more offsets will be recorded for this task. Enable TRACE logging to view failed record key and value.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send</callsite><line>182</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Failed message: (key {} value {} timestamp {}) topic=[{}] partition=[{}]-K(name)key-V(name)value-java.lang.Long(name)timestamp-java.lang.String(name)topic-java.lang.Integer(name)partition</parameter><constant>Failed message: (key {} value {} timestamp {}) topic=[{}] partition=[{}]</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send</callsite><line>185</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Error sending records topic=[{}] and partition=[{}]; The exception handler chose to CONTINUE processing in spite of this error. Enable TRACE logging to view failed messages key and value.-java.lang.String(name)topic-java.lang.Integer(name)partition-java.lang.Exception(name)exception</parameter><constant>Error sending records topic=[{}] and partition=[{}]; The exception handler chose to CONTINUE processing in spite of this error. Enable TRACE logging to view failed messages key and value.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send</callsite><line>203</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Failed message: (key {} value {} timestamp {}) topic=[{}] partition=[{}]-K(name)key-V(name)value-java.lang.Long(name)timestamp-java.lang.String(name)topic-java.lang.Integer(name)partition</parameter><constant>Failed message: (key {} value {} timestamp {}) topic=[{}] partition=[{}]</constant><level>trace</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send</callsite><line>211</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Timeout exception caught when sending record to topic {}. This might happen if the producer cannot send data to the Kafka cluster and thus, its internal buffer fills up. This can also happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.-java.lang.String(name)topic-org.apache.kafka.common.errors.TimeoutException(name)e</parameter><constant>Timeout exception caught when sending record to topic {}. This might happen if the producer cannot send data to the Kafka cluster and thus, its internal buffer fills up. This can also happen if the broker is slow to respond, if the network connection to the broker was interrupted, or if similar circumstances arise. You can increase producer parameter `max.block.ms` to increase this timeout.</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.send</callsite><line>221</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Flushing producer</parameter><constant>Flushing producer</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.flush</callsite><line>265</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Closing producer</parameter><constant>Closing producer</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.RecordCollectorImpl.close</callsite><line>272</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)"Configs:" + Utils.NL-java.lang.String(name)"\t{} = {}" + Utils.NL-java.lang.String(name)"\t{} = {}" + Utils.NL-java.lang.String(name)	{} = {}-java.lang.String(name)retries-int(name)retries-java.lang.String(name)replication.factor-short(name)replicationFactor-java.lang.String(name)windowstore.changelog.additional.retention.ms-long(name)windowChangeLogAdditionalRetention</parameter><constant>	{} = {}retriesreplication.factorwindowstore.changelog.additional.retention.ms</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.InternalTopicManager</callsite><line>74</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Going to create topic {} with {} partitions and config {}.-java.lang.String(name)internalTopicConfig.name()-int(name)internalTopicConfig.numberOfPartitions()-java.util.Map<String,String>(name)topicConfig</parameter><constant>Going to create topic {} with {} partitions and config {}.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>113</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).-java.lang.InterruptedException(name)fatalException</parameter><constant>Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>136</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Could not create topic {}. Topic is probably marked for deletion (number of partitions is unknown). Will retry to create this topic in {} ms (to let broker finish async delete operation first). Error message was: {}-java.lang.String(name)topicName-long(name)retryBackOffMs-java.lang.String(name)cause.toString()</parameter><constant>Could not create topic {}. Topic is probably marked for deletion (number of partitions is unknown). Will retry to create this topic in {} ms (to let broker finish async delete operation first). Error message was: {}</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>142</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during topic creation for {}. Error message was: {}-java.lang.String(name)topicName-java.lang.String(name)cause.toString()</parameter><constant>Unexpected error during topic creation for {}. Error message was: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>146</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.info</logcall> <parameter>java.lang.String(name)Topics {} can not be made ready with {} retries left-java.util.Set<String>(name)topicsNotReady-int(name)retries</parameter><constant>Topics {} can not be made ready with {} retries left</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>156</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)timeoutAndRetryError</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.makeReady</callsite><line>168</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Trying to check if topics {} have been created with expected number of partitions.-java.util.Set<String>(name)topics</parameter><constant>Trying to check if topics {} have been created with expected number of partitions.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.getNumPartitions</callsite><line>180</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).-java.lang.InterruptedException(name)fatalException</parameter><constant>Thread got interrupted. This indicates a bug. Please report at https://issues.apache.org/jira/projects/KAFKA or dev-mailing list (https://kafka.apache.org/contact).</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.getNumPartitions</callsite><line>196</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Topic {} is unknown or not found, hence not existed yet.-java.lang.String(name)topicName</parameter><constant>Topic {} is unknown or not found, hence not existed yet.</constant><level>debug</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.getNumPartitions</callsite><line>203</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)Unexpected error during topic description for {}. Error message was: {}-java.lang.String(name)topicName-java.lang.String(name)cause.toString()</parameter><constant>Unexpected error during topic description for {}. Error message was: {}</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.getNumPartitions</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.Logger.error</logcall> <parameter>java.lang.String(name)errorMsg</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.InternalTopicManager.validateTopics</callsite><line>233</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.assignment.Logger.error</logcall> <parameter>java.lang.String(name)fatalException.getMessage()-org.apache.kafka.streams.errors.TaskAssignmentException(name)fatalException</parameter><constant>$$$Empty Message$$$</constant><level>error</level><callsite>org.apache.kafka.streams.processor.internals.assignment.AssignmentInfo.decode</callsite><line>260</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.assignment.Logger.warn</logcall> <parameter>java.lang.String(name)Unable to assign {} of {} standby tasks for task [{}]. There is not enough available capacity. You should increase the number of threads and/or application instances to maintain the requested number of standby replicas.-int(name)numStandbyReplicas - i-int(name)numStandbyReplicas-org.apache.kafka.streams.processor.TaskId(name)taskId</parameter><constant>Unable to assign {} of {} standby tasks for task [{}]. There is not enough available capacity. You should increase the number of threads and/or application instances to maintain the requested number of standby replicas.</constant><level>warn</level><callsite>org.apache.kafka.streams.processor.internals.assignment.StickyTaskAssignor.assignStandby</callsite><line>61</line><superclass>null</superclass><logcall>org.apache.kafka.streams.processor.internals.assignment.Logger.info</logcall> <parameter>java.lang.String(name)Unable to decode subscription data: used version: {}; latest supported version: {}-int(name)usedVersion-int(name)4</parameter><constant>Unable to decode subscription data: used version: {}; latest supported version: {}4</constant><level>info</level><callsite>org.apache.kafka.streams.processor.internals.assignment.SubscriptionInfo.decode</callsite><line>276</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.Logger.warn</logcall> <parameter>java.lang.String(name)The default close will be removed in 3.0.0 -- you should overwrite it if you have implemented RocksDBConfigSetter</parameter><constant>The default close will be removed in 3.0.0 -- you should overwrite it if you have implemented RocksDBConfigSetter</constant><level>warn</level><callsite>org.apache.kafka.streams.state.RocksDBConfigSetter.close</callsite><line>61</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.MemoryNavigableLRUCache.range</callsite><line>41</line><superclass>org.apache.kafka.streams.state.internals.MemoryLRUCache</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.CachingKeyValueStore.range</callsite><line>236</line><superclass>org.apache.kafka.streams.state.internals.WrappedStateStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.AbstractRocksDBSegmentedBytesStore.fetch</callsite><line>90</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping record for expired segment.</parameter><constant>Skipping record for expired segment.</constant><level>debug</level><callsite>org.apache.kafka.streams.state.internals.AbstractRocksDBSegmentedBytesStore.put</callsite><line>151</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Warning: window end time was truncated to Long.MAX</parameter><constant>Warning: window end time was truncated to Long.MAX</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.WindowKeySchema.timeWindowForSize</callsite><line>109</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.info</logcall> <parameter>java.lang.String(name)Opening store {} in upgrade mode-java.lang.String(name)name</parameter><constant>Opening store {} in upgrade mode</constant><level>info</level><callsite>org.apache.kafka.streams.state.internals.RocksDBTimestampedStore.openRocksDB</callsite><line>79</line><superclass>org.apache.kafka.streams.state.internals.RocksDBStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.info</logcall> <parameter>java.lang.String(name)Opening store {} in regular mode-java.lang.String(name)name</parameter><constant>Opening store {} in regular mode</constant><level>info</level><callsite>org.apache.kafka.streams.state.internals.RocksDBTimestampedStore.openRocksDB</callsite><line>82</line><superclass>org.apache.kafka.streams.state.internals.RocksDBStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.info</logcall> <parameter>java.lang.String(name)Opening store {} in upgrade mode-java.lang.String(name)name</parameter><constant>Opening store {} in upgrade mode</constant><level>info</level><callsite>org.apache.kafka.streams.state.internals.RocksDBTimestampedStore.openRocksDB</callsite><line>95</line><superclass>org.apache.kafka.streams.state.internals.RocksDBStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Cache stats on flush: #puts={}, #gets={}, #evicts={}, #flushes={}-long(name)puts()-long(name)gets()-long(name)evicts()-long(name)flushes()</parameter><constant>Cache stats on flush: #puts={}, #gets={}, #evicts={}, #flushes={}</constant><level>trace</level><callsite>org.apache.kafka.streams.state.internals.ThreadCache.flush</callsite><line>128</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Evicted {} entries from cache {}-int(name)numEvicted-java.lang.String(name)namespace</parameter><constant>Evicted {} entries from cache {}</constant><level>trace</level><callsite>org.apache.kafka.streams.state.internals.ThreadCache.maybeEvict</callsite><line>246</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.error</logcall> <parameter>java.lang.String(name)Error destroying {}-S(name)segment-java.io.IOException(name)e</parameter><constant>Error destroying {}</constant><level>error</level><callsite>org.apache.kafka.streams.state.internals.AbstractSegments.cleanupEarlierThan</callsite><line>179</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Unable to parse segmentName {} to a date. This segment will be skipped-java.lang.String(name)segmentName</parameter><constant>Unable to parse segmentName {} to a date. This segment will be skipped</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.AbstractSegments.segmentIdFromSegmentName</callsite><line>196</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.CachingSessionStore.findSessions</callsite><line>173</line><superclass>org.apache.kafka.streams.state.internals.WrappedStateStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.trace</logcall> <parameter>java.lang.String(name)Named cache {} stats on flush: #hits={}, #misses={}, #overwrites={}, #flushes={}-java.lang.String(name)name-long(name)hits()-long(name)misses()-long(name)overwrites()-long(name)flushes()</parameter><constant>Named cache {} stats on flush: #hits={}, #misses={}, #overwrites={}, #flushes={}</constant><level>trace</level><callsite>org.apache.kafka.streams.state.internals.NamedCache.flush</callsite><line>106</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.CachingWindowStore.fetch</callsite><line>216</line><superclass>org.apache.kafka.streams.state.internals.WrappedStateStore</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Skipping record for expired segment.</parameter><constant>Skipping record for expired segment.</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemoryWindowStore.put</callsite><line>131</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemoryWindowStore.fetch</callsite><line>198</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Closing {} open iterators for store {}-int(name)openIterators.size()-java.lang.String(name)name</parameter><constant>Closing {} open iterators for store {}</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemoryWindowStore.close</callsite><line>259</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Warning: window end time was truncated to Long.MAX</parameter><constant>Warning: window end time was truncated to Long.MAX</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemoryWindowStore.getWindowedKey</callsite><line>497</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.debug</logcall> <parameter>java.lang.String(name)Skipping record for expired segment.</parameter><constant>Skipping record for expired segment.</constant><level>debug</level><callsite>org.apache.kafka.streams.state.internals.InMemorySessionStore.put</callsite><line>107</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemorySessionStore.findSessions</callsite><line>180</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Closing {} open iterators for store {}-int(name)openIterators.size()-java.lang.String(name)name</parameter><constant>Closing {} open iterators for store {}</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemorySessionStore.close</callsite><line>232</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.InMemoryKeyValueStore.range</callsite><line>118</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</parameter><constant>Returning empty iterator for fetch with invalid key range: from > to. This may be due to serdes that don't preserve ordering when lexicographically comparing the serialized bytes. Note that the built-in numerical serdes do not follow this for negative numbers</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.RocksDBStore.range</callsite><line>298</line><superclass>null</superclass><logcall>org.apache.kafka.streams.state.internals.Logger.warn</logcall> <parameter>java.lang.String(name)Closing {} open iterators for store {}-int(name)iterators.size()-java.lang.String(name)name</parameter><constant>Closing {} open iterators for store {}</constant><level>warn</level><callsite>org.apache.kafka.streams.state.internals.RocksDBStore.closeOpenIterators</callsite><line>428</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Initiating embedded Kafka cluster startup</parameter><constant>Initiating embedded Kafka cluster startup</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.start</callsite><line>85</line><superclass>org.apache.kafka.streams.integration.utils.ExternalResource</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Starting a ZooKeeper instance</parameter><constant>Starting a ZooKeeper instance</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.start</callsite><line>86</line><superclass>org.apache.kafka.streams.integration.utils.ExternalResource</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)ZooKeeper instance is running at {}-java.lang.String(name)zKConnectString()</parameter><constant>ZooKeeper instance is running at {}</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.start</callsite><line>88</line><superclass>org.apache.kafka.streams.integration.utils.ExternalResource</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Kafka instance is running at {}, connected to ZooKeeper at {}-java.lang.String(name)brokers[i].brokerList()-java.lang.String(name)brokers[i].zookeeperConnect()</parameter><constant>Kafka instance is running at {}, connected to ZooKeeper at {}</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.EmbeddedKafkaCluster.start</callsite><line>104</line><superclass>org.apache.kafka.streams.integration.utils.ExternalResource</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Starting embedded Kafka broker (with log.dirs={} and ZK ensemble at {}) ...-java.io.File(name)logDir-java.lang.String(name)zookeeperConnect()</parameter><constant>Starting embedded Kafka broker (with log.dirs={} and ZK ensemble at {}) ...</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.KafkaEmbedded</callsite><line>76</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Startup of embedded Kafka broker at {} completed (with ZK ensemble at {}) ...-java.lang.String(name)brokerList()-java.lang.String(name)zookeeperConnect()</parameter><constant>Startup of embedded Kafka broker at {} completed (with ZK ensemble at {}) ...</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.KafkaEmbedded</callsite><line>79</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Shutting down embedded Kafka broker at {} (with ZK ensemble at {}) ...-java.lang.String(name)brokerList()-java.lang.String(name)zookeeperConnect()</parameter><constant>Shutting down embedded Kafka broker at {} (with ZK ensemble at {}) ...</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.stop</callsite><line>131</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Removing log dir at {} ...-java.io.File(name)logDir</parameter><constant>Removing log dir at {} ...</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.stop</callsite><line>135</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Shutdown of embedded Kafka broker at {} completed (with ZK ensemble at {}) ...-java.lang.String(name)brokerList()-java.lang.String(name)zookeeperConnect()</parameter><constant>Shutdown of embedded Kafka broker at {} completed (with ZK ensemble at {}) ...</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.stop</callsite><line>142</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Creating topic { name: {}, partitions: {}, replication: {}, config: {} }-java.lang.String(name)topic-int(name)partitions-int(name)replication-java.util.Map<String,String>(name)topicConfig</parameter><constant>Creating topic { name: {}, partitions: {}, replication: {}, config: {} }</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.createTopic</callsite><line>178</line><superclass>null</superclass><logcall>org.apache.kafka.streams.integration.utils.Logger.debug</logcall> <parameter>java.lang.String(name)Deleting topic { name: {} }-java.lang.String(name)topic</parameter><constant>Deleting topic { name: {} }</constant><level>debug</level><callsite>org.apache.kafka.streams.integration.utils.KafkaEmbedded.deleteTopic</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.log4j.Logger.info</logcall> <parameter>java.lang.String(name)msg</parameter><constant>$$$Empty Message$$$</constant><level>info</level><callsite>org.apache.kafka.tools.VerifiableLog4jAppender.append</callsite><line>259</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.info</logcall> <parameter>java.lang.String(name)Configured PushHttpMetricsReporter for {} to report every {} seconds-java.net.URL(name)url-int(name)period</parameter><constant>Configured PushHttpMetricsReporter for {} to report every {} seconds</constant><level>info</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.configure</callsite><line>129</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Adding metric {}-org.apache.kafka.common.MetricName(name)metric.metricName()</parameter><constant>Adding metric {}</constant><level>debug</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.init</callsite><line>136</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Updating metric {}-org.apache.kafka.common.MetricName(name)metric.metricName()</parameter><constant>Updating metric {}</constant><level>debug</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.metricChange</callsite><line>145</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.debug</logcall> <parameter>java.lang.String(name)Removing metric {}-org.apache.kafka.common.MetricName(name)metric.metricName()</parameter><constant>Removing metric {}</constant><level>debug</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.metricRemoval</callsite><line>153</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.trace</logcall> <parameter>java.lang.String(name)Reporting {} metrics to {}-int(name)samples.size()-java.net.URL(name)url</parameter><constant>Reporting {} metrics to {}</constant><level>trace</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.run</callsite><line>183</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.error</logcall> <parameter>java.lang.String(name)Error reporting metrics, {}: {}-int(name)responseCode-java.lang.String(name)msg</parameter><constant>Error reporting metrics, {}: {}</constant><level>error</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.run</callsite><line>208</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.error</logcall> <parameter>java.lang.String(name)PushHttpMetricsReporter does not currently support redirects, saw {}-int(name)responseCode</parameter><constant>PushHttpMetricsReporter does not currently support redirects, saw {}</constant><level>error</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.run</callsite><line>210</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.info</logcall> <parameter>java.lang.String(name)Finished reporting metrics with response code {}-int(name)responseCode</parameter><constant>Finished reporting metrics with response code {}</constant><level>info</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.run</callsite><line>212</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.error</logcall> <parameter>java.lang.String(name)Error reporting metrics-java.lang.Throwable(name)t</parameter><constant>Error reporting metrics</constant><level>error</level><callsite>org.apache.kafka.tools.PushHttpMetricsReporter.run</callsite><line>215</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.trace</logcall> <parameter>java.lang.String(name)Caught WakeupException because consumer is shutdown, ignore and terminate.-org.apache.kafka.common.errors.WakeupException(name)e</parameter><constant>Caught WakeupException because consumer is shutdown, ignore and terminate.</constant><level>trace</level><callsite>org.apache.kafka.tools.VerifiableConsumer.run</callsite><line>243</line><superclass>null</superclass><logcall>org.apache.kafka.tools.Logger.error</logcall> <parameter>java.lang.String(name)Error during processing, terminating consumer process: -java.lang.Throwable(name)t</parameter><constant>Error during processing, terminating consumer process: </constant><level>error</level><callsite>org.apache.kafka.tools.VerifiableConsumer.run</callsite><line>246</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name)Starting agent process.</parameter><constant>Starting agent process.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.Agent.main</callsite><line>249</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Ignoring request to create worker {}, because there is already a worker with that id.-java.lang.String(name)nodeName-long(name)workerId</parameter><constant>{}: Ignoring request to create worker {}, because there is already a worker with that id.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.createWorker</callsite><line>323</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Will not run worker {} as it has expired.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Will not run worker {} as it has expired.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.createWorker</callsite><line>329</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Worker {} start() exception-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.Exception(name)e</parameter><constant>{}: Worker {} start() exception</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.createWorker</callsite><line>351</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: request conflict while creating worker {} for task {} with spec {}.-java.lang.String(name)nodeName-long(name)workerId-java.lang.String(name)taskId-org.apache.kafka.trogdor.task.TaskSpec(name)spec</parameter><constant>{}: request conflict while creating worker {} for task {} with spec {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.createWorker</callsite><line>359</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Error creating worker {} for task {} with spec {}-java.lang.String(name)nodeName-long(name)workerId-java.lang.String(name)taskId-org.apache.kafka.trogdor.task.TaskSpec(name)spec-java.util.concurrent.ExecutionException(name)e</parameter><constant>{}: Error creating worker {} for task {} with spec {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.createWorker</callsite><line>362</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Created worker {} with spec {}-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-org.apache.kafka.trogdor.task.TaskSpec(name)spec</parameter><constant>{}: Created worker {} with spec {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>402</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: unable to create worker {} for task {}, with spec {}-java.lang.String(name)nodeName-long(name)workerId-java.lang.String(name)taskId-org.apache.kafka.trogdor.task.TaskSpec(name)spec-java.lang.Exception(name)e</parameter><constant>{}: unable to create worker {} for task {}, with spec {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>405</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Worker {} was cancelled while it was starting up.  Transitioning to STOPPING.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Worker {} was cancelled while it was starting up.  Transitioning to STOPPING.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>426</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Worker {} is now RUNNING.  Scheduled to stop in {} ms.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-long(name)worker.spec.durationMs()</parameter><constant>{}: Worker {} is now RUNNING.  Scheduled to stop in {} ms.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>431</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Worker {} {} during startup.  Transitioning to DONE.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)verb</parameter><constant>{}: Worker {} {} during startup.  Transitioning to DONE.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>466</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Worker {} {} during startup.  Transitioning to CANCELLING.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)verb</parameter><constant>{}: Worker {} {} during startup.  Transitioning to CANCELLING.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>470</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Cancelling worker {} {}.  -java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)verb</parameter><constant>{}: Cancelling worker {} {}.  </constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>476</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Running worker {} {}.  Transitioning to STOPPING.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)verb</parameter><constant>{}: Running worker {} {}.  Transitioning to STOPPING.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>480</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Stopping worker {} {}.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)verb</parameter><constant>{}: Stopping worker {} {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>485</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Can't halt worker {} because it is already DONE.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Can't halt worker {} because it is already DONE.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>488</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: destroying worker {} with error {}-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)worker.error</parameter><constant>{}: destroying worker {} with error {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>516</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: completed worker {} with error {}-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)worker.error</parameter><constant>{}: completed worker {} with error {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>520</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Can't stop worker {} because there is no worker with that ID.-java.lang.String(name)nodeName-long(name)workerId</parameter><constant>{}: Can't stop worker {} because there is no worker with that ID.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>551</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Cancelling worker {} during its startup process.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Cancelling worker {} during its startup process.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>560</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Can't stop worker {}, because it is already being cancelled.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Can't stop worker {}, because it is already being cancelled.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>565</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Stopping running worker {}.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Stopping running worker {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>569</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Can't stop worker {}, because it is already stopping.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Can't stop worker {}, because it is already stopping.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>573</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: destroying worker {} with error {}-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker-java.lang.String(name)worker.error</parameter><constant>{}: destroying worker {} with error {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>578</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.debug</logcall> <parameter>java.lang.String(name){}: Can't stop worker {}, because it is already done.-java.lang.String(name)nodeName-org.apache.kafka.trogdor.agent.Worker(name)worker</parameter><constant>{}: Can't stop worker {}, because it is already done.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>582</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.error</logcall> <parameter>java.lang.String(name){}: worker.stop() exception-java.lang.String(name)nodeName-java.lang.Exception(name)exception</parameter><constant>{}: worker.stop() exception</constant><level>error</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>608</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Shutting down WorkerManager.-java.lang.String(name)nodeName</parameter><constant>{}: Shutting down WorkerManager.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>648</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Waiting for shutdownManager quiescence...-java.lang.String(name)nodeName</parameter><constant>{}: Waiting for shutdownManager quiescence...</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>651</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Waiting for workerCleanupExecutor to terminate...-java.lang.String(name)nodeName</parameter><constant>{}: Waiting for workerCleanupExecutor to terminate...</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>655</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Waiting for stateChangeExecutor to terminate...-java.lang.String(name)nodeName</parameter><constant>{}: Waiting for stateChangeExecutor to terminate...</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>657</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Shutting down shutdownExecutor.-java.lang.String(name)nodeName</parameter><constant>{}: Shutting down shutdownExecutor.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>659</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Caught exception while shutting down WorkerManager-java.lang.String(name)nodeName-java.lang.Exception(name)e</parameter><constant>{}: Caught exception while shutting down WorkerManager</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>662</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.info</logcall> <parameter>java.lang.String(name){}: Destroying all workers.-java.lang.String(name)nodeName</parameter><constant>{}: Destroying all workers.</constant><level>info</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>675</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.agent.Logger.error</logcall> <parameter>java.lang.String(name)Failed to stop worker {}-long(name)workerId-java.lang.Exception(name)e</parameter><constant>Failed to stop worker {}</constant><level>error</level><callsite>org.apache.kafka.trogdor.agent.WorkerManager.call</callsite><line>690</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.basic.Logger.info</logcall> <parameter>java.lang.String(name)RUN: {}. RESULT: [{}]-java.lang.String(name)Utils.join(command," ")-java.lang.String(name)result</parameter><constant>RUN: {}. RESULT: [{}]</constant><level>info</level><callsite>org.apache.kafka.trogdor.basic.BasicPlatform.run</callsite><line>52</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.basic.Logger.info</logcall> <parameter>java.lang.String(name)RUN: {}. ERROR: [{}]-java.lang.String(name)Utils.join(command," ")-java.lang.String(name)e.getMessage()</parameter><constant>RUN: {}. ERROR: [{}]</constant><level>info</level><callsite>org.apache.kafka.trogdor.basic.BasicPlatform.run</callsite><line>55</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name){} caught an exception-java.lang.String(name)what-java.lang.Throwable(name)exception</parameter><constant>{} caught an exception</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.abort</callsite><line>66</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to create or verify topics {}-java.util.Map<String,NewTopic>(name)topics-java.lang.Exception(name)e</parameter><constant>Failed to create or verify topics {}</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>138</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)Request to create topics has an empty topic list.</parameter><constant>Request to create topics has an empty topic list.</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>154</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)Topic(s) {} already exist.-java.util.Collection<String>(name)topicsExists</parameter><constant>Topic(s) {} already exist.</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>161</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.info</logcall> <parameter>java.lang.String(name)Attempting to create {} topics (try {})...-int(name)topicsToCreate.size()-int(name)++tries</parameter><constant>Attempting to create {} topics (try {})...</constant><level>info</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>189</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.debug</logcall> <parameter>java.lang.String(name)Successfully created {}.-java.lang.String(name)topicName</parameter><constant>Successfully created {}.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>207</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)Attempt to create topic `{}` failed: {}-java.lang.String(name)topicName-java.lang.String(name)e.getCause().getMessage()</parameter><constant>Attempt to create topic `{}` failed: {}</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>211</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.info</logcall> <parameter>java.lang.String(name)Topic {} already exists.-java.lang.String(name)topicName</parameter><constant>Topic {} already exists.</constant><level>info</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>215</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)Failed to create {}-java.lang.String(name)topicName-java.lang.Throwable(name)e.getCause()</parameter><constant>Failed to create {}</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>218</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)str</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.createTopics</callsite><line>229</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.warn</logcall> <parameter>java.lang.String(name)str</parameter><constant>$$$Empty Message$$$</constant><level>warn</level><callsite>org.apache.kafka.trogdor.common.WorkerUtils.verifyTopics</callsite><line>266</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: error creating worker {}.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)this-java.lang.Throwable(name)e</parameter><constant>{}: error creating worker {}.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.tryCreate</callsite><line>103</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: error stopping worker {}.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)this-java.lang.Throwable(name)e</parameter><constant>{}: error stopping worker {}.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.tryStop</callsite><line>111</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: failed to get agent status: ConnectException {}-java.lang.String(name)node.name()-java.lang.String(name)e.getMessage()</parameter><constant>{}: failed to get agent status: ConnectException {}</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.run</callsite><line>196</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: failed to get agent status-java.lang.String(name)node.name()-java.lang.Exception(name)e</parameter><constant>{}: failed to get agent status</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.run</callsite><line>199</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.trace</logcall> <parameter>java.lang.String(name){}: got heartbeat status {}-java.lang.String(name)node.name()-org.apache.kafka.trogdor.rest.AgentStatusResponse(name)agentStatus</parameter><constant>{}: got heartbeat status {}</constant><level>trace</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.run</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: Unhandled exception in NodeHeartbeatRunnable-java.lang.String(name)node.name()-java.lang.Throwable(name)e</parameter><constant>{}: Unhandled exception in NodeHeartbeatRunnable</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.run</callsite><line>210</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.warn</logcall> <parameter>java.lang.String(name){}: scheduling unknown worker with ID {} for stopping.-java.lang.String(name)node.name()-long(name)workerId</parameter><constant>{}: scheduling unknown worker with ID {} for stopping.</constant><level>warn</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.handlePresentWorkers</callsite><line>238</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.debug</logcall> <parameter>java.lang.String(name){}: worker state is still {}-java.lang.String(name)node.name()-org.apache.kafka.trogdor.rest.WorkerState(name)worker.state</parameter><constant>{}: worker state is still {}</constant><level>debug</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.handlePresentWorkers</callsite><line>250</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name){}: worker state changed from {} to {}-java.lang.String(name)node.name()-org.apache.kafka.trogdor.rest.WorkerState(name)worker.state-org.apache.kafka.trogdor.rest.WorkerState(name)state</parameter><constant>{}: worker state changed from {} to {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.handlePresentWorkers</callsite><line>252</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: there is already a worker {} with ID {}.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)worker-long(name)workerId</parameter><constant>{}: there is already a worker {} with ID {}.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>292</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name){}: scheduling worker {} to start.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)worker</parameter><constant>{}: scheduling worker {} to start.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>297</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: unable to locate worker to stop with ID {}.-java.lang.String(name)node.name()-long(name)workerId</parameter><constant>{}: unable to locate worker to stop with ID {}.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>327</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: Worker {} is already scheduled to stop.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)worker</parameter><constant>{}: Worker {} is already scheduled to stop.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>331</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name){}: scheduling worker {} to stop.-java.lang.String(name)node.name()-org.apache.kafka.trogdor.coordinator.ManagedWorker(name)worker</parameter><constant>{}: scheduling worker {} to stop.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>335</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: unable to locate worker to destroy with ID {}.-java.lang.String(name)node.name()-long(name)workerId</parameter><constant>{}: unable to locate worker to destroy with ID {}.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.call</callsite><line>365</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name){}: Failed to send shutdown request-java.lang.String(name)node.name()-java.lang.Exception(name)e</parameter><constant>{}: Failed to send shutdown request</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.NodeManager.beginShutdown</callsite><line>379</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Created TaskManager for agent(s) on: {}-java.lang.String(name)Utils.join(nodeManagers.keySet(),", ")</parameter><constant>Created TaskManager for agent(s) on: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.TaskManager</callsite><line>144</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)createTask(id={}, spec={}) error-java.lang.String(name)id-org.apache.kafka.trogdor.task.TaskSpec(name)spec-java.lang.Object(name)e</parameter><constant>createTask(id={}, spec={}) error</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.createTask</callsite><line>312</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Task {} already exists with spec {}-java.lang.String(name)id-org.apache.kafka.trogdor.task.TaskSpec(name)originalSpec</parameter><constant>Task {} already exists with spec {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>344</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Failed to create a new task {} with spec {}: {}-java.lang.String(name)id-org.apache.kafka.trogdor.task.TaskSpec(name)spec-java.lang.String(name)failure</parameter><constant>Failed to create a new task {} with spec {}: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>355</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Created a new task {} with spec {}, scheduled to start {} ms from now.-java.lang.String(name)id-org.apache.kafka.trogdor.task.TaskSpec(name)spec-long(name)delayMs</parameter><constant>Created a new task {} with spec {}, scheduled to start {} ms from now.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>367</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Can't start task {}, because it is already in state {}.-java.lang.String(name)task.id-org.apache.kafka.trogdor.rest.TaskStateType(name)task.state</parameter><constant>Can't start task {}, because it is already in state {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>387</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name)Unable to find nodes for task {}-java.lang.String(name)task.id-java.lang.Exception(name)e</parameter><constant>Unable to find nodes for task {}</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>395</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Running task {} on node(s): {}-java.lang.String(name)task.id-java.lang.String(name)Utils.join(nodeNames,", ")</parameter><constant>Running task {} on node(s): {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>401</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)stopTask(id={}) error-java.lang.String(name)id-java.util.concurrent.ExecutionException(name)e</parameter><constant>stopTask(id={}) error</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.stopTask</callsite><line>423</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Can't cancel non-existent task {}.-java.lang.String(name)id</parameter><constant>Can't cancel non-existent task {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>445</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Stopped pending task {}.-java.lang.String(name)id</parameter><constant>Stopped pending task {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>454</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Task {} is now complete with no errors.-java.lang.String(name)id</parameter><constant>Task {} is now complete with no errors.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>461</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Task {} is now complete with error: {}-java.lang.String(name)id-java.lang.String(name)task.error</parameter><constant>Task {} is now complete with error: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>463</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Cancelling task {} with worker(s) {}-java.lang.String(name)id-java.lang.String(name)Utils.mkString(activeWorkerIds,"",""," = ",", ")</parameter><constant>Cancelling task {} with worker(s) {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>471</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Can't cancel task {} because it is already stopping.-java.lang.String(name)id</parameter><constant>Can't cancel task {} because it is already stopping.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>477</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Can't cancel task {} because it is already done.-java.lang.String(name)id</parameter><constant>Can't cancel task {} because it is already done.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>480</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)destroyTask(id={}) error-java.lang.String(name)id-java.util.concurrent.ExecutionException(name)e</parameter><constant>destroyTask(id={}) error</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.destroyTask</callsite><line>491</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Can't destroy task {}: no such task found.-java.lang.String(name)id</parameter><constant>Can't destroy task {}: no such task found.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>513</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Destroying task {}.-java.lang.String(name)id</parameter><constant>Destroying task {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>516</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.debug</logcall> <parameter>java.lang.String(name)Task {}: Updating worker state for {} on {} from {} to {}.-java.lang.String(name)task.id-long(name)workerId-java.lang.String(name)nodeName-org.apache.kafka.trogdor.rest.WorkerState(name)prevState-org.apache.kafka.trogdor.rest.WorkerState(name)nextState</parameter><constant>Task {}: Updating worker state for {} on {} from {} to {}.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>564</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.error</logcall> <parameter>java.lang.String(name)Error updating worker state for {} on {}.  Stopping worker.-long(name)workerId-java.lang.String(name)nodeName-java.lang.Exception(name)e</parameter><constant>Error updating worker state for {} on {}.  Stopping worker.</constant><level>error</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.call</callsite><line>571</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name){}: task {} stopped with error {}.  Stopping worker(s): {}-java.lang.String(name)nodeName-java.lang.String(name)task.id-java.lang.String(name)task.error-java.lang.String(name)Utils.mkString(activeWorkerIds,"{","}",": ",", ")</parameter><constant>{}: task {} stopped with error {}.  Stopping worker(s): {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.TaskManager.handleWorkerCompletion</callsite><line>603</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.coordinator.Logger.info</logcall> <parameter>java.lang.String(name)Starting coordinator process.</parameter><constant>Starting coordinator process.</constant><level>info</level><callsite>org.apache.kafka.trogdor.coordinator.Coordinator.main</callsite><line>170</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Activating ProcessStopFault {}.-java.lang.String(name)id</parameter><constant>Activating ProcessStopFault {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.ProcessStopFaultWorker.start</callsite><line>50</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Deactivating ProcessStopFault {}.-java.lang.String(name)id</parameter><constant>Deactivating ProcessStopFault {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.ProcessStopFaultWorker.stop</callsite><line>58</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.error</logcall> <parameter>java.lang.String(name)Failed to parse process ID from line {}-java.lang.NumberFormatException(name)e</parameter><constant>Failed to parse process ID from line {}</constant><level>error</level><callsite>org.apache.kafka.trogdor.fault.ProcessStopFaultWorker.sendSignals</callsite><line>74</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.error</logcall> <parameter>java.lang.String(name){}: no processes containing {} found to send {} to.-java.lang.String(name)id-java.lang.String(name)javaProcessName-java.lang.String(name)signalName</parameter><constant>{}: no processes containing {} found to send {} to.</constant><level>error</level><callsite>org.apache.kafka.trogdor.fault.ProcessStopFaultWorker.sendSignals</callsite><line>79</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name){}: sending {} to {} pid(s) {}-java.lang.String(name)id-java.lang.String(name)signalName-java.lang.String(name)javaProcessName-java.lang.String(name)Utils.join(pids,", ")</parameter><constant>{}: sending {} to {} pid(s) {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.ProcessStopFaultWorker.sendSignals</callsite><line>82</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Activating DegradedNetworkFaultWorker {}.-java.lang.String(name)id</parameter><constant>Activating DegradedNetworkFaultWorker {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.DegradedNetworkFaultWorker.start</callsite><line>54</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Deactivating DegradedNetworkFaultWorker {}.-java.lang.String(name)id</parameter><constant>Deactivating DegradedNetworkFaultWorker {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.DegradedNetworkFaultWorker.stop</callsite><line>73</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Activating {} {}: {}.-java.lang.String(name)spec.getClass().getSimpleName()-java.lang.String(name)id-org.apache.kafka.trogdor.fault.KiboshFaultSpec(name)spec</parameter><constant>Activating {} {}: {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.KiboshFaultWorker.start</callsite><line>49</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Deactivating {} {}: {}.-java.lang.String(name)spec.getClass().getSimpleName()-java.lang.String(name)id-org.apache.kafka.trogdor.fault.KiboshFaultSpec(name)spec</parameter><constant>Deactivating {} {}: {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.KiboshFaultWorker.stop</callsite><line>58</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Activating NetworkPartitionFault {}.-java.lang.String(name)id</parameter><constant>Activating NetworkPartitionFault {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.NetworkPartitionFaultWorker.start</callsite><line>52</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.fault.Logger.info</logcall> <parameter>java.lang.String(name)Deactivating NetworkPartitionFault {}.-java.lang.String(name)id</parameter><constant>Deactivating NetworkPartitionFault {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.fault.NetworkPartitionFaultWorker.stop</callsite><line>61</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.debug</logcall> <parameter>java.lang.String(name)Uncaught exception in REST call: -java.lang.Throwable(name)e</parameter><constant>Uncaught exception in REST call: </constant><level>debug</level><callsite>org.apache.kafka.trogdor.rest.RestExceptionMapper.toResponse</callsite><line>36</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.info</logcall> <parameter>java.lang.String(name)Uncaught exception in REST call: {}-java.lang.String(name)e.getMessage()</parameter><constant>Uncaught exception in REST call: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.rest.RestExceptionMapper.toResponse</callsite><line>38</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.info</logcall> <parameter>java.lang.String(name)Starting REST server</parameter><constant>Starting REST server</constant><level>info</level><callsite>org.apache.kafka.trogdor.rest.JsonRestServer.start</callsite><line>90</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.info</logcall> <parameter>java.lang.String(name)Registered resource {}-java.lang.Object(name)resource</parameter><constant>Registered resource {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.rest.JsonRestServer.start</callsite><line>95</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.debug</logcall> <parameter>java.lang.String(name)Sending {} with input {} to {}-java.lang.String(name)method-java.lang.String(name)serializedBody-java.lang.String(name)url</parameter><constant>Sending {} with input {} to {}</constant><level>debug</level><callsite>org.apache.kafka.trogdor.rest.JsonRestServer.httpRequest</callsite><line>179</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.rest.Logger.info</logcall> <parameter>java.lang.String(name){} {}: error: {}-java.lang.String(name)method-java.lang.String(name)url-java.lang.String(name)e.getMessage()</parameter><constant>{} {}: error: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.rest.JsonRestServer.httpRequest</callsite><line>267</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.task.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating NoOpTask.-java.lang.String(name)id</parameter><constant>{}: Activating NoOpTask.</constant><level>info</level><callsite>org.apache.kafka.trogdor.task.NoOpTaskWorker.start</callsite><line>40</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.task.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating NoOpTask.-java.lang.String(name)id</parameter><constant>{}: Deactivating NoOpTask.</constant><level>info</level><callsite>org.apache.kafka.trogdor.task.NoOpTaskWorker.stop</callsite><line>47</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating RoundTripWorker.-java.lang.String(name)id</parameter><constant>{}: Activating RoundTripWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.start</callsite><line>116</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){}: Starting RoundTripWorker#ProducerRunnable.-java.lang.String(name)id</parameter><constant>{}: Starting RoundTripWorker#ProducerRunnable.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>232</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: ProducerRunnable is exiting.  messagesSent={}; uniqueMessagesSent={}; ackedSends={}/{}.-java.lang.String(name)id-long(name)messagesSent-long(name)uniqueMessagesSent-long(name)spec.maxMessages() - unackedSends-long(name)spec.maxMessages()</parameter><constant>{}: ProducerRunnable is exiting.  messagesSent={}; uniqueMessagesSent={}; ackedSends={}/{}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: consumer waiting for {} message(s), starting with: {}-java.lang.String(name)id-long(name)numToReceive-java.lang.String(name)Utils.join(list,", ")</parameter><constant>{}: consumer waiting for {} message(s), starting with: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.log</callsite><line>320</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){}: Starting RoundTripWorker#ConsumerRunnable.-java.lang.String(name)id</parameter><constant>{}: Starting RoundTripWorker#ConsumerRunnable.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>348</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Consumer received the full count of {} unique messages.  Waiting for all {} sends to be acked...-java.lang.String(name)id-long(name)spec.maxMessages()-java.lang.Long(name)unackedSends</parameter><constant>{}: Consumer received the full count of {} unique messages.  Waiting for all {} sends to be acked...</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>364</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: all sends have been acked.-java.lang.String(name)id</parameter><constant>{}: all sends have been acked.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>372</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){}: Consumer got WakeupException-java.lang.String(name)id-org.apache.kafka.common.errors.WakeupException(name)e</parameter><constant>{}: Consumer got WakeupException</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>385</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){}: Consumer got TimeoutException-java.lang.String(name)id-org.apache.kafka.common.errors.TimeoutException(name)e</parameter><constant>{}: Consumer got TimeoutException</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>387</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: ConsumerRunnable is exiting.  Invoked poll {} time(s).  messagesReceived = {}; uniqueMessagesReceived = {}.-java.lang.String(name)id-long(name)pollInvoked-long(name)messagesReceived-long(name)uniqueMessagesReceived</parameter><constant>{}: ConsumerRunnable is exiting.  Invoked poll {} time(s).  messagesReceived = {}; uniqueMessagesReceived = {}.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.run</callsite><line>393</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating RoundTripWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivating RoundTripWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.stop</callsite><line>445</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivated RoundTripWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivated RoundTripWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.RoundTripWorker.stop</callsite><line>456</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating ConnectionStressWorker with {}-java.lang.String(name)id-org.apache.kafka.trogdor.workload.ConnectionStressSpec(name)spec</parameter><constant>{}: Activating ConnectionStressWorker with {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConnectionStressWorker.start</callsite><line>103</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating ConnectionStressWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivating ConnectionStressWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConnectionStressWorker.stop</callsite><line>305</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating ProduceBenchWorker with {}-java.lang.String(name)id-org.apache.kafka.trogdor.workload.ProduceBenchSpec(name)spec</parameter><constant>{}: Activating ProduceBenchWorker with {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.start</callsite><line>86</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name)SendRecordsCallback: error-java.lang.Exception(name)exception</parameter><constant>SendRecordsCallback: error</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.onCompletion</callsite><line>146</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name)Sent {} total record(s) in {} ms.  status: {}-long(name)histogram.summarize().numSamples()-long(name)curTimeMs - startTimeMs-org.apache.kafka.trogdor.workload.StatusData(name)statusData</parameter><constant>Sent {} total record(s) in {} ms.  status: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.call</callsite><line>260</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name)Beginning transaction.</parameter><constant>Beginning transaction.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.takeTransactionAction</callsite><line>272</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name)Committing transaction.</parameter><constant>Committing transaction.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.takeTransactionAction</callsite><line>276</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name)Aborting transaction.</parameter><constant>Aborting transaction.</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.takeTransactionAction</callsite><line>281</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating ProduceBenchWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivating ProduceBenchWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ProduceBenchWorker.stop</callsite><line>409</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating ConsumeBenchWorker with {}-java.lang.String(name)id-org.apache.kafka.trogdor.workload.ConsumeBenchSpec(name)spec</parameter><constant>{}: Activating ConsumeBenchWorker with {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.start</callsite><line>87</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name)Will consume from topics {} via dynamic group assignment.-java.util.Set<String>(name)topics</parameter><constant>Will consume from topics {} via dynamic group assignment.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.ConsumeMessages</callsite><line>220</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name)Will consume from topic partitions {} via manual assignment.-java.util.List<TopicPartition>(name)partitions</parameter><constant>Will consume from topic partitions {} via manual assignment.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.ConsumeMessages</callsite><line>226</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){} Consumed total number of messages={}, bytes={} in {} ms.  status: {}-java.lang.String(name)clientId-long(name)messagesConsumed-long(name)bytesConsumed-long(name)curTimeMs - startTimeMs-org.apache.kafka.trogdor.workload.StatusData(name)statusData</parameter><constant>{} Consumed total number of messages={}, bytes={} in {} ms.  status: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.call</callsite><line>271</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){} was interrupted. Closing...-java.lang.String(name)this.getClass().getName()</parameter><constant>{} was interrupted. Closing...</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.run</callsite><line>293</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name)Status={}-java.lang.String(name)JsonUtil.toJsonString(statusData)</parameter><constant>Status={}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.update</callsite><line>363</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating ConsumeBenchWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivating ConsumeBenchWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ConsumeBenchWorker.stop</callsite><line>448</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Activating ExternalCommandWorker with {}-java.lang.String(name)id-org.apache.kafka.trogdor.workload.ExternalCommandSpec(name)spec</parameter><constant>{}: Activating ExternalCommandWorker with {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.start</callsite><line>141</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name){}: Unable to start process-java.lang.String(name)id-java.lang.Throwable(name)t</parameter><constant>{}: Unable to start process</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.start</callsite><line>150</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.trace</logcall> <parameter>java.lang.String(name){}: starting stdout monitor.-java.lang.String(name)id</parameter><constant>{}: starting stdout monitor.</constant><level>trace</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>194</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: can't read any more from stdout: {}-java.lang.String(name)id-java.lang.String(name)e.getMessage()</parameter><constant>{}: can't read any more from stdout: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>205</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.trace</logcall> <parameter>java.lang.String(name){}: read line from stdin: {}-java.lang.String(name)id-java.lang.String(name)line</parameter><constant>{}: read line from stdin: {}</constant><level>trace</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>208</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name){}: error: {}-java.lang.String(name)id-java.lang.String(name)error</parameter><constant>{}: error: {}</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>219</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: error reading from stdout.-java.lang.String(name)id-java.lang.Throwable(name)e</parameter><constant>{}: error reading from stdout.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>224</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.trace</logcall> <parameter>java.lang.String(name){}: starting stderr monitor.-java.lang.String(name)id</parameter><constant>{}: starting stderr monitor.</constant><level>trace</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>238</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: can't read any more from stderr: {}-java.lang.String(name)id-java.lang.String(name)e.getMessage()</parameter><constant>{}: can't read any more from stderr: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>249</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name){}: (stderr):{}-java.lang.String(name)id-java.lang.String(name)line</parameter><constant>{}: (stderr):{}</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>252</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: error reading from stderr.-java.lang.String(name)id-java.lang.Throwable(name)e</parameter><constant>{}: error reading from stderr.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>255</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: stdin writer ready.-java.lang.String(name)id</parameter><constant>{}: stdin writer ready.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>273</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.trace</logcall> <parameter>java.lang.String(name){}: StdinWriter terminating.-java.lang.String(name)id</parameter><constant>{}: StdinWriter terminating.</constant><level>trace</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>276</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: writing to stdin: {}-java.lang.String(name)id-java.lang.String(name)inputString</parameter><constant>{}: writing to stdin: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>280</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: can't write any more to stdin: {}-java.lang.String(name)id-java.lang.String(name)e.getMessage()</parameter><constant>{}: can't write any more to stdin: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>285</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: error writing to stdin.-java.lang.String(name)id-java.lang.Throwable(name)e</parameter><constant>{}: error writing to stdin.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>287</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.debug</logcall> <parameter>java.lang.String(name){}: error closing stdinWriter: {}-java.lang.String(name)id-java.lang.String(name)e.getMessage()</parameter><constant>{}: error closing stdinWriter: {}</constant><level>debug</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>292</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: process exited with return code {}-java.lang.String(name)id-int(name)exitStatus</parameter><constant>{}: process exited with return code {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>316</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name){}: ExitMonitor error-java.lang.String(name)id-java.lang.Throwable(name)e</parameter><constant>{}: ExitMonitor error</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>336</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: destroying process-java.lang.String(name)id</parameter><constant>{}: destroying process</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>358</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: forcibly destroying process-java.lang.String(name)id</parameter><constant>{}: forcibly destroying process</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>364</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.trace</logcall> <parameter>java.lang.String(name){}: closing Terminator thread.-java.lang.String(name)id</parameter><constant>{}: closing Terminator thread.</constant><level>trace</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>370</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.error</logcall> <parameter>java.lang.String(name){}: Terminator error-java.lang.String(name)id-java.lang.Throwable(name)e</parameter><constant>{}: Terminator error</constant><level>error</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.run</callsite><line>375</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.workload.Logger.info</logcall> <parameter>java.lang.String(name){}: Deactivating ExternalCommandWorker.-java.lang.String(name)id</parameter><constant>{}: Deactivating ExternalCommandWorker.</constant><level>info</level><callsite>org.apache.kafka.trogdor.workload.ExternalCommandWorker.stop</callsite><line>386</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.debug</logcall> <parameter>java.lang.String(name)RAN {}: {}-org.apache.kafka.trogdor.common.Node(name)curNode-java.lang.String(name)Utils.join(command," ")</parameter><constant>RAN {}: {}</constant><level>debug</level><callsite>org.apache.kafka.trogdor.common.CapturingCommandRunner.run</callsite><line>53</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.info</logcall> <parameter>java.lang.String(name)Creating MiniTrogdorCluster with agents: {} and coordinator: {}-java.lang.String(name)Utils.join(agentNames,", ")-java.lang.String(name)coordinatorName</parameter><constant>Creating MiniTrogdorCluster with agents: {} and coordinator: {}</constant><level>info</level><callsite>org.apache.kafka.trogdor.common.MiniTrogdorCluster.build</callsite><line>135</line><superclass>null</superclass><logcall>org.apache.kafka.trogdor.common.Logger.info</logcall> <parameter>java.lang.String(name)Closing MiniTrogdorCluster.</parameter><constant>Closing MiniTrogdorCluster.</constant><level>info</level><callsite>org.apache.kafka.trogdor.common.MiniTrogdorCluster.close</callsite><line>277</line><superclass>null</superclass><logcall>org.apache.kafka.connect.transforms.Logger.trace</logcall> <parameter>java.lang.String(name)Applying SetSchemaMetadata SMT. Original schema: {}, updated schema: {}-org.apache.kafka.connect.data.Schema(name)schema-org.apache.kafka.connect.data.Schema(name)updatedSchema</parameter><constant>Applying SetSchemaMetadata SMT. Original schema: {}, updated schema: {}</constant><level>trace</level><callsite>org.apache.kafka.connect.transforms.SetSchemaMetadata.apply</callsite><line>82</line><superclass>null</superclass><logcall>org.apache.kafka.connect.transforms.Logger.trace</logcall> <parameter>java.lang.String(name)Cast field '{}' from '{}' to '{}'-java.lang.String(name)field.name()-java.lang.Object(name)origFieldValue-java.lang.Object(name)newFieldValue</parameter><constant>Cast field '{}' from '{}' to '{}'</constant><level>trace</level><callsite>org.apache.kafka.connect.transforms.Cast.applyWithSchema</callsite><line>162</line><superclass>null</superclass>